{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "gKPfyLk_k-k_",
        "LgAg5pCJxjlL",
        "3fi3DPM18hfe",
        "4AKqQgxvnvBb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae441ec35804478c90e77e66b0ab9215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b686f3ea17cf4b2bb26b7ba3635836ab",
              "IPY_MODEL_86855bf84c674115971847cd34eaf27e",
              "IPY_MODEL_ffb5547bf2fe4dccb3c529dd12bb8883"
            ],
            "layout": "IPY_MODEL_15cf433e56f74b008c22729d9b4c06c6"
          }
        },
        "b686f3ea17cf4b2bb26b7ba3635836ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58268898eb9c4619a87a3eba8009d2fd",
            "placeholder": "​",
            "style": "IPY_MODEL_747b486c41314c089a6e024685966cd7",
            "value": "config.json: 100%"
          }
        },
        "86855bf84c674115971847cd34eaf27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff17e7ac2144c9198fad41f858be73f",
            "max": 803,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_140b78eb0722405da21e574de214ee3e",
            "value": 803
          }
        },
        "ffb5547bf2fe4dccb3c529dd12bb8883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008459f3a15c450b9e9fedade10e23ff",
            "placeholder": "​",
            "style": "IPY_MODEL_a81db9130e5b4a05976520dcff524766",
            "value": " 803/803 [00:00&lt;00:00, 41.0kB/s]"
          }
        },
        "15cf433e56f74b008c22729d9b4c06c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58268898eb9c4619a87a3eba8009d2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747b486c41314c089a6e024685966cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ff17e7ac2144c9198fad41f858be73f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140b78eb0722405da21e574de214ee3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "008459f3a15c450b9e9fedade10e23ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81db9130e5b4a05976520dcff524766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0bfec24ae2743a589208384f20fd32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f5b13fb21784c379fc97baa47dcb9c4",
              "IPY_MODEL_188c2b933364496d9b1b7404e5c41ddc",
              "IPY_MODEL_afef4158982a4fe4a6470df53e0f9212"
            ],
            "layout": "IPY_MODEL_5c3ff09ffa38458c8e326ea5f1b9e22f"
          }
        },
        "9f5b13fb21784c379fc97baa47dcb9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f11be0bb3ac4649a174987e05b2ecaf",
            "placeholder": "​",
            "style": "IPY_MODEL_de05b3c9d1ce48f8a130bf39137f8252",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "188c2b933364496d9b1b7404e5c41ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41cf30a13b634e0cb9f3f05641238763",
            "max": 1742910431,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_691a1624688746f6a545f4945b7a3f27",
            "value": 1742910431
          }
        },
        "afef4158982a4fe4a6470df53e0f9212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16dda797a02e4063a52a8eec697f54db",
            "placeholder": "​",
            "style": "IPY_MODEL_abdd2b0ee6d24b5597c7d51ab03c1bc7",
            "value": " 1.74G/1.74G [00:17&lt;00:00, 170MB/s]"
          }
        },
        "5c3ff09ffa38458c8e326ea5f1b9e22f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f11be0bb3ac4649a174987e05b2ecaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de05b3c9d1ce48f8a130bf39137f8252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41cf30a13b634e0cb9f3f05641238763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691a1624688746f6a545f4945b7a3f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16dda797a02e4063a52a8eec697f54db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdd2b0ee6d24b5597c7d51ab03c1bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune Distractor"
      ],
      "metadata": {
        "id": "nSSpxtkym96i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained TO ESSAM"
      ],
      "metadata": {
        "id": "pg1x02D2fPJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78eeb64b-0e5a-4b98-a762-6673ee8a7371",
        "id": "wCj7OXuffbQS"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RILfVfBtfbQU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "def load_Destractive_model():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"potsawee/t5-large-generation-race-Distractor\")\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-race-Distractor\")\n",
        "  return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrained_distractor(model, tokenizer, context, question, answer):\n",
        "  input_text = \" \".join([question, tokenizer.sep_token, answer, tokenizer.sep_token, context])\n",
        "  inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs, max_new_tokens=128)\n",
        "  distractors = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "  distractors = distractors.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n",
        "  distractors = [y.strip() for y in distractors.split(tokenizer.sep_token)]\n",
        "  options = [answer] + distractors\n",
        "\n",
        "  if \"\" or '' in options:\n",
        "    try:\n",
        "      options.remove(\"\")\n",
        "    except:\n",
        "      options.remove('')\n",
        "\n",
        "  random.shuffle(options)\n",
        "  return question, options, answer"
      ],
      "metadata": {
        "id": "iH0aWeMwfbQU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "context = r\"\"\"\n",
        "World number one Novak Djokovic says he is hoping for a \"positive decision\" to allow him\n",
        "to play at Indian Wells and the Miami Open next month. The United States has extended\n",
        "its requirement for international visitors to be vaccinated against Covid-19. Proof of vaccination\n",
        "will be required to enter the country until at least 10 April, but the Serbian has previously\n",
        "said he is unvaccinated. The 35-year-old has applied for special permission to enter the country.\n",
        "Indian Wells and the Miami Open - two of the most prestigious tournaments on the tennis calendar\n",
        "outside the Grand Slams - start on 6 and 20 March respectively. Djokovic says he will return to\n",
        "the ATP tour in Dubai next week after claiming a record-extending 10th Australian Open title\n",
        "and a record-equalling 22nd Grand Slam men's title last month.\"\"\".replace(\"\\n\", \"\")\n",
        "question = \"What is the best title for the passage?\"\n",
        "answer = \"Djokovic's application for special permission to enter the United States\"\n",
        "\n",
        "model, tokenizer = load_Destractive_model()\n",
        "question, options, answer = pretrained_distractor(model, tokenizer, context, question, answer)"
      ],
      "metadata": {
        "id": "jjEMCHBcfbQV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question)\n",
        "print(answer)\n",
        "print(options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVq_C0m2f6yU",
        "outputId": "88354666-413a-4900-9d17-4c9735ce2713"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the best title for the passage?\n",
            "Djokovic's application for special permission to enter the United States\n",
            "[\"Djokovic's preparation for the Miami Open\", \"Djokovic's application for special permission to enter the United States\", \"Djokovic's preparation for the Miami Open\", \"Djokovic's preparation for the Miami Open\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference code for Mohamed Essam"
      ],
      "metadata": {
        "id": "gKPfyLk_k-k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeaervOGo07n",
        "outputId": "d1902207-576d-4ed5-95c8-bb4a0b6c9d9e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import random\n",
        "\n",
        "#GPU -> this for hole project\n",
        "if torch.cuda.is_available():\n",
        "    torch_device = 'cuda'\n",
        "else:\n",
        "    torch_device = 'cpu'\n",
        "torch_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yk2XupO-lEW_",
        "outputId": "2a79206c-2960-400e-fd6b-f1a629124ab9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWD05V08EJPj",
        "outputId": "9131fced-1693-4f59-f65b-b7f366848052"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VIP model folder https://drive.google.com/drive/folders/1Y7B3EBI7TcK7VvppdFrUJ97BQwxhKHx_?usp=sharing choose 30000\n",
        "def load_Distractor_model(Distractor_path = \"\", distractor_model_type = \"t5-small\", max_length = 512):\n",
        "  distractor_model = AutoModelForSeq2SeqLM.from_pretrained(distractor_model_type)\n",
        "  if torch_device == \"cuda\":\n",
        "      distractor_model.cuda()\n",
        "      state = torch.load(Distractor_path) # path to Distractor Gen (t5-large)\n",
        "  else:\n",
        "      state = torch.load(Distractor_path, map_location=torch.device('cpu'))\n",
        "\n",
        "  model_state_dict = state['model']\n",
        "  distractor_model.load_state_dict(model_state_dict)\n",
        "  distractor_model.eval()\n",
        "  print('DistractorGeneration Model loaded:', Distractor_path)\n",
        "\n",
        "  distractor_tokenizer = AutoTokenizer.from_pretrained(distractor_model_type, model_max_length=max_length)\n",
        "  distractor_tokenizer.add_special_tokens({\"sep_token\": \"<sep>\"})\n",
        "\n",
        "  return distractor_tokenizer\n",
        "\n",
        "distractor_tokenizer = load_Distractor_model(Distractor_path = \"/content/drive/MyDrive/Distractor_Finetune/save_dir/t5-small-Race-Distractor-Generation-version0-step54920.pt\", distractor_model_type = \"t5-small\", max_length = 512)\n",
        "#VIP distractor_tokenizer --> path to"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw45OV2pnBqB",
        "outputId": "6b72c24c-9bf6-4d81-8f3d-97dc4d2100c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistractorGeneration Model loaded: /content/drive/MyDrive/Distractor_Finetune/save_dir/t5-small-Race-Distractor-Generation-version0-step54920.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "context = r\"\"\"\n",
        "World number one Novak Djokovic says he is hoping for a \"positive decision\" to allow him\n",
        "to play at Indian Wells and the Miami Open next month. The United States has extended\n",
        "its requirement for international visitors to be vaccinated against Covid-19. Proof of vaccination\n",
        "will be required to enter the country until at least 10 April, but the Serbian has previously\n",
        "said he is unvaccinated. The 35-year-old has applied for special permission to enter the country.\n",
        "Indian Wells and the Miami Open - two of the most prestigious tournaments on the tennis calendar\n",
        "outside the Grand Slams - start on 6 and 20 March respectively. Djokovic says he will return to\n",
        "the ATP tour in Dubai next week after claiming a record-extending 10th Australian Open title\n",
        "and a record-equalling 22nd Grand Slam men's title last month.\"\"\".replace(\"\\n\", \"\")\n",
        "\n",
        "question = \"What is the best title for the passage?\"\n",
        "answer = \"Djokovic's application for special permission to enter the United States\"\n"
      ],
      "metadata": {
        "id": "c-rka2n41w_0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_distractors(t5_tokenizer, context = \"\",question = \"\" ,answer = \"\" ,separator='<sep>', max_length=512, torch_device='cpu',):\n",
        "  #output ==> dis <sep> dis <> dis\n",
        "  input_text = question + ' ' + separator + ' ' + answer + ' ' + separator + ' ' + context\n",
        "  encoding = t5_tokenizer(\n",
        "      [input_text],\n",
        "      padding=\"longest\",\n",
        "      max_length=max_length,\n",
        "      truncation=True,\n",
        "      return_tensors=\"pt\",)\n",
        "\n",
        "  input_ids = encoding.input_ids\n",
        "\n",
        "  if torch_device == 'cuda':\n",
        "      input_ids = input_ids.cuda()\n",
        "\n",
        "\n",
        "  outputs = distractor_model.generate(\n",
        "  input_ids,\n",
        "  max_new_tokens=128,\n",
        "  do_sample=True,)\n",
        "\n",
        "  distractors = distractor_tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "  distractors = distractors.replace(distractor_tokenizer.pad_token, \"\").replace(distractor_tokenizer.eos_token, \"\")\n",
        "  distractors = [y.strip() for y in distractors.split(distractor_tokenizer.sep_token)]\n",
        "  #[gg,gg,gg]\n",
        "  options = [answer] + distractors\n",
        "\n",
        "  if \"\" or '' in options:\n",
        "    try:\n",
        "      options.remove(\"\")\n",
        "    except:\n",
        "      options.remove('')\n",
        "\n",
        "  random.shuffle(options)\n",
        "  return question, options, answer\n",
        "\n",
        "prefix = ['A', 'B' , 'C', 'D']\n",
        "question, options, answer = generate_distractors(distractor_tokenizer, context = context,question = question ,answer = answer ,separator='<sep>', max_length=512, torch_device= torch_device,)\n",
        "print(f\"Q: {question} \\n \")\n",
        "for i , option in zip(prefix, options):\n",
        "  print(f\"  {i}: {option} \\n\")\n",
        "print(f\"correct: {answer}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6twM8vTrsUp",
        "outputId": "60d2d9ad-0542-475d-8213-8b8149f52a5a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the best title for the passage? \n",
            " \n",
            "  A: New Rules for international visitors \n",
            "\n",
            "  B: Djokovic's challenge \n",
            "\n",
            "  C: Djokovic's application for special permission to enter the United States \n",
            "\n",
            "  D: World number two Novak Djokovic's dream \n",
            "\n",
            "correct: Djokovic's application for special permission to enter the United States\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test load Model\n",
        "# model2: distractor generation\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "max_length = 512\n",
        "Distractor_path = \"/content/drive/MyDrive/Distractor_Finetune/save_dir/t5-small-Race-Distractor-Generation-version0-step54920.pt\"\n",
        "distractor_model_type = \"t5-small\"\n",
        "\n",
        "distractor_model = AutoModelForSeq2SeqLM.from_pretrained(distractor_model_type)\n",
        "if torch_device == \"cuda\":\n",
        "    distractor_model.cuda()\n",
        "    state = torch.load(Distractor_path) # path to Distractor Gen (t5-large)\n",
        "else:\n",
        "    state = torch.load(Distractor_path, map_location=torch.device('cpu'))\n",
        "model_state_dict = state['model']\n",
        "distractor_model.load_state_dict(model_state_dict)\n",
        "distractor_model.eval()\n",
        "\n",
        "distector_tokenizer = AutoTokenizer.from_pretrained(distractor_model_type, model_max_length=max_length)\n",
        "distector_tokenizer.add_special_tokens({\"sep_token\": \"<sep>\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9sOZ04pljno",
        "outputId": "8ab4e5c6-94d3-4dc8-9898-9831897a8f1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FineTune"
      ],
      "metadata": {
        "id": "LgAg5pCJxjlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# https://drive.google.com/drive/folders/1jYwVMvCnogWhGv5ULIFft9c4_oUPQ-Qk?usp=sharing"
      ],
      "metadata": {
        "id": "D93BPURRnxoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25099eb-f6ff-4070-817c-a661a725dd63"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "zsNB5Gqjy0P7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bad92c-503f-41f4-a722-b023f7658d76"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "cTeBPSUY3Qx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83910f78-1227-407d-bcb7-6e0ba1a0d1fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Distractor_Finetune/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIMzIeh9xnMg",
        "outputId": "d76f8ff2-440b-438b-9035-d90e623d58ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch_device: cuda\n",
            "model_name: t5-small-Race-Distractor-Generation-version0\n",
            "t5_model: t5-small\n",
            "lr0: 5e-05\n",
            "batch_size: 8\n",
            "num_workers: 0\n",
            "num_epochs: 10\n",
            "max_length: 512\n",
            "Downloading readme: 100% 11.0k/11.0k [00:00<00:00, 24.4MB/s]\n",
            "Downloading data: 100% 2.08M/2.08M [00:00<00:00, 3.99MB/s]\n",
            "Downloading data: 100% 37.4M/37.4M [00:02<00:00, 13.1MB/s]\n",
            "Downloading data: 100% 2.05M/2.05M [00:00<00:00, 6.73MB/s]\n",
            "Generating test split: 100% 4934/4934 [00:00<00:00, 65372.45 examples/s]\n",
            "Generating train split: 100% 87866/87866 [00:00<00:00, 114704.18 examples/s]\n",
            "Generating validation split: 100% 4887/4887 [00:00<00:00, 142945.76 examples/s]\n",
            "RaceQuestionAnswerGeneration Initialized\n",
            "len_train_data: 87866\n",
            "RaceQuestionAnswerGeneration Initialized\n",
            "len_valid_data: 4887\n",
            "\n",
            "Starting the training of T5-model from scratch\n",
            "\n",
            "#parameters: 60506624\n",
            "2024-03-27 09:42:57.701648, Epoch: 1/10  |  1/10984  |  loss = 6.41240120\n",
            "Saved at /content/drive/MyDrive/Distractor_Finetune/save_dir/t5-small-Race-Distractor-Generation-version0-step0.pt\n",
            "############\n",
            "Valid Loss = 7.231214\n",
            "Model improved\n",
            "2024-03-27 09:43:57.476265, Epoch: 1/10  |  2/10984  |  loss = 6.50421000\n",
            "2024-03-27 09:43:57.775835, Epoch: 1/10  |  3/10984  |  loss = 6.79857922\n",
            "2024-03-27 09:43:58.050006, Epoch: 1/10  |  4/10984  |  loss = 11.10650539\n",
            "2024-03-27 09:43:58.353711, Epoch: 1/10  |  5/10984  |  loss = 5.66474533\n",
            "2024-03-27 09:43:58.642951, Epoch: 1/10  |  6/10984  |  loss = 7.72894144\n",
            "2024-03-27 09:43:58.919181, Epoch: 1/10  |  7/10984  |  loss = 8.01847076\n",
            "2024-03-27 09:43:59.182853, Epoch: 1/10  |  8/10984  |  loss = 6.53509426\n",
            "2024-03-27 09:43:59.490442, Epoch: 1/10  |  9/10984  |  loss = 6.14823103\n",
            "2024-03-27 09:43:59.744949, Epoch: 1/10  |  10/10984  |  loss = 6.68600225\n",
            "2024-03-27 09:44:00.017934, Epoch: 1/10  |  11/10984  |  loss = 6.01341200\n",
            "2024-03-27 09:44:00.314599, Epoch: 1/10  |  12/10984  |  loss = 6.25707865\n",
            "2024-03-27 09:44:00.572068, Epoch: 1/10  |  13/10984  |  loss = 8.31293774\n",
            "2024-03-27 09:44:00.862100, Epoch: 1/10  |  14/10984  |  loss = 7.18214989\n",
            "2024-03-27 09:44:01.167191, Epoch: 1/10  |  15/10984  |  loss = 6.06585455\n",
            "2024-03-27 09:44:01.473180, Epoch: 1/10  |  16/10984  |  loss = 5.08367729\n",
            "2024-03-27 09:44:01.777371, Epoch: 1/10  |  17/10984  |  loss = 6.19658279\n",
            "2024-03-27 09:44:02.079369, Epoch: 1/10  |  18/10984  |  loss = 5.90775967\n",
            "2024-03-27 09:44:02.346002, Epoch: 1/10  |  19/10984  |  loss = 6.38837433\n",
            "2024-03-27 09:44:02.646963, Epoch: 1/10  |  20/10984  |  loss = 6.27944660\n",
            "2024-03-27 09:44:02.941340, Epoch: 1/10  |  21/10984  |  loss = 6.11667633\n",
            "2024-03-27 09:44:03.243155, Epoch: 1/10  |  22/10984  |  loss = 5.25971174\n",
            "2024-03-27 09:44:03.534566, Epoch: 1/10  |  23/10984  |  loss = 7.93029070\n",
            "2024-03-27 09:44:03.818051, Epoch: 1/10  |  24/10984  |  loss = 5.05310440\n",
            "2024-03-27 09:44:04.108952, Epoch: 1/10  |  25/10984  |  loss = 6.50212145\n",
            "2024-03-27 09:44:04.378084, Epoch: 1/10  |  26/10984  |  loss = 5.35042477\n",
            "2024-03-27 09:44:04.662924, Epoch: 1/10  |  27/10984  |  loss = 6.08700705\n",
            "2024-03-27 09:44:04.967386, Epoch: 1/10  |  28/10984  |  loss = 6.03498411\n",
            "2024-03-27 09:44:05.244470, Epoch: 1/10  |  29/10984  |  loss = 6.76658487\n",
            "2024-03-27 09:44:05.534776, Epoch: 1/10  |  30/10984  |  loss = 6.22215366\n",
            "2024-03-27 09:44:05.830925, Epoch: 1/10  |  31/10984  |  loss = 4.88688850\n",
            "2024-03-27 09:44:06.121829, Epoch: 1/10  |  32/10984  |  loss = 5.96614552\n",
            "2024-03-27 09:44:06.417082, Epoch: 1/10  |  33/10984  |  loss = 5.85731936\n",
            "2024-03-27 09:44:06.701737, Epoch: 1/10  |  34/10984  |  loss = 5.76121616\n",
            "2024-03-27 09:44:06.990927, Epoch: 1/10  |  35/10984  |  loss = 6.66170216\n",
            "2024-03-27 09:44:07.243429, Epoch: 1/10  |  36/10984  |  loss = 6.42993546\n",
            "2024-03-27 09:44:07.549158, Epoch: 1/10  |  37/10984  |  loss = 5.50335598\n",
            "2024-03-27 09:44:07.844607, Epoch: 1/10  |  38/10984  |  loss = 5.62111473\n",
            "2024-03-27 09:44:08.135685, Epoch: 1/10  |  39/10984  |  loss = 5.91540956\n",
            "2024-03-27 09:44:08.420824, Epoch: 1/10  |  40/10984  |  loss = 6.18282604\n",
            "2024-03-27 09:44:08.704628, Epoch: 1/10  |  41/10984  |  loss = 6.83469391\n",
            "2024-03-27 09:44:08.988413, Epoch: 1/10  |  42/10984  |  loss = 5.49432230\n",
            "2024-03-27 09:44:09.212596, Epoch: 1/10  |  43/10984  |  loss = 6.01360559\n",
            "2024-03-27 09:44:09.506367, Epoch: 1/10  |  44/10984  |  loss = 5.50097227\n",
            "2024-03-27 09:44:09.781047, Epoch: 1/10  |  45/10984  |  loss = 5.49889755\n",
            "2024-03-27 09:44:10.072166, Epoch: 1/10  |  46/10984  |  loss = 6.26936626\n",
            "2024-03-27 09:44:10.335148, Epoch: 1/10  |  47/10984  |  loss = 5.02401257\n",
            "2024-03-27 09:44:10.624860, Epoch: 1/10  |  48/10984  |  loss = 5.09773922\n",
            "2024-03-27 09:44:10.911082, Epoch: 1/10  |  49/10984  |  loss = 5.83712482\n",
            "2024-03-27 09:44:11.244894, Epoch: 1/10  |  50/10984  |  loss = 6.08303404\n",
            "2024-03-27 09:44:11.553596, Epoch: 1/10  |  51/10984  |  loss = 6.44444466\n",
            "2024-03-27 09:44:11.832041, Epoch: 1/10  |  52/10984  |  loss = 5.96550512\n",
            "2024-03-27 09:44:12.173062, Epoch: 1/10  |  53/10984  |  loss = 6.82805681\n",
            "2024-03-27 09:44:12.472111, Epoch: 1/10  |  54/10984  |  loss = 5.15623999\n",
            "2024-03-27 09:44:12.778066, Epoch: 1/10  |  55/10984  |  loss = 5.88183212\n",
            "2024-03-27 09:44:13.042369, Epoch: 1/10  |  56/10984  |  loss = 5.44827890\n",
            "2024-03-27 09:44:13.405678, Epoch: 1/10  |  57/10984  |  loss = 5.24815845\n",
            "2024-03-27 09:44:13.709226, Epoch: 1/10  |  58/10984  |  loss = 5.30523872\n",
            "2024-03-27 09:44:13.993920, Epoch: 1/10  |  59/10984  |  loss = 5.23844194\n",
            "2024-03-27 09:44:14.279255, Epoch: 1/10  |  60/10984  |  loss = 5.21551371\n",
            "2024-03-27 09:44:14.580760, Epoch: 1/10  |  61/10984  |  loss = 4.28481770\n",
            "2024-03-27 09:44:14.886243, Epoch: 1/10  |  62/10984  |  loss = 4.59054089\n",
            "2024-03-27 09:44:15.192586, Epoch: 1/10  |  63/10984  |  loss = 5.36489153\n",
            "2024-03-27 09:44:15.469042, Epoch: 1/10  |  64/10984  |  loss = 5.78186178\n",
            "2024-03-27 09:44:15.756996, Epoch: 1/10  |  65/10984  |  loss = 6.25455666\n",
            "2024-03-27 09:44:16.066017, Epoch: 1/10  |  66/10984  |  loss = 4.76727438\n",
            "2024-03-27 09:44:16.375992, Epoch: 1/10  |  67/10984  |  loss = 4.60074139\n",
            "2024-03-27 09:44:16.664508, Epoch: 1/10  |  68/10984  |  loss = 6.45661354\n",
            "2024-03-27 09:44:16.958975, Epoch: 1/10  |  69/10984  |  loss = 5.56240463\n",
            "2024-03-27 09:44:17.256087, Epoch: 1/10  |  70/10984  |  loss = 5.33429003\n",
            "2024-03-27 09:44:17.534440, Epoch: 1/10  |  71/10984  |  loss = 6.08021021\n",
            "2024-03-27 09:44:17.809997, Epoch: 1/10  |  72/10984  |  loss = 5.16871929\n",
            "2024-03-27 09:44:18.084351, Epoch: 1/10  |  73/10984  |  loss = 5.53072548\n",
            "2024-03-27 09:44:18.371822, Epoch: 1/10  |  74/10984  |  loss = 4.49785757\n",
            "2024-03-27 09:44:18.618901, Epoch: 1/10  |  75/10984  |  loss = 5.82431841\n",
            "2024-03-27 09:44:18.903015, Epoch: 1/10  |  76/10984  |  loss = 5.18089628\n",
            "2024-03-27 09:44:19.203546, Epoch: 1/10  |  77/10984  |  loss = 5.23132133\n",
            "2024-03-27 09:44:19.495661, Epoch: 1/10  |  78/10984  |  loss = 4.95492172\n",
            "2024-03-27 09:44:19.777432, Epoch: 1/10  |  79/10984  |  loss = 5.10513353\n",
            "2024-03-27 09:44:20.026878, Epoch: 1/10  |  80/10984  |  loss = 6.02162266\n",
            "2024-03-27 09:44:20.328613, Epoch: 1/10  |  81/10984  |  loss = 4.04528618\n",
            "2024-03-27 09:44:20.614782, Epoch: 1/10  |  82/10984  |  loss = 5.21015501\n",
            "2024-03-27 09:44:20.894299, Epoch: 1/10  |  83/10984  |  loss = 5.15890503\n",
            "2024-03-27 09:44:21.185437, Epoch: 1/10  |  84/10984  |  loss = 4.96083975\n",
            "2024-03-27 09:44:21.475809, Epoch: 1/10  |  85/10984  |  loss = 5.52586365\n",
            "2024-03-27 09:44:21.773777, Epoch: 1/10  |  86/10984  |  loss = 5.15305281\n",
            "2024-03-27 09:44:22.052226, Epoch: 1/10  |  87/10984  |  loss = 4.66007233\n",
            "2024-03-27 09:44:22.339554, Epoch: 1/10  |  88/10984  |  loss = 5.39001703\n",
            "2024-03-27 09:44:22.612753, Epoch: 1/10  |  89/10984  |  loss = 4.36956263\n",
            "2024-03-27 09:44:22.907309, Epoch: 1/10  |  90/10984  |  loss = 4.71773815\n",
            "2024-03-27 09:44:23.198153, Epoch: 1/10  |  91/10984  |  loss = 4.55940294\n",
            "2024-03-27 09:44:23.485276, Epoch: 1/10  |  92/10984  |  loss = 5.15828991\n",
            "2024-03-27 09:44:23.776058, Epoch: 1/10  |  93/10984  |  loss = 5.19188356\n",
            "2024-03-27 09:44:24.063259, Epoch: 1/10  |  94/10984  |  loss = 4.60266066\n",
            "2024-03-27 09:44:24.350019, Epoch: 1/10  |  95/10984  |  loss = 5.07783318\n",
            "2024-03-27 09:44:24.635647, Epoch: 1/10  |  96/10984  |  loss = 5.18786097\n",
            "2024-03-27 09:44:24.925850, Epoch: 1/10  |  97/10984  |  loss = 5.19947147\n",
            "2024-03-27 09:44:25.215493, Epoch: 1/10  |  98/10984  |  loss = 5.27249575\n",
            "2024-03-27 09:44:25.476282, Epoch: 1/10  |  99/10984  |  loss = 5.25257635\n",
            "2024-03-27 09:44:25.764616, Epoch: 1/10  |  100/10984  |  loss = 4.95923471\n",
            "2024-03-27 09:44:26.061684, Epoch: 1/10  |  101/10984  |  loss = 5.55853367\n",
            "2024-03-27 09:44:26.346046, Epoch: 1/10  |  102/10984  |  loss = 5.45411873\n",
            "2024-03-27 09:44:26.610957, Epoch: 1/10  |  103/10984  |  loss = 4.20136833\n",
            "2024-03-27 09:44:26.892265, Epoch: 1/10  |  104/10984  |  loss = 5.66460991\n",
            "2024-03-27 09:44:27.170796, Epoch: 1/10  |  105/10984  |  loss = 4.84392643\n",
            "2024-03-27 09:44:27.472978, Epoch: 1/10  |  106/10984  |  loss = 4.63890648\n",
            "2024-03-27 09:44:27.743860, Epoch: 1/10  |  107/10984  |  loss = 4.72721529\n",
            "2024-03-27 09:44:28.000998, Epoch: 1/10  |  108/10984  |  loss = 6.70035696\n",
            "2024-03-27 09:44:28.316536, Epoch: 1/10  |  109/10984  |  loss = 4.59352970\n",
            "2024-03-27 09:44:28.608008, Epoch: 1/10  |  110/10984  |  loss = 5.69373560\n",
            "2024-03-27 09:44:28.898646, Epoch: 1/10  |  111/10984  |  loss = 5.13499784\n",
            "2024-03-27 09:44:29.198954, Epoch: 1/10  |  112/10984  |  loss = 5.26707458\n",
            "2024-03-27 09:44:29.487204, Epoch: 1/10  |  113/10984  |  loss = 4.53078604\n",
            "2024-03-27 09:44:29.787569, Epoch: 1/10  |  114/10984  |  loss = 4.81335640\n",
            "2024-03-27 09:44:30.092770, Epoch: 1/10  |  115/10984  |  loss = 5.13412905\n",
            "2024-03-27 09:44:30.378660, Epoch: 1/10  |  116/10984  |  loss = 4.50913286\n",
            "2024-03-27 09:44:30.666418, Epoch: 1/10  |  117/10984  |  loss = 4.45918083\n",
            "2024-03-27 09:44:30.946946, Epoch: 1/10  |  118/10984  |  loss = 4.95750237\n",
            "2024-03-27 09:44:31.236874, Epoch: 1/10  |  119/10984  |  loss = 4.35272121\n",
            "2024-03-27 09:44:31.517654, Epoch: 1/10  |  120/10984  |  loss = 5.29296303\n",
            "2024-03-27 09:44:31.806932, Epoch: 1/10  |  121/10984  |  loss = 4.49463654\n",
            "2024-03-27 09:44:32.075756, Epoch: 1/10  |  122/10984  |  loss = 4.90225029\n",
            "2024-03-27 09:44:32.335984, Epoch: 1/10  |  123/10984  |  loss = 5.32401848\n",
            "2024-03-27 09:44:32.625088, Epoch: 1/10  |  124/10984  |  loss = 5.74224138\n",
            "2024-03-27 09:44:32.924527, Epoch: 1/10  |  125/10984  |  loss = 5.06021261\n",
            "2024-03-27 09:44:33.210604, Epoch: 1/10  |  126/10984  |  loss = 5.12405205\n",
            "2024-03-27 09:44:33.506208, Epoch: 1/10  |  127/10984  |  loss = 4.24953747\n",
            "2024-03-27 09:44:33.798161, Epoch: 1/10  |  128/10984  |  loss = 4.76830435\n",
            "2024-03-27 09:44:34.072546, Epoch: 1/10  |  129/10984  |  loss = 5.43568468\n",
            "2024-03-27 09:44:34.362914, Epoch: 1/10  |  130/10984  |  loss = 4.92811632\n",
            "2024-03-27 09:44:34.656983, Epoch: 1/10  |  131/10984  |  loss = 5.33234501\n",
            "2024-03-27 09:44:34.947779, Epoch: 1/10  |  132/10984  |  loss = 4.67481279\n",
            "2024-03-27 09:44:35.227956, Epoch: 1/10  |  133/10984  |  loss = 4.85901642\n",
            "2024-03-27 09:44:35.517534, Epoch: 1/10  |  134/10984  |  loss = 4.86760664\n",
            "2024-03-27 09:44:35.801631, Epoch: 1/10  |  135/10984  |  loss = 5.42157888\n",
            "2024-03-27 09:44:36.062794, Epoch: 1/10  |  136/10984  |  loss = 5.19737339\n",
            "2024-03-27 09:44:36.344486, Epoch: 1/10  |  137/10984  |  loss = 4.50401783\n",
            "2024-03-27 09:44:36.632357, Epoch: 1/10  |  138/10984  |  loss = 4.95326567\n",
            "2024-03-27 09:44:36.918252, Epoch: 1/10  |  139/10984  |  loss = 5.44749165\n",
            "2024-03-27 09:44:37.199989, Epoch: 1/10  |  140/10984  |  loss = 5.22963285\n",
            "2024-03-27 09:44:37.470074, Epoch: 1/10  |  141/10984  |  loss = 4.37477350\n",
            "2024-03-27 09:44:37.759754, Epoch: 1/10  |  142/10984  |  loss = 5.17698717\n",
            "2024-03-27 09:44:38.044707, Epoch: 1/10  |  143/10984  |  loss = 5.39772749\n",
            "2024-03-27 09:44:38.328351, Epoch: 1/10  |  144/10984  |  loss = 5.01253986\n",
            "2024-03-27 09:44:38.606838, Epoch: 1/10  |  145/10984  |  loss = 5.24342489\n",
            "2024-03-27 09:44:38.891098, Epoch: 1/10  |  146/10984  |  loss = 4.48626184\n",
            "2024-03-27 09:44:39.151111, Epoch: 1/10  |  147/10984  |  loss = 5.56729794\n",
            "2024-03-27 09:44:39.438823, Epoch: 1/10  |  148/10984  |  loss = 4.91650534\n",
            "2024-03-27 09:44:39.726657, Epoch: 1/10  |  149/10984  |  loss = 4.57408285\n",
            "2024-03-27 09:44:39.977630, Epoch: 1/10  |  150/10984  |  loss = 4.32297182\n",
            "2024-03-27 09:44:40.259960, Epoch: 1/10  |  151/10984  |  loss = 5.00849867\n",
            "2024-03-27 09:44:40.556947, Epoch: 1/10  |  152/10984  |  loss = 5.16426373\n",
            "2024-03-27 09:44:40.856113, Epoch: 1/10  |  153/10984  |  loss = 3.98069358\n",
            "2024-03-27 09:44:41.147566, Epoch: 1/10  |  154/10984  |  loss = 5.16880131\n",
            "2024-03-27 09:44:41.483944, Epoch: 1/10  |  155/10984  |  loss = 4.84086227\n",
            "2024-03-27 09:44:41.800425, Epoch: 1/10  |  156/10984  |  loss = 4.83712053\n",
            "2024-03-27 09:44:42.118987, Epoch: 1/10  |  157/10984  |  loss = 5.14284468\n",
            "2024-03-27 09:44:42.459998, Epoch: 1/10  |  158/10984  |  loss = 4.70205498\n",
            "2024-03-27 09:44:42.869169, Epoch: 1/10  |  159/10984  |  loss = 4.77092791\n",
            "2024-03-27 09:44:43.220590, Epoch: 1/10  |  160/10984  |  loss = 5.14880228\n",
            "2024-03-27 09:44:43.592495, Epoch: 1/10  |  161/10984  |  loss = 4.52725792\n",
            "2024-03-27 09:44:43.889801, Epoch: 1/10  |  162/10984  |  loss = 5.32523251\n",
            "2024-03-27 09:44:44.158666, Epoch: 1/10  |  163/10984  |  loss = 4.44666719\n",
            "2024-03-27 09:44:44.447550, Epoch: 1/10  |  164/10984  |  loss = 5.30547094\n",
            "2024-03-27 09:44:44.733141, Epoch: 1/10  |  165/10984  |  loss = 4.08888340\n",
            "2024-03-27 09:44:45.103770, Epoch: 1/10  |  166/10984  |  loss = 3.82444477\n",
            "2024-03-27 09:44:45.445013, Epoch: 1/10  |  167/10984  |  loss = 4.26998568\n",
            "2024-03-27 09:44:45.748939, Epoch: 1/10  |  168/10984  |  loss = 5.44119978\n",
            "2024-03-27 09:44:46.051453, Epoch: 1/10  |  169/10984  |  loss = 4.48511219\n",
            "2024-03-27 09:44:46.356058, Epoch: 1/10  |  170/10984  |  loss = 5.84684277\n",
            "2024-03-27 09:44:46.668434, Epoch: 1/10  |  171/10984  |  loss = 4.29093122\n",
            "2024-03-27 09:44:46.976242, Epoch: 1/10  |  172/10984  |  loss = 5.13417292\n",
            "2024-03-27 09:44:47.280102, Epoch: 1/10  |  173/10984  |  loss = 4.51732302\n",
            "2024-03-27 09:44:47.515662, Epoch: 1/10  |  174/10984  |  loss = 5.28404665\n",
            "2024-03-27 09:44:47.815614, Epoch: 1/10  |  175/10984  |  loss = 4.36295509\n",
            "2024-03-27 09:44:48.120759, Epoch: 1/10  |  176/10984  |  loss = 5.14373112\n",
            "2024-03-27 09:44:48.421460, Epoch: 1/10  |  177/10984  |  loss = 4.18658686\n",
            "2024-03-27 09:44:48.717795, Epoch: 1/10  |  178/10984  |  loss = 4.43681765\n",
            "2024-03-27 09:44:49.012710, Epoch: 1/10  |  179/10984  |  loss = 5.27559566\n",
            "2024-03-27 09:44:49.297553, Epoch: 1/10  |  180/10984  |  loss = 5.41279650\n",
            "2024-03-27 09:44:49.631048, Epoch: 1/10  |  181/10984  |  loss = 4.93102837\n",
            "2024-03-27 09:44:49.941081, Epoch: 1/10  |  182/10984  |  loss = 4.83308506\n",
            "2024-03-27 09:44:50.170852, Epoch: 1/10  |  183/10984  |  loss = 5.83161116\n",
            "2024-03-27 09:44:50.470156, Epoch: 1/10  |  184/10984  |  loss = 4.31883335\n",
            "2024-03-27 09:44:50.780231, Epoch: 1/10  |  185/10984  |  loss = 4.29122639\n",
            "2024-03-27 09:44:51.076252, Epoch: 1/10  |  186/10984  |  loss = 4.35486317\n",
            "2024-03-27 09:44:51.391842, Epoch: 1/10  |  187/10984  |  loss = 4.84654331\n",
            "2024-03-27 09:44:51.690256, Epoch: 1/10  |  188/10984  |  loss = 4.96732473\n",
            "2024-03-27 09:44:52.033031, Epoch: 1/10  |  189/10984  |  loss = 3.42419791\n",
            "2024-03-27 09:44:52.303679, Epoch: 1/10  |  190/10984  |  loss = 4.10275412\n",
            "2024-03-27 09:44:52.613102, Epoch: 1/10  |  191/10984  |  loss = 4.06991959\n",
            "2024-03-27 09:44:52.905054, Epoch: 1/10  |  192/10984  |  loss = 5.13246202\n",
            "2024-03-27 09:44:53.201619, Epoch: 1/10  |  193/10984  |  loss = 4.30216122\n",
            "2024-03-27 09:44:53.495761, Epoch: 1/10  |  194/10984  |  loss = 4.92367125\n",
            "2024-03-27 09:44:53.803102, Epoch: 1/10  |  195/10984  |  loss = 4.70422983\n",
            "2024-03-27 09:44:54.152704, Epoch: 1/10  |  196/10984  |  loss = 3.92526293\n",
            "2024-03-27 09:44:54.445379, Epoch: 1/10  |  197/10984  |  loss = 4.23308134\n",
            "2024-03-27 09:44:54.771362, Epoch: 1/10  |  198/10984  |  loss = 5.25104809\n",
            "2024-03-27 09:44:55.151609, Epoch: 1/10  |  199/10984  |  loss = 5.04424810\n",
            "2024-03-27 09:44:55.468998, Epoch: 1/10  |  200/10984  |  loss = 4.38173771\n",
            "2024-03-27 09:44:55.791214, Epoch: 1/10  |  201/10984  |  loss = 4.22791481\n",
            "2024-03-27 09:44:56.088113, Epoch: 1/10  |  202/10984  |  loss = 5.84469414\n",
            "2024-03-27 09:44:56.413174, Epoch: 1/10  |  203/10984  |  loss = 4.83341837\n",
            "2024-03-27 09:44:56.772472, Epoch: 1/10  |  204/10984  |  loss = 4.19046211\n",
            "2024-03-27 09:44:57.125868, Epoch: 1/10  |  205/10984  |  loss = 4.80765390\n",
            "2024-03-27 09:44:57.424453, Epoch: 1/10  |  206/10984  |  loss = 4.78278828\n",
            "2024-03-27 09:44:57.760961, Epoch: 1/10  |  207/10984  |  loss = 4.00897264\n",
            "2024-03-27 09:44:58.055375, Epoch: 1/10  |  208/10984  |  loss = 3.95537901\n",
            "2024-03-27 09:44:58.346733, Epoch: 1/10  |  209/10984  |  loss = 4.72051859\n",
            "2024-03-27 09:44:58.628603, Epoch: 1/10  |  210/10984  |  loss = 3.99483585\n",
            "2024-03-27 09:44:58.919513, Epoch: 1/10  |  211/10984  |  loss = 4.84938622\n",
            "2024-03-27 09:44:59.214499, Epoch: 1/10  |  212/10984  |  loss = 4.49734879\n",
            "2024-03-27 09:44:59.502658, Epoch: 1/10  |  213/10984  |  loss = 4.10589123\n",
            "2024-03-27 09:44:59.801528, Epoch: 1/10  |  214/10984  |  loss = 4.01133966\n",
            "2024-03-27 09:45:00.060111, Epoch: 1/10  |  215/10984  |  loss = 4.97680187\n",
            "2024-03-27 09:45:00.326934, Epoch: 1/10  |  216/10984  |  loss = 4.83148766\n",
            "2024-03-27 09:45:00.615445, Epoch: 1/10  |  217/10984  |  loss = 4.26016760\n",
            "2024-03-27 09:45:00.886917, Epoch: 1/10  |  218/10984  |  loss = 4.20829296\n",
            "2024-03-27 09:45:01.173490, Epoch: 1/10  |  219/10984  |  loss = 4.14890909\n",
            "2024-03-27 09:45:01.456497, Epoch: 1/10  |  220/10984  |  loss = 4.88876867\n",
            "2024-03-27 09:45:01.745248, Epoch: 1/10  |  221/10984  |  loss = 5.06675529\n",
            "2024-03-27 09:45:02.033067, Epoch: 1/10  |  222/10984  |  loss = 5.65254498\n",
            "2024-03-27 09:45:02.284561, Epoch: 1/10  |  223/10984  |  loss = 4.80718136\n",
            "2024-03-27 09:45:02.585634, Epoch: 1/10  |  224/10984  |  loss = 3.30937028\n",
            "2024-03-27 09:45:02.887289, Epoch: 1/10  |  225/10984  |  loss = 4.40083075\n",
            "2024-03-27 09:45:03.160561, Epoch: 1/10  |  226/10984  |  loss = 4.08153057\n",
            "2024-03-27 09:45:03.456088, Epoch: 1/10  |  227/10984  |  loss = 3.46990108\n",
            "2024-03-27 09:45:03.711677, Epoch: 1/10  |  228/10984  |  loss = 4.97496319\n",
            "2024-03-27 09:45:04.001680, Epoch: 1/10  |  229/10984  |  loss = 4.62133741\n",
            "2024-03-27 09:45:04.286891, Epoch: 1/10  |  230/10984  |  loss = 3.69140077\n",
            "2024-03-27 09:45:04.566270, Epoch: 1/10  |  231/10984  |  loss = 5.36640739\n",
            "2024-03-27 09:45:04.839130, Epoch: 1/10  |  232/10984  |  loss = 4.33219242\n",
            "2024-03-27 09:45:05.124411, Epoch: 1/10  |  233/10984  |  loss = 4.68902445\n",
            "2024-03-27 09:45:05.388892, Epoch: 1/10  |  234/10984  |  loss = 4.47053146\n",
            "2024-03-27 09:45:05.680503, Epoch: 1/10  |  235/10984  |  loss = 4.24013424\n",
            "2024-03-27 09:45:05.977300, Epoch: 1/10  |  236/10984  |  loss = 4.23611641\n",
            "2024-03-27 09:45:06.254699, Epoch: 1/10  |  237/10984  |  loss = 5.76356936\n",
            "2024-03-27 09:45:06.547527, Epoch: 1/10  |  238/10984  |  loss = 4.43265772\n",
            "2024-03-27 09:45:06.836381, Epoch: 1/10  |  239/10984  |  loss = 3.89866328\n",
            "2024-03-27 09:45:07.082534, Epoch: 1/10  |  240/10984  |  loss = 4.65346050\n",
            "2024-03-27 09:45:07.377578, Epoch: 1/10  |  241/10984  |  loss = 5.08978605\n",
            "2024-03-27 09:45:07.680562, Epoch: 1/10  |  242/10984  |  loss = 3.56009841\n",
            "2024-03-27 09:45:07.971322, Epoch: 1/10  |  243/10984  |  loss = 3.96313143\n",
            "2024-03-27 09:45:08.275570, Epoch: 1/10  |  244/10984  |  loss = 3.15349555\n",
            "2024-03-27 09:45:08.577376, Epoch: 1/10  |  245/10984  |  loss = 3.52831054\n",
            "2024-03-27 09:45:08.814570, Epoch: 1/10  |  246/10984  |  loss = 5.14719152\n",
            "2024-03-27 09:45:09.110273, Epoch: 1/10  |  247/10984  |  loss = 4.31918144\n",
            "2024-03-27 09:45:09.394747, Epoch: 1/10  |  248/10984  |  loss = 4.12755632\n",
            "2024-03-27 09:45:09.709018, Epoch: 1/10  |  249/10984  |  loss = 4.40669060\n",
            "2024-03-27 09:45:10.009882, Epoch: 1/10  |  250/10984  |  loss = 4.20618105\n",
            "2024-03-27 09:45:10.299671, Epoch: 1/10  |  251/10984  |  loss = 4.02249241\n",
            "2024-03-27 09:45:10.596981, Epoch: 1/10  |  252/10984  |  loss = 3.74558139\n",
            "2024-03-27 09:45:10.892731, Epoch: 1/10  |  253/10984  |  loss = 4.36266041\n",
            "2024-03-27 09:45:11.187494, Epoch: 1/10  |  254/10984  |  loss = 3.59465742\n",
            "2024-03-27 09:45:11.469016, Epoch: 1/10  |  255/10984  |  loss = 4.74417734\n",
            "2024-03-27 09:45:11.749866, Epoch: 1/10  |  256/10984  |  loss = 4.02556753\n",
            "2024-03-27 09:45:12.041886, Epoch: 1/10  |  257/10984  |  loss = 4.90497541\n",
            "2024-03-27 09:45:12.339050, Epoch: 1/10  |  258/10984  |  loss = 3.50252271\n",
            "2024-03-27 09:45:12.614117, Epoch: 1/10  |  259/10984  |  loss = 3.82440591\n",
            "2024-03-27 09:45:12.902673, Epoch: 1/10  |  260/10984  |  loss = 4.03872919\n",
            "2024-03-27 09:45:13.245598, Epoch: 1/10  |  261/10984  |  loss = 2.88336825\n",
            "2024-03-27 09:45:13.533170, Epoch: 1/10  |  262/10984  |  loss = 3.96692491\n",
            "2024-03-27 09:45:13.811846, Epoch: 1/10  |  263/10984  |  loss = 4.38933754\n",
            "2024-03-27 09:45:14.096259, Epoch: 1/10  |  264/10984  |  loss = 3.93811774\n",
            "2024-03-27 09:45:14.393497, Epoch: 1/10  |  265/10984  |  loss = 3.80389953\n",
            "2024-03-27 09:45:14.687446, Epoch: 1/10  |  266/10984  |  loss = 3.46418452\n",
            "2024-03-27 09:45:14.983716, Epoch: 1/10  |  267/10984  |  loss = 3.86167502\n",
            "2024-03-27 09:45:15.274866, Epoch: 1/10  |  268/10984  |  loss = 4.43281507\n",
            "2024-03-27 09:45:15.559014, Epoch: 1/10  |  269/10984  |  loss = 4.17654800\n",
            "2024-03-27 09:45:15.845927, Epoch: 1/10  |  270/10984  |  loss = 4.28531742\n",
            "2024-03-27 09:45:16.119400, Epoch: 1/10  |  271/10984  |  loss = 3.69734573\n",
            "2024-03-27 09:45:16.383062, Epoch: 1/10  |  272/10984  |  loss = 3.92949319\n",
            "2024-03-27 09:45:16.685552, Epoch: 1/10  |  273/10984  |  loss = 4.35876179\n",
            "2024-03-27 09:45:16.959467, Epoch: 1/10  |  274/10984  |  loss = 4.51182032\n",
            "2024-03-27 09:45:17.244751, Epoch: 1/10  |  275/10984  |  loss = 4.92626715\n",
            "2024-03-27 09:45:17.530554, Epoch: 1/10  |  276/10984  |  loss = 3.51287460\n",
            "2024-03-27 09:45:17.822170, Epoch: 1/10  |  277/10984  |  loss = 3.81964540\n",
            "2024-03-27 09:45:18.115946, Epoch: 1/10  |  278/10984  |  loss = 4.08178091\n",
            "2024-03-27 09:45:18.404218, Epoch: 1/10  |  279/10984  |  loss = 3.70412946\n",
            "2024-03-27 09:45:18.698720, Epoch: 1/10  |  280/10984  |  loss = 3.43124127\n",
            "2024-03-27 09:45:18.962743, Epoch: 1/10  |  281/10984  |  loss = 3.68858242\n",
            "2024-03-27 09:45:19.258248, Epoch: 1/10  |  282/10984  |  loss = 3.89352727\n",
            "2024-03-27 09:45:19.513723, Epoch: 1/10  |  283/10984  |  loss = 3.73978901\n",
            "2024-03-27 09:45:19.797852, Epoch: 1/10  |  284/10984  |  loss = 3.54889369\n",
            "2024-03-27 09:45:20.094073, Epoch: 1/10  |  285/10984  |  loss = 3.40065908\n",
            "2024-03-27 09:45:20.393250, Epoch: 1/10  |  286/10984  |  loss = 3.54395223\n",
            "2024-03-27 09:45:20.690767, Epoch: 1/10  |  287/10984  |  loss = 3.97978640\n",
            "2024-03-27 09:45:20.981588, Epoch: 1/10  |  288/10984  |  loss = 3.69899487\n",
            "2024-03-27 09:45:21.198532, Epoch: 1/10  |  289/10984  |  loss = 4.01118898\n",
            "2024-03-27 09:45:21.514977, Epoch: 1/10  |  290/10984  |  loss = 3.35734916\n",
            "2024-03-27 09:45:21.807620, Epoch: 1/10  |  291/10984  |  loss = 4.27667332\n",
            "2024-03-27 09:45:22.073366, Epoch: 1/10  |  292/10984  |  loss = 4.10455370\n",
            "2024-03-27 09:45:22.362196, Epoch: 1/10  |  293/10984  |  loss = 4.98099947\n",
            "2024-03-27 09:45:22.660492, Epoch: 1/10  |  294/10984  |  loss = 4.40702629\n",
            "2024-03-27 09:45:22.952356, Epoch: 1/10  |  295/10984  |  loss = 3.80337596\n",
            "2024-03-27 09:45:23.200094, Epoch: 1/10  |  296/10984  |  loss = 3.53113842\n",
            "2024-03-27 09:45:23.489777, Epoch: 1/10  |  297/10984  |  loss = 3.77094626\n",
            "2024-03-27 09:45:23.761529, Epoch: 1/10  |  298/10984  |  loss = 3.97060823\n",
            "2024-03-27 09:45:24.052544, Epoch: 1/10  |  299/10984  |  loss = 3.69213176\n",
            "2024-03-27 09:45:24.341691, Epoch: 1/10  |  300/10984  |  loss = 3.93544531\n",
            "2024-03-27 09:45:24.629080, Epoch: 1/10  |  301/10984  |  loss = 3.48525119\n",
            "2024-03-27 09:45:24.892557, Epoch: 1/10  |  302/10984  |  loss = 3.55903387\n",
            "2024-03-27 09:45:25.184455, Epoch: 1/10  |  303/10984  |  loss = 4.01800251\n",
            "2024-03-27 09:45:25.489464, Epoch: 1/10  |  304/10984  |  loss = 2.97829676\n",
            "2024-03-27 09:45:25.771166, Epoch: 1/10  |  305/10984  |  loss = 3.83460402\n",
            "2024-03-27 09:45:26.064888, Epoch: 1/10  |  306/10984  |  loss = 3.75891399\n",
            "2024-03-27 09:45:26.364507, Epoch: 1/10  |  307/10984  |  loss = 3.71523643\n",
            "2024-03-27 09:45:26.647986, Epoch: 1/10  |  308/10984  |  loss = 3.88272595\n",
            "2024-03-27 09:45:26.942274, Epoch: 1/10  |  309/10984  |  loss = 4.40337658\n",
            "2024-03-27 09:45:27.230212, Epoch: 1/10  |  310/10984  |  loss = 3.02960706\n",
            "2024-03-27 09:45:27.497883, Epoch: 1/10  |  311/10984  |  loss = 3.46670222\n",
            "2024-03-27 09:45:27.777614, Epoch: 1/10  |  312/10984  |  loss = 3.96331429\n",
            "2024-03-27 09:45:28.069427, Epoch: 1/10  |  313/10984  |  loss = 4.53396845\n",
            "2024-03-27 09:45:28.349830, Epoch: 1/10  |  314/10984  |  loss = 3.22088838\n",
            "2024-03-27 09:45:28.626823, Epoch: 1/10  |  315/10984  |  loss = 4.34929800\n",
            "2024-03-27 09:45:28.907250, Epoch: 1/10  |  316/10984  |  loss = 4.93303156\n",
            "2024-03-27 09:45:29.198019, Epoch: 1/10  |  317/10984  |  loss = 4.49196291\n",
            "2024-03-27 09:45:29.470151, Epoch: 1/10  |  318/10984  |  loss = 3.72059131\n",
            "2024-03-27 09:45:29.756309, Epoch: 1/10  |  319/10984  |  loss = 4.01299953\n",
            "2024-03-27 09:45:30.039561, Epoch: 1/10  |  320/10984  |  loss = 4.29784107\n",
            "2024-03-27 09:45:30.330764, Epoch: 1/10  |  321/10984  |  loss = 4.33115864\n",
            "2024-03-27 09:45:30.619565, Epoch: 1/10  |  322/10984  |  loss = 3.66593409\n",
            "2024-03-27 09:45:30.903975, Epoch: 1/10  |  323/10984  |  loss = 3.86366796\n",
            "2024-03-27 09:45:31.198174, Epoch: 1/10  |  324/10984  |  loss = 4.22364235\n",
            "2024-03-27 09:45:31.482138, Epoch: 1/10  |  325/10984  |  loss = 3.52562833\n",
            "2024-03-27 09:45:31.755541, Epoch: 1/10  |  326/10984  |  loss = 3.79468751\n",
            "2024-03-27 09:45:32.023724, Epoch: 1/10  |  327/10984  |  loss = 3.98288965\n",
            "2024-03-27 09:45:32.316291, Epoch: 1/10  |  328/10984  |  loss = 4.20127296\n",
            "2024-03-27 09:45:32.608853, Epoch: 1/10  |  329/10984  |  loss = 3.65169501\n",
            "2024-03-27 09:45:32.916662, Epoch: 1/10  |  330/10984  |  loss = 4.04202652\n",
            "2024-03-27 09:45:33.210474, Epoch: 1/10  |  331/10984  |  loss = 3.16855574\n",
            "2024-03-27 09:45:33.502287, Epoch: 1/10  |  332/10984  |  loss = 3.52514720\n",
            "2024-03-27 09:45:33.795962, Epoch: 1/10  |  333/10984  |  loss = 3.72026634\n",
            "2024-03-27 09:45:34.091567, Epoch: 1/10  |  334/10984  |  loss = 3.45914912\n",
            "2024-03-27 09:45:34.383105, Epoch: 1/10  |  335/10984  |  loss = 3.44830418\n",
            "2024-03-27 09:45:34.686899, Epoch: 1/10  |  336/10984  |  loss = 3.81062627\n",
            "2024-03-27 09:45:34.996145, Epoch: 1/10  |  337/10984  |  loss = 4.13888931\n",
            "2024-03-27 09:45:35.284385, Epoch: 1/10  |  338/10984  |  loss = 3.59153771\n",
            "2024-03-27 09:45:35.584894, Epoch: 1/10  |  339/10984  |  loss = 3.49787593\n",
            "2024-03-27 09:45:35.883904, Epoch: 1/10  |  340/10984  |  loss = 3.63856649\n",
            "2024-03-27 09:45:36.183558, Epoch: 1/10  |  341/10984  |  loss = 2.81232595\n",
            "2024-03-27 09:45:36.456784, Epoch: 1/10  |  342/10984  |  loss = 3.76981473\n",
            "2024-03-27 09:45:36.743012, Epoch: 1/10  |  343/10984  |  loss = 4.34678793\n",
            "2024-03-27 09:45:37.040926, Epoch: 1/10  |  344/10984  |  loss = 4.20780468\n",
            "2024-03-27 09:45:37.321107, Epoch: 1/10  |  345/10984  |  loss = 3.22929740\n",
            "2024-03-27 09:45:37.609763, Epoch: 1/10  |  346/10984  |  loss = 3.03368163\n",
            "2024-03-27 09:45:37.903674, Epoch: 1/10  |  347/10984  |  loss = 4.02841997\n",
            "2024-03-27 09:45:38.192311, Epoch: 1/10  |  348/10984  |  loss = 3.81450462\n",
            "2024-03-27 09:45:38.427679, Epoch: 1/10  |  349/10984  |  loss = 3.97586060\n",
            "2024-03-27 09:45:38.701106, Epoch: 1/10  |  350/10984  |  loss = 3.44459987\n",
            "2024-03-27 09:45:38.966177, Epoch: 1/10  |  351/10984  |  loss = 3.53158712\n",
            "2024-03-27 09:45:39.266653, Epoch: 1/10  |  352/10984  |  loss = 3.13625574\n",
            "2024-03-27 09:45:39.563785, Epoch: 1/10  |  353/10984  |  loss = 3.85326600\n",
            "2024-03-27 09:45:39.849514, Epoch: 1/10  |  354/10984  |  loss = 3.69615030\n",
            "2024-03-27 09:45:40.115680, Epoch: 1/10  |  355/10984  |  loss = 3.78958654\n",
            "2024-03-27 09:45:40.403543, Epoch: 1/10  |  356/10984  |  loss = 3.69134974\n",
            "2024-03-27 09:45:40.695737, Epoch: 1/10  |  357/10984  |  loss = 3.53063440\n",
            "2024-03-27 09:45:40.987951, Epoch: 1/10  |  358/10984  |  loss = 3.75206590\n",
            "2024-03-27 09:45:41.288068, Epoch: 1/10  |  359/10984  |  loss = 3.81043959\n",
            "2024-03-27 09:45:41.572761, Epoch: 1/10  |  360/10984  |  loss = 3.84990096\n",
            "2024-03-27 09:45:41.853387, Epoch: 1/10  |  361/10984  |  loss = 4.77092886\n",
            "2024-03-27 09:45:42.137871, Epoch: 1/10  |  362/10984  |  loss = 3.74589825\n",
            "2024-03-27 09:45:42.414849, Epoch: 1/10  |  363/10984  |  loss = 3.45128059\n",
            "2024-03-27 09:45:42.687121, Epoch: 1/10  |  364/10984  |  loss = 3.30665421\n",
            "2024-03-27 09:45:42.987105, Epoch: 1/10  |  365/10984  |  loss = 3.26715827\n",
            "2024-03-27 09:45:43.278549, Epoch: 1/10  |  366/10984  |  loss = 3.81949306\n",
            "2024-03-27 09:45:43.565445, Epoch: 1/10  |  367/10984  |  loss = 4.22669125\n",
            "2024-03-27 09:45:43.840648, Epoch: 1/10  |  368/10984  |  loss = 4.10294676\n",
            "2024-03-27 09:45:44.100318, Epoch: 1/10  |  369/10984  |  loss = 3.26531792\n",
            "2024-03-27 09:45:44.391151, Epoch: 1/10  |  370/10984  |  loss = 3.28140926\n",
            "2024-03-27 09:45:44.672968, Epoch: 1/10  |  371/10984  |  loss = 4.51176023\n",
            "2024-03-27 09:45:44.971901, Epoch: 1/10  |  372/10984  |  loss = 3.66885233\n",
            "2024-03-27 09:45:45.265853, Epoch: 1/10  |  373/10984  |  loss = 3.41783285\n",
            "2024-03-27 09:45:45.498034, Epoch: 1/10  |  374/10984  |  loss = 4.07224655\n",
            "2024-03-27 09:45:45.789305, Epoch: 1/10  |  375/10984  |  loss = 3.93955064\n",
            "2024-03-27 09:45:46.066065, Epoch: 1/10  |  376/10984  |  loss = 3.25627518\n",
            "2024-03-27 09:45:46.343700, Epoch: 1/10  |  377/10984  |  loss = 2.69528365\n",
            "2024-03-27 09:45:46.588801, Epoch: 1/10  |  378/10984  |  loss = 4.15014076\n",
            "2024-03-27 09:45:46.889499, Epoch: 1/10  |  379/10984  |  loss = 3.54260635\n",
            "2024-03-27 09:45:47.185563, Epoch: 1/10  |  380/10984  |  loss = 3.46759939\n",
            "2024-03-27 09:45:47.479053, Epoch: 1/10  |  381/10984  |  loss = 3.81558228\n",
            "2024-03-27 09:45:47.769261, Epoch: 1/10  |  382/10984  |  loss = 3.30111170\n",
            "2024-03-27 09:45:48.071578, Epoch: 1/10  |  383/10984  |  loss = 3.42856765\n",
            "2024-03-27 09:45:48.347549, Epoch: 1/10  |  384/10984  |  loss = 3.62915993\n",
            "2024-03-27 09:45:48.606191, Epoch: 1/10  |  385/10984  |  loss = 4.48221159\n",
            "2024-03-27 09:45:48.909067, Epoch: 1/10  |  386/10984  |  loss = 2.89031386\n",
            "2024-03-27 09:45:49.188371, Epoch: 1/10  |  387/10984  |  loss = 2.86715937\n",
            "2024-03-27 09:45:49.468588, Epoch: 1/10  |  388/10984  |  loss = 3.17507815\n",
            "2024-03-27 09:45:49.748029, Epoch: 1/10  |  389/10984  |  loss = 3.97603917\n",
            "2024-03-27 09:45:50.048984, Epoch: 1/10  |  390/10984  |  loss = 3.63508320\n",
            "2024-03-27 09:45:50.340990, Epoch: 1/10  |  391/10984  |  loss = 3.97582841\n",
            "2024-03-27 09:45:50.621330, Epoch: 1/10  |  392/10984  |  loss = 4.23348379\n",
            "2024-03-27 09:45:50.926435, Epoch: 1/10  |  393/10984  |  loss = 3.97353101\n",
            "2024-03-27 09:45:51.219415, Epoch: 1/10  |  394/10984  |  loss = 4.95456028\n",
            "2024-03-27 09:45:51.495797, Epoch: 1/10  |  395/10984  |  loss = 3.57006073\n",
            "2024-03-27 09:45:51.794071, Epoch: 1/10  |  396/10984  |  loss = 3.35811210\n",
            "2024-03-27 09:45:52.074206, Epoch: 1/10  |  397/10984  |  loss = 2.92547512\n",
            "2024-03-27 09:45:52.358736, Epoch: 1/10  |  398/10984  |  loss = 3.67257094\n",
            "2024-03-27 09:45:52.658393, Epoch: 1/10  |  399/10984  |  loss = 3.20097995\n",
            "2024-03-27 09:45:52.942478, Epoch: 1/10  |  400/10984  |  loss = 3.19060564\n",
            "2024-03-27 09:45:53.267876, Epoch: 1/10  |  401/10984  |  loss = 3.25546241\n",
            "2024-03-27 09:45:53.553089, Epoch: 1/10  |  402/10984  |  loss = 3.07265091\n",
            "2024-03-27 09:45:53.842418, Epoch: 1/10  |  403/10984  |  loss = 3.37507272\n",
            "2024-03-27 09:45:54.127070, Epoch: 1/10  |  404/10984  |  loss = 3.58576035\n",
            "2024-03-27 09:45:54.388967, Epoch: 1/10  |  405/10984  |  loss = 3.65627217\n",
            "2024-03-27 09:45:54.680790, Epoch: 1/10  |  406/10984  |  loss = 3.34145594\n",
            "2024-03-27 09:45:54.968865, Epoch: 1/10  |  407/10984  |  loss = 3.97081661\n",
            "2024-03-27 09:45:55.260539, Epoch: 1/10  |  408/10984  |  loss = 3.89765453\n",
            "2024-03-27 09:45:55.541262, Epoch: 1/10  |  409/10984  |  loss = 3.77125812\n",
            "2024-03-27 09:45:55.820818, Epoch: 1/10  |  410/10984  |  loss = 3.06824613\n",
            "2024-03-27 09:45:56.123132, Epoch: 1/10  |  411/10984  |  loss = 3.49799991\n",
            "2024-03-27 09:45:56.408989, Epoch: 1/10  |  412/10984  |  loss = 3.81824470\n",
            "2024-03-27 09:45:56.691064, Epoch: 1/10  |  413/10984  |  loss = 4.12511539\n",
            "2024-03-27 09:45:56.979172, Epoch: 1/10  |  414/10984  |  loss = 3.68076825\n",
            "2024-03-27 09:45:57.281698, Epoch: 1/10  |  415/10984  |  loss = 3.83504295\n",
            "2024-03-27 09:45:57.585016, Epoch: 1/10  |  416/10984  |  loss = 3.38277650\n",
            "2024-03-27 09:45:57.873313, Epoch: 1/10  |  417/10984  |  loss = 2.57820559\n",
            "2024-03-27 09:45:58.157747, Epoch: 1/10  |  418/10984  |  loss = 3.95615482\n",
            "2024-03-27 09:45:58.445357, Epoch: 1/10  |  419/10984  |  loss = 3.99468589\n",
            "2024-03-27 09:45:58.734234, Epoch: 1/10  |  420/10984  |  loss = 4.16210794\n",
            "2024-03-27 09:45:59.048013, Epoch: 1/10  |  421/10984  |  loss = 3.60562468\n",
            "2024-03-27 09:45:59.349385, Epoch: 1/10  |  422/10984  |  loss = 3.44021273\n",
            "2024-03-27 09:45:59.633721, Epoch: 1/10  |  423/10984  |  loss = 3.77748322\n",
            "2024-03-27 09:45:59.928238, Epoch: 1/10  |  424/10984  |  loss = 3.40155196\n",
            "2024-03-27 09:46:00.217509, Epoch: 1/10  |  425/10984  |  loss = 3.79854631\n",
            "2024-03-27 09:46:00.524181, Epoch: 1/10  |  426/10984  |  loss = 3.56749344\n",
            "2024-03-27 09:46:00.826562, Epoch: 1/10  |  427/10984  |  loss = 2.71380782\n",
            "2024-03-27 09:46:01.130353, Epoch: 1/10  |  428/10984  |  loss = 3.57620692\n",
            "2024-03-27 09:46:01.430697, Epoch: 1/10  |  429/10984  |  loss = 2.95831466\n",
            "2024-03-27 09:46:01.712989, Epoch: 1/10  |  430/10984  |  loss = 3.18308091\n",
            "2024-03-27 09:46:01.998692, Epoch: 1/10  |  431/10984  |  loss = 3.92454505\n",
            "2024-03-27 09:46:02.297831, Epoch: 1/10  |  432/10984  |  loss = 3.69614100\n",
            "2024-03-27 09:46:02.585294, Epoch: 1/10  |  433/10984  |  loss = 3.02263522\n",
            "2024-03-27 09:46:02.865311, Epoch: 1/10  |  434/10984  |  loss = 3.76996660\n",
            "2024-03-27 09:46:03.156330, Epoch: 1/10  |  435/10984  |  loss = 3.47761488\n",
            "2024-03-27 09:46:03.449920, Epoch: 1/10  |  436/10984  |  loss = 3.02770352\n",
            "2024-03-27 09:46:03.738719, Epoch: 1/10  |  437/10984  |  loss = 3.58696890\n",
            "2024-03-27 09:46:04.020721, Epoch: 1/10  |  438/10984  |  loss = 3.19221926\n",
            "2024-03-27 09:46:04.302479, Epoch: 1/10  |  439/10984  |  loss = 3.76166034\n",
            "2024-03-27 09:46:04.591478, Epoch: 1/10  |  440/10984  |  loss = 3.47482204\n",
            "2024-03-27 09:46:04.878383, Epoch: 1/10  |  441/10984  |  loss = 3.74310327\n",
            "2024-03-27 09:46:05.157545, Epoch: 1/10  |  442/10984  |  loss = 3.88649297\n",
            "2024-03-27 09:46:05.455828, Epoch: 1/10  |  443/10984  |  loss = 3.03644609\n",
            "2024-03-27 09:46:05.754528, Epoch: 1/10  |  444/10984  |  loss = 3.33294368\n",
            "2024-03-27 09:46:06.041195, Epoch: 1/10  |  445/10984  |  loss = 3.92965364\n",
            "2024-03-27 09:46:06.332519, Epoch: 1/10  |  446/10984  |  loss = 2.86234641\n",
            "2024-03-27 09:46:06.618718, Epoch: 1/10  |  447/10984  |  loss = 3.39855218\n",
            "2024-03-27 09:46:06.899883, Epoch: 1/10  |  448/10984  |  loss = 3.64302087\n",
            "2024-03-27 09:46:07.191081, Epoch: 1/10  |  449/10984  |  loss = 3.14569497\n",
            "2024-03-27 09:46:07.453440, Epoch: 1/10  |  450/10984  |  loss = 4.04608250\n",
            "2024-03-27 09:46:07.705879, Epoch: 1/10  |  451/10984  |  loss = 3.18776178\n",
            "2024-03-27 09:46:08.011118, Epoch: 1/10  |  452/10984  |  loss = 3.16582417\n",
            "2024-03-27 09:46:08.307949, Epoch: 1/10  |  453/10984  |  loss = 3.19650984\n",
            "2024-03-27 09:46:08.602224, Epoch: 1/10  |  454/10984  |  loss = 3.56220269\n",
            "2024-03-27 09:46:08.900908, Epoch: 1/10  |  455/10984  |  loss = 2.86286950\n",
            "2024-03-27 09:46:09.208457, Epoch: 1/10  |  456/10984  |  loss = 2.64867783\n",
            "2024-03-27 09:46:09.491758, Epoch: 1/10  |  457/10984  |  loss = 2.93815899\n",
            "2024-03-27 09:46:09.742702, Epoch: 1/10  |  458/10984  |  loss = 3.11386299\n",
            "2024-03-27 09:46:10.024610, Epoch: 1/10  |  459/10984  |  loss = 3.24867368\n",
            "2024-03-27 09:46:10.327616, Epoch: 1/10  |  460/10984  |  loss = 3.25149107\n",
            "2024-03-27 09:46:10.618115, Epoch: 1/10  |  461/10984  |  loss = 3.26673269\n",
            "2024-03-27 09:46:10.911353, Epoch: 1/10  |  462/10984  |  loss = 3.66903448\n",
            "2024-03-27 09:46:11.196230, Epoch: 1/10  |  463/10984  |  loss = 3.53349686\n",
            "2024-03-27 09:46:11.491771, Epoch: 1/10  |  464/10984  |  loss = 3.90432692\n",
            "2024-03-27 09:46:11.783750, Epoch: 1/10  |  465/10984  |  loss = 3.91422820\n",
            "2024-03-27 09:46:12.088232, Epoch: 1/10  |  466/10984  |  loss = 3.51117516\n",
            "2024-03-27 09:46:12.378506, Epoch: 1/10  |  467/10984  |  loss = 3.42115760\n",
            "2024-03-27 09:46:12.677325, Epoch: 1/10  |  468/10984  |  loss = 3.47520661\n",
            "2024-03-27 09:46:12.989751, Epoch: 1/10  |  469/10984  |  loss = 3.01113009\n",
            "2024-03-27 09:46:13.286858, Epoch: 1/10  |  470/10984  |  loss = 3.64638042\n",
            "2024-03-27 09:46:13.593090, Epoch: 1/10  |  471/10984  |  loss = 3.84124112\n",
            "2024-03-27 09:46:13.885185, Epoch: 1/10  |  472/10984  |  loss = 3.66135049\n",
            "2024-03-27 09:46:14.139077, Epoch: 1/10  |  473/10984  |  loss = 3.22439694\n",
            "2024-03-27 09:46:14.437431, Epoch: 1/10  |  474/10984  |  loss = 2.93932104\n",
            "2024-03-27 09:46:14.735004, Epoch: 1/10  |  475/10984  |  loss = 3.44373274\n",
            "2024-03-27 09:46:15.000739, Epoch: 1/10  |  476/10984  |  loss = 3.95376945\n",
            "2024-03-27 09:46:15.268696, Epoch: 1/10  |  477/10984  |  loss = 3.65201521\n",
            "2024-03-27 09:46:15.560259, Epoch: 1/10  |  478/10984  |  loss = 4.48077059\n",
            "2024-03-27 09:46:15.855082, Epoch: 1/10  |  479/10984  |  loss = 3.37727213\n",
            "2024-03-27 09:46:16.138802, Epoch: 1/10  |  480/10984  |  loss = 3.53253317\n",
            "2024-03-27 09:46:16.427310, Epoch: 1/10  |  481/10984  |  loss = 3.95159268\n",
            "2024-03-27 09:46:16.700830, Epoch: 1/10  |  482/10984  |  loss = 3.25727630\n",
            "2024-03-27 09:46:16.981892, Epoch: 1/10  |  483/10984  |  loss = 3.73077297\n",
            "2024-03-27 09:46:17.268162, Epoch: 1/10  |  484/10984  |  loss = 4.44973373\n",
            "2024-03-27 09:46:17.559858, Epoch: 1/10  |  485/10984  |  loss = 2.90391541\n",
            "2024-03-27 09:46:17.845345, Epoch: 1/10  |  486/10984  |  loss = 3.84810662\n",
            "2024-03-27 09:46:18.138208, Epoch: 1/10  |  487/10984  |  loss = 4.03086519\n",
            "2024-03-27 09:46:18.421937, Epoch: 1/10  |  488/10984  |  loss = 3.62454534\n",
            "2024-03-27 09:46:18.712345, Epoch: 1/10  |  489/10984  |  loss = 3.84101272\n",
            "2024-03-27 09:46:19.010503, Epoch: 1/10  |  490/10984  |  loss = 3.24563909\n",
            "2024-03-27 09:46:19.290482, Epoch: 1/10  |  491/10984  |  loss = 3.38626409\n",
            "2024-03-27 09:46:19.604577, Epoch: 1/10  |  492/10984  |  loss = 3.38504720\n",
            "2024-03-27 09:46:19.936947, Epoch: 1/10  |  493/10984  |  loss = 2.97913861\n",
            "2024-03-27 09:46:20.230513, Epoch: 1/10  |  494/10984  |  loss = 3.62912345\n",
            "2024-03-27 09:46:20.517049, Epoch: 1/10  |  495/10984  |  loss = 3.77761340\n",
            "2024-03-27 09:46:20.810848, Epoch: 1/10  |  496/10984  |  loss = 3.78864026\n",
            "2024-03-27 09:46:21.100086, Epoch: 1/10  |  497/10984  |  loss = 4.06931400\n",
            "2024-03-27 09:46:21.381012, Epoch: 1/10  |  498/10984  |  loss = 3.50752974\n",
            "2024-03-27 09:46:21.689407, Epoch: 1/10  |  499/10984  |  loss = 3.20157528\n",
            "2024-03-27 09:46:21.933204, Epoch: 1/10  |  500/10984  |  loss = 3.86503959\n",
            "2024-03-27 09:46:22.219020, Epoch: 1/10  |  501/10984  |  loss = 3.79456186\n",
            "2024-03-27 09:46:22.527068, Epoch: 1/10  |  502/10984  |  loss = 2.57880807\n",
            "2024-03-27 09:46:22.792737, Epoch: 1/10  |  503/10984  |  loss = 3.74700236\n",
            "2024-03-27 09:46:23.081304, Epoch: 1/10  |  504/10984  |  loss = 4.57003450\n",
            "2024-03-27 09:46:23.332475, Epoch: 1/10  |  505/10984  |  loss = 3.92044449\n",
            "2024-03-27 09:46:23.623211, Epoch: 1/10  |  506/10984  |  loss = 3.68673921\n",
            "2024-03-27 09:46:23.914814, Epoch: 1/10  |  507/10984  |  loss = 3.26535678\n",
            "2024-03-27 09:46:24.200200, Epoch: 1/10  |  508/10984  |  loss = 3.45912623\n",
            "2024-03-27 09:46:24.491890, Epoch: 1/10  |  509/10984  |  loss = 3.42713165\n",
            "2024-03-27 09:46:24.785962, Epoch: 1/10  |  510/10984  |  loss = 3.90839815\n",
            "2024-03-27 09:46:25.079030, Epoch: 1/10  |  511/10984  |  loss = 3.53866935\n",
            "2024-03-27 09:46:25.358064, Epoch: 1/10  |  512/10984  |  loss = 4.28204918\n",
            "2024-03-27 09:46:25.653701, Epoch: 1/10  |  513/10984  |  loss = 3.28308511\n",
            "2024-03-27 09:46:25.933502, Epoch: 1/10  |  514/10984  |  loss = 2.88240027\n",
            "2024-03-27 09:46:26.233430, Epoch: 1/10  |  515/10984  |  loss = 3.08670592\n",
            "2024-03-27 09:46:26.530602, Epoch: 1/10  |  516/10984  |  loss = 3.61642337\n",
            "2024-03-27 09:46:26.828573, Epoch: 1/10  |  517/10984  |  loss = 4.44756889\n",
            "2024-03-27 09:46:27.129666, Epoch: 1/10  |  518/10984  |  loss = 2.97274160\n",
            "2024-03-27 09:46:27.424142, Epoch: 1/10  |  519/10984  |  loss = 3.57959390\n",
            "2024-03-27 09:46:27.712671, Epoch: 1/10  |  520/10984  |  loss = 3.60894036\n",
            "2024-03-27 09:46:28.009009, Epoch: 1/10  |  521/10984  |  loss = 3.57168508\n",
            "2024-03-27 09:46:28.293415, Epoch: 1/10  |  522/10984  |  loss = 3.74892950\n",
            "2024-03-27 09:46:28.586895, Epoch: 1/10  |  523/10984  |  loss = 3.62499547\n",
            "2024-03-27 09:46:28.871340, Epoch: 1/10  |  524/10984  |  loss = 3.28261304\n",
            "2024-03-27 09:46:29.165118, Epoch: 1/10  |  525/10984  |  loss = 3.64709139\n",
            "2024-03-27 09:46:29.448026, Epoch: 1/10  |  526/10984  |  loss = 4.37957096\n",
            "2024-03-27 09:46:29.743608, Epoch: 1/10  |  527/10984  |  loss = 3.06387329\n",
            "2024-03-27 09:46:30.021248, Epoch: 1/10  |  528/10984  |  loss = 3.77893543\n",
            "2024-03-27 09:46:30.309033, Epoch: 1/10  |  529/10984  |  loss = 3.20956635\n",
            "2024-03-27 09:46:30.585104, Epoch: 1/10  |  530/10984  |  loss = 3.24350452\n",
            "2024-03-27 09:46:30.870647, Epoch: 1/10  |  531/10984  |  loss = 2.77235508\n",
            "2024-03-27 09:46:31.156345, Epoch: 1/10  |  532/10984  |  loss = 4.29825020\n",
            "2024-03-27 09:46:31.401157, Epoch: 1/10  |  533/10984  |  loss = 3.12944317\n",
            "2024-03-27 09:46:31.662641, Epoch: 1/10  |  534/10984  |  loss = 4.01915455\n",
            "2024-03-27 09:46:31.949478, Epoch: 1/10  |  535/10984  |  loss = 3.68356991\n",
            "2024-03-27 09:46:32.246155, Epoch: 1/10  |  536/10984  |  loss = 4.16147518\n",
            "2024-03-27 09:46:32.539694, Epoch: 1/10  |  537/10984  |  loss = 3.75338817\n",
            "2024-03-27 09:46:32.809559, Epoch: 1/10  |  538/10984  |  loss = 3.92131472\n",
            "2024-03-27 09:46:33.116252, Epoch: 1/10  |  539/10984  |  loss = 3.33868623\n",
            "2024-03-27 09:46:33.379945, Epoch: 1/10  |  540/10984  |  loss = 3.54039764\n",
            "2024-03-27 09:46:33.671980, Epoch: 1/10  |  541/10984  |  loss = 3.32244420\n",
            "2024-03-27 09:46:33.949174, Epoch: 1/10  |  542/10984  |  loss = 4.29210091\n",
            "2024-03-27 09:46:34.234120, Epoch: 1/10  |  543/10984  |  loss = 2.75941753\n",
            "2024-03-27 09:46:34.522895, Epoch: 1/10  |  544/10984  |  loss = 3.64682841\n",
            "2024-03-27 09:46:34.804937, Epoch: 1/10  |  545/10984  |  loss = 3.91065574\n",
            "2024-03-27 09:46:35.067416, Epoch: 1/10  |  546/10984  |  loss = 4.25047064\n",
            "2024-03-27 09:46:35.348676, Epoch: 1/10  |  547/10984  |  loss = 3.49894953\n",
            "2024-03-27 09:46:35.643568, Epoch: 1/10  |  548/10984  |  loss = 3.58077717\n",
            "2024-03-27 09:46:35.937176, Epoch: 1/10  |  549/10984  |  loss = 3.85554671\n",
            "2024-03-27 09:46:36.233353, Epoch: 1/10  |  550/10984  |  loss = 3.35336757\n",
            "2024-03-27 09:46:36.528091, Epoch: 1/10  |  551/10984  |  loss = 3.77918768\n",
            "2024-03-27 09:46:36.820536, Epoch: 1/10  |  552/10984  |  loss = 3.75228214\n",
            "2024-03-27 09:46:37.111651, Epoch: 1/10  |  553/10984  |  loss = 4.30687714\n",
            "2024-03-27 09:46:37.387005, Epoch: 1/10  |  554/10984  |  loss = 4.07679939\n",
            "2024-03-27 09:46:37.680363, Epoch: 1/10  |  555/10984  |  loss = 3.86882472\n",
            "2024-03-27 09:46:37.970120, Epoch: 1/10  |  556/10984  |  loss = 3.62959838\n",
            "2024-03-27 09:46:38.267373, Epoch: 1/10  |  557/10984  |  loss = 3.20644712\n",
            "2024-03-27 09:46:38.566226, Epoch: 1/10  |  558/10984  |  loss = 3.59399176\n",
            "2024-03-27 09:46:38.863029, Epoch: 1/10  |  559/10984  |  loss = 3.98872423\n",
            "2024-03-27 09:46:39.166885, Epoch: 1/10  |  560/10984  |  loss = 3.00199509\n",
            "2024-03-27 09:46:39.462143, Epoch: 1/10  |  561/10984  |  loss = 3.15866041\n",
            "2024-03-27 09:46:39.753489, Epoch: 1/10  |  562/10984  |  loss = 4.20872259\n",
            "2024-03-27 09:46:40.044825, Epoch: 1/10  |  563/10984  |  loss = 3.23389125\n",
            "2024-03-27 09:46:40.343612, Epoch: 1/10  |  564/10984  |  loss = 3.79730320\n",
            "2024-03-27 09:46:40.634452, Epoch: 1/10  |  565/10984  |  loss = 3.92426729\n",
            "2024-03-27 09:46:40.919860, Epoch: 1/10  |  566/10984  |  loss = 3.34083438\n",
            "2024-03-27 09:46:41.186365, Epoch: 1/10  |  567/10984  |  loss = 2.74774098\n",
            "2024-03-27 09:46:41.443799, Epoch: 1/10  |  568/10984  |  loss = 3.63727808\n",
            "2024-03-27 09:46:41.754406, Epoch: 1/10  |  569/10984  |  loss = 3.06552458\n",
            "2024-03-27 09:46:42.037600, Epoch: 1/10  |  570/10984  |  loss = 3.38768148\n",
            "2024-03-27 09:46:42.326479, Epoch: 1/10  |  571/10984  |  loss = 3.66720986\n",
            "2024-03-27 09:46:42.578516, Epoch: 1/10  |  572/10984  |  loss = 2.75381064\n",
            "2024-03-27 09:46:42.865456, Epoch: 1/10  |  573/10984  |  loss = 3.78171635\n",
            "2024-03-27 09:46:43.152949, Epoch: 1/10  |  574/10984  |  loss = 3.76897812\n",
            "2024-03-27 09:46:43.454831, Epoch: 1/10  |  575/10984  |  loss = 4.25592422\n",
            "2024-03-27 09:46:43.741436, Epoch: 1/10  |  576/10984  |  loss = 3.91876531\n",
            "2024-03-27 09:46:44.035852, Epoch: 1/10  |  577/10984  |  loss = 3.03409100\n",
            "2024-03-27 09:46:44.359029, Epoch: 1/10  |  578/10984  |  loss = 3.56628323\n",
            "2024-03-27 09:46:44.647656, Epoch: 1/10  |  579/10984  |  loss = 2.90363026\n",
            "2024-03-27 09:46:44.932888, Epoch: 1/10  |  580/10984  |  loss = 2.85892630\n",
            "2024-03-27 09:46:45.227802, Epoch: 1/10  |  581/10984  |  loss = 3.47788620\n",
            "2024-03-27 09:46:45.514172, Epoch: 1/10  |  582/10984  |  loss = 3.88170314\n",
            "2024-03-27 09:46:45.799995, Epoch: 1/10  |  583/10984  |  loss = 3.44299245\n",
            "2024-03-27 09:46:46.066535, Epoch: 1/10  |  584/10984  |  loss = 3.14294553\n",
            "2024-03-27 09:46:46.338616, Epoch: 1/10  |  585/10984  |  loss = 3.28297043\n",
            "2024-03-27 09:46:46.623390, Epoch: 1/10  |  586/10984  |  loss = 3.71606994\n",
            "2024-03-27 09:46:46.912255, Epoch: 1/10  |  587/10984  |  loss = 3.64980984\n",
            "2024-03-27 09:46:47.192906, Epoch: 1/10  |  588/10984  |  loss = 3.32089567\n",
            "2024-03-27 09:46:47.472947, Epoch: 1/10  |  589/10984  |  loss = 3.40676379\n",
            "2024-03-27 09:46:47.746214, Epoch: 1/10  |  590/10984  |  loss = 4.31057072\n",
            "2024-03-27 09:46:48.038507, Epoch: 1/10  |  591/10984  |  loss = 3.55801725\n",
            "2024-03-27 09:46:48.305745, Epoch: 1/10  |  592/10984  |  loss = 3.47577524\n",
            "2024-03-27 09:46:48.589950, Epoch: 1/10  |  593/10984  |  loss = 2.98011279\n",
            "2024-03-27 09:46:48.888796, Epoch: 1/10  |  594/10984  |  loss = 4.10535431\n",
            "2024-03-27 09:46:49.173205, Epoch: 1/10  |  595/10984  |  loss = 2.68657732\n",
            "2024-03-27 09:46:49.464719, Epoch: 1/10  |  596/10984  |  loss = 3.71231627\n",
            "2024-03-27 09:46:49.754450, Epoch: 1/10  |  597/10984  |  loss = 3.39894938\n",
            "2024-03-27 09:46:50.002581, Epoch: 1/10  |  598/10984  |  loss = 4.21221352\n",
            "2024-03-27 09:46:50.301368, Epoch: 1/10  |  599/10984  |  loss = 3.50999808\n",
            "2024-03-27 09:46:50.599002, Epoch: 1/10  |  600/10984  |  loss = 3.78852987\n",
            "2024-03-27 09:46:50.903886, Epoch: 1/10  |  601/10984  |  loss = 3.44032407\n",
            "2024-03-27 09:46:51.206021, Epoch: 1/10  |  602/10984  |  loss = 4.44044018\n",
            "2024-03-27 09:46:51.497621, Epoch: 1/10  |  603/10984  |  loss = 3.32691288\n",
            "2024-03-27 09:46:51.811504, Epoch: 1/10  |  604/10984  |  loss = 3.03178501\n",
            "2024-03-27 09:46:52.122334, Epoch: 1/10  |  605/10984  |  loss = 3.30053425\n",
            "2024-03-27 09:46:52.409693, Epoch: 1/10  |  606/10984  |  loss = 3.30475068\n",
            "2024-03-27 09:46:52.672342, Epoch: 1/10  |  607/10984  |  loss = 3.29735374\n",
            "2024-03-27 09:46:52.960994, Epoch: 1/10  |  608/10984  |  loss = 3.53754735\n",
            "2024-03-27 09:46:53.251960, Epoch: 1/10  |  609/10984  |  loss = 4.00915194\n",
            "2024-03-27 09:46:53.551964, Epoch: 1/10  |  610/10984  |  loss = 3.35483074\n",
            "2024-03-27 09:46:53.842151, Epoch: 1/10  |  611/10984  |  loss = 3.13202000\n",
            "2024-03-27 09:46:54.138919, Epoch: 1/10  |  612/10984  |  loss = 2.69152308\n",
            "2024-03-27 09:46:54.412315, Epoch: 1/10  |  613/10984  |  loss = 4.40665293\n",
            "2024-03-27 09:46:54.703951, Epoch: 1/10  |  614/10984  |  loss = 3.39412403\n",
            "2024-03-27 09:46:54.995743, Epoch: 1/10  |  615/10984  |  loss = 3.41457534\n",
            "2024-03-27 09:46:55.288485, Epoch: 1/10  |  616/10984  |  loss = 3.96411943\n",
            "2024-03-27 09:46:55.578587, Epoch: 1/10  |  617/10984  |  loss = 4.27661943\n",
            "2024-03-27 09:46:55.877764, Epoch: 1/10  |  618/10984  |  loss = 3.52360892\n",
            "2024-03-27 09:46:56.163301, Epoch: 1/10  |  619/10984  |  loss = 3.38260317\n",
            "2024-03-27 09:46:56.445793, Epoch: 1/10  |  620/10984  |  loss = 3.75245714\n",
            "2024-03-27 09:46:56.717056, Epoch: 1/10  |  621/10984  |  loss = 3.16294909\n",
            "2024-03-27 09:46:56.990297, Epoch: 1/10  |  622/10984  |  loss = 3.03806138\n",
            "2024-03-27 09:46:57.294702, Epoch: 1/10  |  623/10984  |  loss = 2.88162136\n",
            "2024-03-27 09:46:57.591738, Epoch: 1/10  |  624/10984  |  loss = 2.88556862\n",
            "2024-03-27 09:46:57.877718, Epoch: 1/10  |  625/10984  |  loss = 3.27921319\n",
            "2024-03-27 09:46:58.167914, Epoch: 1/10  |  626/10984  |  loss = 3.94737601\n",
            "2024-03-27 09:46:58.405903, Epoch: 1/10  |  627/10984  |  loss = 3.40200400\n",
            "2024-03-27 09:46:58.704699, Epoch: 1/10  |  628/10984  |  loss = 3.55698967\n",
            "2024-03-27 09:46:58.991441, Epoch: 1/10  |  629/10984  |  loss = 3.53678846\n",
            "2024-03-27 09:46:59.280491, Epoch: 1/10  |  630/10984  |  loss = 3.00710320\n",
            "2024-03-27 09:46:59.594327, Epoch: 1/10  |  631/10984  |  loss = 2.70080614\n",
            "2024-03-27 09:46:59.886313, Epoch: 1/10  |  632/10984  |  loss = 3.17667079\n",
            "2024-03-27 09:47:00.173865, Epoch: 1/10  |  633/10984  |  loss = 3.37627292\n",
            "2024-03-27 09:47:00.457244, Epoch: 1/10  |  634/10984  |  loss = 3.55874896\n",
            "2024-03-27 09:47:00.749206, Epoch: 1/10  |  635/10984  |  loss = 3.41879940\n",
            "2024-03-27 09:47:01.036902, Epoch: 1/10  |  636/10984  |  loss = 3.49720001\n",
            "2024-03-27 09:47:01.332216, Epoch: 1/10  |  637/10984  |  loss = 3.01861906\n",
            "2024-03-27 09:47:01.621885, Epoch: 1/10  |  638/10984  |  loss = 3.62666988\n",
            "2024-03-27 09:47:01.907802, Epoch: 1/10  |  639/10984  |  loss = 3.98962641\n",
            "2024-03-27 09:47:02.204842, Epoch: 1/10  |  640/10984  |  loss = 3.32403731\n",
            "2024-03-27 09:47:02.497022, Epoch: 1/10  |  641/10984  |  loss = 3.64019060\n",
            "2024-03-27 09:47:02.780210, Epoch: 1/10  |  642/10984  |  loss = 3.87861204\n",
            "2024-03-27 09:47:03.067323, Epoch: 1/10  |  643/10984  |  loss = 3.15861082\n",
            "2024-03-27 09:47:03.358972, Epoch: 1/10  |  644/10984  |  loss = 3.33795762\n",
            "2024-03-27 09:47:03.647383, Epoch: 1/10  |  645/10984  |  loss = 3.67535281\n",
            "2024-03-27 09:47:03.933604, Epoch: 1/10  |  646/10984  |  loss = 3.69403458\n",
            "2024-03-27 09:47:04.238984, Epoch: 1/10  |  647/10984  |  loss = 3.03371477\n",
            "2024-03-27 09:47:04.534961, Epoch: 1/10  |  648/10984  |  loss = 3.46103096\n",
            "2024-03-27 09:47:04.829245, Epoch: 1/10  |  649/10984  |  loss = 3.22774625\n",
            "2024-03-27 09:47:05.122730, Epoch: 1/10  |  650/10984  |  loss = 3.37819386\n",
            "2024-03-27 09:47:05.419642, Epoch: 1/10  |  651/10984  |  loss = 3.56105781\n",
            "2024-03-27 09:47:05.723773, Epoch: 1/10  |  652/10984  |  loss = 3.15788722\n",
            "2024-03-27 09:47:06.018099, Epoch: 1/10  |  653/10984  |  loss = 3.25713396\n",
            "2024-03-27 09:47:06.306694, Epoch: 1/10  |  654/10984  |  loss = 3.30083179\n",
            "2024-03-27 09:47:06.607271, Epoch: 1/10  |  655/10984  |  loss = 3.60593653\n",
            "2024-03-27 09:47:06.884288, Epoch: 1/10  |  656/10984  |  loss = 3.51751757\n",
            "2024-03-27 09:47:07.146801, Epoch: 1/10  |  657/10984  |  loss = 3.88594747\n",
            "2024-03-27 09:47:07.452683, Epoch: 1/10  |  658/10984  |  loss = 2.82469225\n",
            "2024-03-27 09:47:07.745236, Epoch: 1/10  |  659/10984  |  loss = 3.88474989\n",
            "2024-03-27 09:47:08.039403, Epoch: 1/10  |  660/10984  |  loss = 3.14356732\n",
            "2024-03-27 09:47:08.292167, Epoch: 1/10  |  661/10984  |  loss = 3.16266465\n",
            "2024-03-27 09:47:08.598553, Epoch: 1/10  |  662/10984  |  loss = 3.97251201\n",
            "2024-03-27 09:47:08.889591, Epoch: 1/10  |  663/10984  |  loss = 3.51348662\n",
            "2024-03-27 09:47:09.176151, Epoch: 1/10  |  664/10984  |  loss = 3.46370173\n",
            "2024-03-27 09:47:09.465843, Epoch: 1/10  |  665/10984  |  loss = 3.36525512\n",
            "2024-03-27 09:47:09.748220, Epoch: 1/10  |  666/10984  |  loss = 3.62226534\n",
            "2024-03-27 09:47:10.029652, Epoch: 1/10  |  667/10984  |  loss = 3.90082002\n",
            "2024-03-27 09:47:10.316715, Epoch: 1/10  |  668/10984  |  loss = 3.51913714\n",
            "2024-03-27 09:47:10.603925, Epoch: 1/10  |  669/10984  |  loss = 3.63408303\n",
            "2024-03-27 09:47:10.865550, Epoch: 1/10  |  670/10984  |  loss = 2.94468451\n",
            "2024-03-27 09:47:11.158704, Epoch: 1/10  |  671/10984  |  loss = 3.88981771\n",
            "2024-03-27 09:47:11.452722, Epoch: 1/10  |  672/10984  |  loss = 3.10120559\n",
            "2024-03-27 09:47:11.741760, Epoch: 1/10  |  673/10984  |  loss = 4.01903152\n",
            "2024-03-27 09:47:12.040775, Epoch: 1/10  |  674/10984  |  loss = 3.75307369\n",
            "2024-03-27 09:47:12.334419, Epoch: 1/10  |  675/10984  |  loss = 3.48867202\n",
            "2024-03-27 09:47:12.616854, Epoch: 1/10  |  676/10984  |  loss = 3.11733079\n",
            "2024-03-27 09:47:12.908999, Epoch: 1/10  |  677/10984  |  loss = 3.41412139\n",
            "2024-03-27 09:47:13.194816, Epoch: 1/10  |  678/10984  |  loss = 3.49903154\n",
            "2024-03-27 09:47:13.480423, Epoch: 1/10  |  679/10984  |  loss = 3.26915860\n",
            "2024-03-27 09:47:13.778616, Epoch: 1/10  |  680/10984  |  loss = 3.17071104\n",
            "2024-03-27 09:47:14.044674, Epoch: 1/10  |  681/10984  |  loss = 3.09291577\n",
            "2024-03-27 09:47:14.350734, Epoch: 1/10  |  682/10984  |  loss = 3.18333483\n",
            "2024-03-27 09:47:14.621599, Epoch: 1/10  |  683/10984  |  loss = 3.69532228\n",
            "2024-03-27 09:47:14.917573, Epoch: 1/10  |  684/10984  |  loss = 3.33872557\n",
            "2024-03-27 09:47:15.204148, Epoch: 1/10  |  685/10984  |  loss = 3.90257287\n",
            "2024-03-27 09:47:15.498623, Epoch: 1/10  |  686/10984  |  loss = 2.78058052\n",
            "2024-03-27 09:47:15.791787, Epoch: 1/10  |  687/10984  |  loss = 3.55810976\n",
            "2024-03-27 09:47:16.080232, Epoch: 1/10  |  688/10984  |  loss = 4.07867289\n",
            "2024-03-27 09:47:16.367747, Epoch: 1/10  |  689/10984  |  loss = 3.51535630\n",
            "2024-03-27 09:47:16.661965, Epoch: 1/10  |  690/10984  |  loss = 2.79525065\n",
            "2024-03-27 09:47:16.965767, Epoch: 1/10  |  691/10984  |  loss = 3.32961750\n",
            "2024-03-27 09:47:17.267906, Epoch: 1/10  |  692/10984  |  loss = 4.23623610\n",
            "2024-03-27 09:47:17.564286, Epoch: 1/10  |  693/10984  |  loss = 4.54167128\n",
            "2024-03-27 09:47:17.848617, Epoch: 1/10  |  694/10984  |  loss = 3.52357173\n",
            "2024-03-27 09:47:18.149514, Epoch: 1/10  |  695/10984  |  loss = 3.37508154\n",
            "2024-03-27 09:47:18.439206, Epoch: 1/10  |  696/10984  |  loss = 3.86302614\n",
            "2024-03-27 09:47:18.728970, Epoch: 1/10  |  697/10984  |  loss = 3.19155860\n",
            "2024-03-27 09:47:19.032507, Epoch: 1/10  |  698/10984  |  loss = 3.65188313\n",
            "2024-03-27 09:47:19.330380, Epoch: 1/10  |  699/10984  |  loss = 4.03214073\n",
            "2024-03-27 09:47:19.628781, Epoch: 1/10  |  700/10984  |  loss = 3.19393611\n",
            "2024-03-27 09:47:19.933807, Epoch: 1/10  |  701/10984  |  loss = 3.95982099\n",
            "2024-03-27 09:47:20.227004, Epoch: 1/10  |  702/10984  |  loss = 3.36271954\n",
            "2024-03-27 09:47:20.526458, Epoch: 1/10  |  703/10984  |  loss = 3.61108088\n",
            "2024-03-27 09:47:20.820029, Epoch: 1/10  |  704/10984  |  loss = 3.23100519\n",
            "2024-03-27 09:47:21.120605, Epoch: 1/10  |  705/10984  |  loss = 3.13726711\n",
            "2024-03-27 09:47:21.422304, Epoch: 1/10  |  706/10984  |  loss = 2.79204869\n",
            "2024-03-27 09:47:21.712244, Epoch: 1/10  |  707/10984  |  loss = 3.35203457\n",
            "2024-03-27 09:47:22.005993, Epoch: 1/10  |  708/10984  |  loss = 3.31876683\n",
            "2024-03-27 09:47:22.301878, Epoch: 1/10  |  709/10984  |  loss = 3.41449618\n",
            "2024-03-27 09:47:22.571450, Epoch: 1/10  |  710/10984  |  loss = 3.17774367\n",
            "2024-03-27 09:47:22.868781, Epoch: 1/10  |  711/10984  |  loss = 3.60624719\n",
            "2024-03-27 09:47:23.158158, Epoch: 1/10  |  712/10984  |  loss = 3.63273001\n",
            "2024-03-27 09:47:23.443936, Epoch: 1/10  |  713/10984  |  loss = 3.76110411\n",
            "2024-03-27 09:47:23.735093, Epoch: 1/10  |  714/10984  |  loss = 3.42159510\n",
            "2024-03-27 09:47:24.022253, Epoch: 1/10  |  715/10984  |  loss = 3.24120092\n",
            "2024-03-27 09:47:24.312373, Epoch: 1/10  |  716/10984  |  loss = 3.73036599\n",
            "2024-03-27 09:47:24.597319, Epoch: 1/10  |  717/10984  |  loss = 4.08516741\n",
            "2024-03-27 09:47:24.877064, Epoch: 1/10  |  718/10984  |  loss = 3.09512353\n",
            "2024-03-27 09:47:25.180448, Epoch: 1/10  |  719/10984  |  loss = 3.60495353\n",
            "2024-03-27 09:47:25.483886, Epoch: 1/10  |  720/10984  |  loss = 3.03282356\n",
            "2024-03-27 09:47:25.737682, Epoch: 1/10  |  721/10984  |  loss = 3.31156564\n",
            "2024-03-27 09:47:26.042234, Epoch: 1/10  |  722/10984  |  loss = 3.28382850\n",
            "2024-03-27 09:47:26.331346, Epoch: 1/10  |  723/10984  |  loss = 3.74062252\n",
            "2024-03-27 09:47:26.594613, Epoch: 1/10  |  724/10984  |  loss = 3.19565940\n",
            "2024-03-27 09:47:26.882758, Epoch: 1/10  |  725/10984  |  loss = 3.30144954\n",
            "2024-03-27 09:47:27.147250, Epoch: 1/10  |  726/10984  |  loss = 2.47601247\n",
            "2024-03-27 09:47:27.437797, Epoch: 1/10  |  727/10984  |  loss = 3.53822994\n",
            "2024-03-27 09:47:27.688596, Epoch: 1/10  |  728/10984  |  loss = 3.96118689\n",
            "2024-03-27 09:47:27.980786, Epoch: 1/10  |  729/10984  |  loss = 3.52513766\n",
            "2024-03-27 09:47:28.276409, Epoch: 1/10  |  730/10984  |  loss = 2.62586951\n",
            "2024-03-27 09:47:28.565690, Epoch: 1/10  |  731/10984  |  loss = 3.88476014\n",
            "2024-03-27 09:47:28.847420, Epoch: 1/10  |  732/10984  |  loss = 3.36302185\n",
            "2024-03-27 09:47:29.142538, Epoch: 1/10  |  733/10984  |  loss = 3.63303995\n",
            "2024-03-27 09:47:29.439291, Epoch: 1/10  |  734/10984  |  loss = 3.82029057\n",
            "2024-03-27 09:47:29.735559, Epoch: 1/10  |  735/10984  |  loss = 3.55857348\n",
            "2024-03-27 09:47:30.039360, Epoch: 1/10  |  736/10984  |  loss = 3.28299189\n",
            "2024-03-27 09:47:30.346474, Epoch: 1/10  |  737/10984  |  loss = 3.54529476\n",
            "2024-03-27 09:47:30.666855, Epoch: 1/10  |  738/10984  |  loss = 3.52786446\n",
            "2024-03-27 09:47:30.964535, Epoch: 1/10  |  739/10984  |  loss = 3.66205907\n",
            "2024-03-27 09:47:31.268083, Epoch: 1/10  |  740/10984  |  loss = 4.12011862\n",
            "2024-03-27 09:47:31.563498, Epoch: 1/10  |  741/10984  |  loss = 3.55742431\n",
            "2024-03-27 09:47:31.861254, Epoch: 1/10  |  742/10984  |  loss = 3.21568632\n",
            "2024-03-27 09:47:32.152017, Epoch: 1/10  |  743/10984  |  loss = 3.36060905\n",
            "2024-03-27 09:47:32.443066, Epoch: 1/10  |  744/10984  |  loss = 3.07319689\n",
            "2024-03-27 09:47:32.730172, Epoch: 1/10  |  745/10984  |  loss = 3.29074240\n",
            "2024-03-27 09:47:33.017129, Epoch: 1/10  |  746/10984  |  loss = 3.28024459\n",
            "2024-03-27 09:47:33.302441, Epoch: 1/10  |  747/10984  |  loss = 2.72854733\n",
            "2024-03-27 09:47:33.596415, Epoch: 1/10  |  748/10984  |  loss = 3.00889468\n",
            "2024-03-27 09:47:33.876468, Epoch: 1/10  |  749/10984  |  loss = 3.10515237\n",
            "2024-03-27 09:47:34.150991, Epoch: 1/10  |  750/10984  |  loss = 3.67427802\n",
            "2024-03-27 09:47:34.454577, Epoch: 1/10  |  751/10984  |  loss = 3.33058667\n",
            "2024-03-27 09:47:34.748572, Epoch: 1/10  |  752/10984  |  loss = 3.89343977\n",
            "2024-03-27 09:47:35.037126, Epoch: 1/10  |  753/10984  |  loss = 3.60535765\n",
            "2024-03-27 09:47:35.314856, Epoch: 1/10  |  754/10984  |  loss = 3.46854329\n",
            "2024-03-27 09:47:35.604997, Epoch: 1/10  |  755/10984  |  loss = 3.68309474\n",
            "2024-03-27 09:47:35.889307, Epoch: 1/10  |  756/10984  |  loss = 3.52538395\n",
            "2024-03-27 09:47:36.159269, Epoch: 1/10  |  757/10984  |  loss = 4.02198982\n",
            "2024-03-27 09:47:36.450259, Epoch: 1/10  |  758/10984  |  loss = 3.40403938\n",
            "2024-03-27 09:47:36.738574, Epoch: 1/10  |  759/10984  |  loss = 3.39475894\n",
            "2024-03-27 09:47:37.019628, Epoch: 1/10  |  760/10984  |  loss = 3.46218014\n",
            "2024-03-27 09:47:37.306489, Epoch: 1/10  |  761/10984  |  loss = 3.23976970\n",
            "2024-03-27 09:47:37.606191, Epoch: 1/10  |  762/10984  |  loss = 2.74212933\n",
            "2024-03-27 09:47:37.888552, Epoch: 1/10  |  763/10984  |  loss = 4.02412271\n",
            "2024-03-27 09:47:38.176809, Epoch: 1/10  |  764/10984  |  loss = 3.73652864\n",
            "2024-03-27 09:47:38.375740, Epoch: 1/10  |  765/10984  |  loss = 3.32555747\n",
            "2024-03-27 09:47:38.628439, Epoch: 1/10  |  766/10984  |  loss = 3.91617274\n",
            "2024-03-27 09:47:38.921880, Epoch: 1/10  |  767/10984  |  loss = 3.50885439\n",
            "2024-03-27 09:47:39.207405, Epoch: 1/10  |  768/10984  |  loss = 3.31808639\n",
            "2024-03-27 09:47:39.495133, Epoch: 1/10  |  769/10984  |  loss = 4.06321859\n",
            "2024-03-27 09:47:39.767049, Epoch: 1/10  |  770/10984  |  loss = 3.13645482\n",
            "2024-03-27 09:47:40.053811, Epoch: 1/10  |  771/10984  |  loss = 3.39776134\n",
            "2024-03-27 09:47:40.347399, Epoch: 1/10  |  772/10984  |  loss = 3.50022435\n",
            "2024-03-27 09:47:40.642067, Epoch: 1/10  |  773/10984  |  loss = 2.83321571\n",
            "2024-03-27 09:47:40.927712, Epoch: 1/10  |  774/10984  |  loss = 3.96574068\n",
            "2024-03-27 09:47:41.219420, Epoch: 1/10  |  775/10984  |  loss = 2.75091314\n",
            "2024-03-27 09:47:41.509830, Epoch: 1/10  |  776/10984  |  loss = 3.30662251\n",
            "2024-03-27 09:47:41.790123, Epoch: 1/10  |  777/10984  |  loss = 3.18892241\n",
            "2024-03-27 09:47:42.091161, Epoch: 1/10  |  778/10984  |  loss = 2.96020436\n",
            "2024-03-27 09:47:42.387382, Epoch: 1/10  |  779/10984  |  loss = 3.37589526\n",
            "2024-03-27 09:47:42.691559, Epoch: 1/10  |  780/10984  |  loss = 3.62023830\n",
            "2024-03-27 09:47:42.996503, Epoch: 1/10  |  781/10984  |  loss = 3.14422393\n",
            "2024-03-27 09:47:43.288167, Epoch: 1/10  |  782/10984  |  loss = 3.69497848\n",
            "2024-03-27 09:47:43.572411, Epoch: 1/10  |  783/10984  |  loss = 3.43199825\n",
            "2024-03-27 09:47:43.862921, Epoch: 1/10  |  784/10984  |  loss = 3.17534852\n",
            "2024-03-27 09:47:44.166025, Epoch: 1/10  |  785/10984  |  loss = 3.41371202\n",
            "2024-03-27 09:47:44.472264, Epoch: 1/10  |  786/10984  |  loss = 3.59269762\n",
            "2024-03-27 09:47:44.758888, Epoch: 1/10  |  787/10984  |  loss = 3.27711725\n",
            "2024-03-27 09:47:45.047794, Epoch: 1/10  |  788/10984  |  loss = 3.07578373\n",
            "2024-03-27 09:47:45.300650, Epoch: 1/10  |  789/10984  |  loss = 3.23492122\n",
            "2024-03-27 09:47:45.605585, Epoch: 1/10  |  790/10984  |  loss = 3.33626175\n",
            "2024-03-27 09:47:45.897244, Epoch: 1/10  |  791/10984  |  loss = 3.12090802\n",
            "2024-03-27 09:47:46.179959, Epoch: 1/10  |  792/10984  |  loss = 3.47061229\n",
            "2024-03-27 09:47:46.455496, Epoch: 1/10  |  793/10984  |  loss = 2.89321399\n",
            "2024-03-27 09:47:46.740568, Epoch: 1/10  |  794/10984  |  loss = 4.24234772\n",
            "2024-03-27 09:47:47.053904, Epoch: 1/10  |  795/10984  |  loss = 2.55541086\n",
            "2024-03-27 09:47:47.319184, Epoch: 1/10  |  796/10984  |  loss = 3.09229040\n",
            "2024-03-27 09:47:47.607241, Epoch: 1/10  |  797/10984  |  loss = 3.28683186\n",
            "2024-03-27 09:47:47.899914, Epoch: 1/10  |  798/10984  |  loss = 3.31291342\n",
            "2024-03-27 09:47:48.156011, Epoch: 1/10  |  799/10984  |  loss = 3.64980102\n",
            "2024-03-27 09:47:48.423667, Epoch: 1/10  |  800/10984  |  loss = 3.24143553\n",
            "2024-03-27 09:47:48.708079, Epoch: 1/10  |  801/10984  |  loss = 3.31456399\n",
            "2024-03-27 09:47:48.996935, Epoch: 1/10  |  802/10984  |  loss = 2.95034361\n",
            "2024-03-27 09:47:49.283246, Epoch: 1/10  |  803/10984  |  loss = 3.49386168\n",
            "2024-03-27 09:47:49.578360, Epoch: 1/10  |  804/10984  |  loss = 3.13195467\n",
            "2024-03-27 09:47:49.856259, Epoch: 1/10  |  805/10984  |  loss = 3.36404085\n",
            "2024-03-27 09:47:50.082961, Epoch: 1/10  |  806/10984  |  loss = 3.60178161\n",
            "2024-03-27 09:47:50.377582, Epoch: 1/10  |  807/10984  |  loss = 3.72731805\n",
            "2024-03-27 09:47:50.665133, Epoch: 1/10  |  808/10984  |  loss = 3.21069145\n",
            "2024-03-27 09:47:50.953681, Epoch: 1/10  |  809/10984  |  loss = 3.32654190\n",
            "2024-03-27 09:47:51.220587, Epoch: 1/10  |  810/10984  |  loss = 3.24604416\n",
            "2024-03-27 09:47:51.528810, Epoch: 1/10  |  811/10984  |  loss = 2.87902164\n",
            "2024-03-27 09:47:51.786641, Epoch: 1/10  |  812/10984  |  loss = 3.94111681\n",
            "2024-03-27 09:47:52.043236, Epoch: 1/10  |  813/10984  |  loss = 3.86145854\n",
            "2024-03-27 09:47:52.339307, Epoch: 1/10  |  814/10984  |  loss = 3.31745434\n",
            "2024-03-27 09:47:52.638733, Epoch: 1/10  |  815/10984  |  loss = 4.00097132\n",
            "2024-03-27 09:47:52.946982, Epoch: 1/10  |  816/10984  |  loss = 3.09562182\n",
            "2024-03-27 09:47:53.225882, Epoch: 1/10  |  817/10984  |  loss = 3.42659736\n",
            "2024-03-27 09:47:53.506863, Epoch: 1/10  |  818/10984  |  loss = 3.40708876\n",
            "2024-03-27 09:47:53.796047, Epoch: 1/10  |  819/10984  |  loss = 3.44257998\n",
            "2024-03-27 09:47:54.099441, Epoch: 1/10  |  820/10984  |  loss = 3.17429352\n",
            "2024-03-27 09:47:54.382126, Epoch: 1/10  |  821/10984  |  loss = 3.76504731\n",
            "2024-03-27 09:47:54.670478, Epoch: 1/10  |  822/10984  |  loss = 4.00039673\n",
            "2024-03-27 09:47:54.957826, Epoch: 1/10  |  823/10984  |  loss = 3.68625927\n",
            "2024-03-27 09:47:55.255512, Epoch: 1/10  |  824/10984  |  loss = 3.36036205\n",
            "2024-03-27 09:47:55.558632, Epoch: 1/10  |  825/10984  |  loss = 3.53363657\n",
            "2024-03-27 09:47:55.845757, Epoch: 1/10  |  826/10984  |  loss = 3.37506247\n",
            "2024-03-27 09:47:56.089717, Epoch: 1/10  |  827/10984  |  loss = 3.61661673\n",
            "2024-03-27 09:47:56.374157, Epoch: 1/10  |  828/10984  |  loss = 3.17765784\n",
            "2024-03-27 09:47:56.671947, Epoch: 1/10  |  829/10984  |  loss = 3.37170768\n",
            "2024-03-27 09:47:56.968024, Epoch: 1/10  |  830/10984  |  loss = 3.07461429\n",
            "2024-03-27 09:47:57.256816, Epoch: 1/10  |  831/10984  |  loss = 3.65454340\n",
            "2024-03-27 09:47:57.560456, Epoch: 1/10  |  832/10984  |  loss = 3.16391873\n",
            "2024-03-27 09:47:57.862346, Epoch: 1/10  |  833/10984  |  loss = 2.87420201\n",
            "2024-03-27 09:47:58.125421, Epoch: 1/10  |  834/10984  |  loss = 3.27988863\n",
            "2024-03-27 09:47:58.426321, Epoch: 1/10  |  835/10984  |  loss = 2.73157859\n",
            "2024-03-27 09:47:58.703565, Epoch: 1/10  |  836/10984  |  loss = 3.37348747\n",
            "2024-03-27 09:47:58.993774, Epoch: 1/10  |  837/10984  |  loss = 3.31279707\n",
            "2024-03-27 09:47:59.288427, Epoch: 1/10  |  838/10984  |  loss = 3.71845388\n",
            "2024-03-27 09:47:59.578088, Epoch: 1/10  |  839/10984  |  loss = 3.10844707\n",
            "2024-03-27 09:47:59.858705, Epoch: 1/10  |  840/10984  |  loss = 3.38855791\n",
            "2024-03-27 09:48:00.150164, Epoch: 1/10  |  841/10984  |  loss = 2.82558370\n",
            "2024-03-27 09:48:00.436448, Epoch: 1/10  |  842/10984  |  loss = 3.99862623\n",
            "2024-03-27 09:48:00.727744, Epoch: 1/10  |  843/10984  |  loss = 2.73006630\n",
            "2024-03-27 09:48:00.987983, Epoch: 1/10  |  844/10984  |  loss = 2.81756258\n",
            "2024-03-27 09:48:01.275406, Epoch: 1/10  |  845/10984  |  loss = 3.42300296\n",
            "2024-03-27 09:48:01.561183, Epoch: 1/10  |  846/10984  |  loss = 3.24246216\n",
            "2024-03-27 09:48:01.852434, Epoch: 1/10  |  847/10984  |  loss = 3.54481006\n",
            "2024-03-27 09:48:02.138469, Epoch: 1/10  |  848/10984  |  loss = 3.94495416\n",
            "2024-03-27 09:48:02.421135, Epoch: 1/10  |  849/10984  |  loss = 4.11526394\n",
            "2024-03-27 09:48:02.684566, Epoch: 1/10  |  850/10984  |  loss = 3.37305021\n",
            "2024-03-27 09:48:02.979088, Epoch: 1/10  |  851/10984  |  loss = 3.20111370\n",
            "2024-03-27 09:48:03.265306, Epoch: 1/10  |  852/10984  |  loss = 3.57690215\n",
            "2024-03-27 09:48:03.507134, Epoch: 1/10  |  853/10984  |  loss = 3.20294118\n",
            "2024-03-27 09:48:03.797816, Epoch: 1/10  |  854/10984  |  loss = 2.96356344\n",
            "2024-03-27 09:48:04.080967, Epoch: 1/10  |  855/10984  |  loss = 3.36791515\n",
            "2024-03-27 09:48:04.371076, Epoch: 1/10  |  856/10984  |  loss = 3.70123696\n",
            "2024-03-27 09:48:04.662672, Epoch: 1/10  |  857/10984  |  loss = 3.29251719\n",
            "2024-03-27 09:48:04.937248, Epoch: 1/10  |  858/10984  |  loss = 3.41146684\n",
            "2024-03-27 09:48:05.236082, Epoch: 1/10  |  859/10984  |  loss = 2.93478799\n",
            "2024-03-27 09:48:05.535189, Epoch: 1/10  |  860/10984  |  loss = 2.52960610\n",
            "2024-03-27 09:48:05.814386, Epoch: 1/10  |  861/10984  |  loss = 3.30192828\n",
            "2024-03-27 09:48:06.073587, Epoch: 1/10  |  862/10984  |  loss = 3.62090826\n",
            "2024-03-27 09:48:06.366432, Epoch: 1/10  |  863/10984  |  loss = 3.32621956\n",
            "2024-03-27 09:48:06.624210, Epoch: 1/10  |  864/10984  |  loss = 3.42300248\n",
            "2024-03-27 09:48:06.905959, Epoch: 1/10  |  865/10984  |  loss = 3.86137652\n",
            "2024-03-27 09:48:07.192793, Epoch: 1/10  |  866/10984  |  loss = 3.82041049\n",
            "2024-03-27 09:48:07.493061, Epoch: 1/10  |  867/10984  |  loss = 2.65628695\n",
            "2024-03-27 09:48:07.778047, Epoch: 1/10  |  868/10984  |  loss = 3.22731328\n",
            "2024-03-27 09:48:08.082024, Epoch: 1/10  |  869/10984  |  loss = 3.07127666\n",
            "2024-03-27 09:48:08.329682, Epoch: 1/10  |  870/10984  |  loss = 3.47562742\n",
            "2024-03-27 09:48:08.630850, Epoch: 1/10  |  871/10984  |  loss = 3.64285159\n",
            "2024-03-27 09:48:08.925115, Epoch: 1/10  |  872/10984  |  loss = 3.46417832\n",
            "2024-03-27 09:48:09.218850, Epoch: 1/10  |  873/10984  |  loss = 3.26259971\n",
            "2024-03-27 09:48:09.523286, Epoch: 1/10  |  874/10984  |  loss = 4.02959347\n",
            "2024-03-27 09:48:09.811330, Epoch: 1/10  |  875/10984  |  loss = 3.91602898\n",
            "2024-03-27 09:48:10.111572, Epoch: 1/10  |  876/10984  |  loss = 2.99383330\n",
            "2024-03-27 09:48:10.412488, Epoch: 1/10  |  877/10984  |  loss = 3.11002731\n",
            "2024-03-27 09:48:10.653598, Epoch: 1/10  |  878/10984  |  loss = 2.99099541\n",
            "2024-03-27 09:48:10.950561, Epoch: 1/10  |  879/10984  |  loss = 3.14285183\n",
            "2024-03-27 09:48:11.251804, Epoch: 1/10  |  880/10984  |  loss = 3.03252244\n",
            "2024-03-27 09:48:11.533584, Epoch: 1/10  |  881/10984  |  loss = 3.58518004\n",
            "2024-03-27 09:48:11.820425, Epoch: 1/10  |  882/10984  |  loss = 3.46376634\n",
            "2024-03-27 09:48:12.114307, Epoch: 1/10  |  883/10984  |  loss = 3.93695951\n",
            "2024-03-27 09:48:12.364680, Epoch: 1/10  |  884/10984  |  loss = 3.39792800\n",
            "2024-03-27 09:48:12.645858, Epoch: 1/10  |  885/10984  |  loss = 4.21608543\n",
            "2024-03-27 09:48:12.942750, Epoch: 1/10  |  886/10984  |  loss = 2.89081025\n",
            "2024-03-27 09:48:13.233418, Epoch: 1/10  |  887/10984  |  loss = 3.77786040\n",
            "2024-03-27 09:48:13.520886, Epoch: 1/10  |  888/10984  |  loss = 3.28130698\n",
            "2024-03-27 09:48:13.803471, Epoch: 1/10  |  889/10984  |  loss = 3.31546903\n",
            "2024-03-27 09:48:14.094947, Epoch: 1/10  |  890/10984  |  loss = 3.79464602\n",
            "2024-03-27 09:48:14.379460, Epoch: 1/10  |  891/10984  |  loss = 3.24577069\n",
            "2024-03-27 09:48:14.661799, Epoch: 1/10  |  892/10984  |  loss = 3.49590540\n",
            "2024-03-27 09:48:14.945897, Epoch: 1/10  |  893/10984  |  loss = 3.03311729\n",
            "2024-03-27 09:48:15.210046, Epoch: 1/10  |  894/10984  |  loss = 3.48981404\n",
            "2024-03-27 09:48:15.469932, Epoch: 1/10  |  895/10984  |  loss = 2.68326473\n",
            "2024-03-27 09:48:15.774524, Epoch: 1/10  |  896/10984  |  loss = 2.88253450\n",
            "2024-03-27 09:48:16.065088, Epoch: 1/10  |  897/10984  |  loss = 3.95663977\n",
            "2024-03-27 09:48:16.325792, Epoch: 1/10  |  898/10984  |  loss = 2.80944443\n",
            "2024-03-27 09:48:16.599885, Epoch: 1/10  |  899/10984  |  loss = 3.54143667\n",
            "2024-03-27 09:48:16.856166, Epoch: 1/10  |  900/10984  |  loss = 3.28766489\n",
            "2024-03-27 09:48:17.138840, Epoch: 1/10  |  901/10984  |  loss = 2.69333482\n",
            "2024-03-27 09:48:17.429699, Epoch: 1/10  |  902/10984  |  loss = 3.31867766\n",
            "2024-03-27 09:48:17.679394, Epoch: 1/10  |  903/10984  |  loss = 2.72999430\n",
            "2024-03-27 09:48:17.961343, Epoch: 1/10  |  904/10984  |  loss = 2.85851836\n",
            "2024-03-27 09:48:18.253395, Epoch: 1/10  |  905/10984  |  loss = 2.69825244\n",
            "2024-03-27 09:48:18.536962, Epoch: 1/10  |  906/10984  |  loss = 2.94032001\n",
            "2024-03-27 09:48:18.834617, Epoch: 1/10  |  907/10984  |  loss = 2.72034240\n",
            "2024-03-27 09:48:19.117738, Epoch: 1/10  |  908/10984  |  loss = 3.85425282\n",
            "2024-03-27 09:48:19.398061, Epoch: 1/10  |  909/10984  |  loss = 3.52460146\n",
            "2024-03-27 09:48:19.691852, Epoch: 1/10  |  910/10984  |  loss = 3.32609677\n",
            "2024-03-27 09:48:19.973095, Epoch: 1/10  |  911/10984  |  loss = 3.48521638\n",
            "2024-03-27 09:48:20.250011, Epoch: 1/10  |  912/10984  |  loss = 3.19335628\n",
            "2024-03-27 09:48:20.548904, Epoch: 1/10  |  913/10984  |  loss = 3.67181873\n",
            "2024-03-27 09:48:20.859071, Epoch: 1/10  |  914/10984  |  loss = 2.86478519\n",
            "2024-03-27 09:48:21.150407, Epoch: 1/10  |  915/10984  |  loss = 3.05198836\n",
            "2024-03-27 09:48:21.449962, Epoch: 1/10  |  916/10984  |  loss = 3.41238594\n",
            "2024-03-27 09:48:21.748526, Epoch: 1/10  |  917/10984  |  loss = 3.44526243\n",
            "2024-03-27 09:48:22.042574, Epoch: 1/10  |  918/10984  |  loss = 3.84879637\n",
            "2024-03-27 09:48:22.319607, Epoch: 1/10  |  919/10984  |  loss = 3.07183456\n",
            "2024-03-27 09:48:22.616739, Epoch: 1/10  |  920/10984  |  loss = 2.54339051\n",
            "2024-03-27 09:48:22.916859, Epoch: 1/10  |  921/10984  |  loss = 3.50991106\n",
            "2024-03-27 09:48:23.213415, Epoch: 1/10  |  922/10984  |  loss = 3.80209327\n",
            "2024-03-27 09:48:23.514051, Epoch: 1/10  |  923/10984  |  loss = 3.97772980\n",
            "2024-03-27 09:48:23.796798, Epoch: 1/10  |  924/10984  |  loss = 3.20390940\n",
            "2024-03-27 09:48:24.086135, Epoch: 1/10  |  925/10984  |  loss = 3.24338102\n",
            "2024-03-27 09:48:24.382385, Epoch: 1/10  |  926/10984  |  loss = 3.29347634\n",
            "2024-03-27 09:48:24.683075, Epoch: 1/10  |  927/10984  |  loss = 3.37051558\n",
            "2024-03-27 09:48:24.968895, Epoch: 1/10  |  928/10984  |  loss = 3.20724487\n",
            "2024-03-27 09:48:25.270741, Epoch: 1/10  |  929/10984  |  loss = 2.79031062\n",
            "2024-03-27 09:48:25.548660, Epoch: 1/10  |  930/10984  |  loss = 3.20544481\n",
            "2024-03-27 09:48:25.849631, Epoch: 1/10  |  931/10984  |  loss = 2.95530534\n",
            "2024-03-27 09:48:26.116897, Epoch: 1/10  |  932/10984  |  loss = 2.71012926\n",
            "2024-03-27 09:48:26.401627, Epoch: 1/10  |  933/10984  |  loss = 3.11899042\n",
            "2024-03-27 09:48:26.687867, Epoch: 1/10  |  934/10984  |  loss = 3.46993685\n",
            "2024-03-27 09:48:26.982329, Epoch: 1/10  |  935/10984  |  loss = 2.99973559\n",
            "2024-03-27 09:48:27.260165, Epoch: 1/10  |  936/10984  |  loss = 4.43414497\n",
            "2024-03-27 09:48:27.544982, Epoch: 1/10  |  937/10984  |  loss = 3.01737070\n",
            "2024-03-27 09:48:27.830910, Epoch: 1/10  |  938/10984  |  loss = 4.27219677\n",
            "2024-03-27 09:48:28.116938, Epoch: 1/10  |  939/10984  |  loss = 3.77304173\n",
            "2024-03-27 09:48:28.415987, Epoch: 1/10  |  940/10984  |  loss = 3.10294914\n",
            "2024-03-27 09:48:28.683593, Epoch: 1/10  |  941/10984  |  loss = 3.18831205\n",
            "2024-03-27 09:48:28.964209, Epoch: 1/10  |  942/10984  |  loss = 3.33213949\n",
            "2024-03-27 09:48:29.245410, Epoch: 1/10  |  943/10984  |  loss = 3.35984445\n",
            "2024-03-27 09:48:29.537003, Epoch: 1/10  |  944/10984  |  loss = 3.60197711\n",
            "2024-03-27 09:48:29.810912, Epoch: 1/10  |  945/10984  |  loss = 3.35395885\n",
            "2024-03-27 09:48:30.108047, Epoch: 1/10  |  946/10984  |  loss = 3.08845758\n",
            "2024-03-27 09:48:30.397756, Epoch: 1/10  |  947/10984  |  loss = 3.44730830\n",
            "2024-03-27 09:48:30.684045, Epoch: 1/10  |  948/10984  |  loss = 2.84637284\n",
            "2024-03-27 09:48:30.975594, Epoch: 1/10  |  949/10984  |  loss = 2.91923547\n",
            "2024-03-27 09:48:31.241767, Epoch: 1/10  |  950/10984  |  loss = 2.60415292\n",
            "2024-03-27 09:48:31.529525, Epoch: 1/10  |  951/10984  |  loss = 3.80287743\n",
            "2024-03-27 09:48:31.799838, Epoch: 1/10  |  952/10984  |  loss = 3.07891250\n",
            "2024-03-27 09:48:32.088122, Epoch: 1/10  |  953/10984  |  loss = 3.37492919\n",
            "2024-03-27 09:48:32.364471, Epoch: 1/10  |  954/10984  |  loss = 3.47153282\n",
            "2024-03-27 09:48:32.621355, Epoch: 1/10  |  955/10984  |  loss = 3.48172617\n",
            "2024-03-27 09:48:32.907509, Epoch: 1/10  |  956/10984  |  loss = 3.51673985\n",
            "2024-03-27 09:48:33.197695, Epoch: 1/10  |  957/10984  |  loss = 4.07272863\n",
            "2024-03-27 09:48:33.485448, Epoch: 1/10  |  958/10984  |  loss = 3.46708441\n",
            "2024-03-27 09:48:33.778338, Epoch: 1/10  |  959/10984  |  loss = 3.37498426\n",
            "2024-03-27 09:48:34.073678, Epoch: 1/10  |  960/10984  |  loss = 3.45675302\n",
            "2024-03-27 09:48:34.371615, Epoch: 1/10  |  961/10984  |  loss = 3.45443368\n",
            "2024-03-27 09:48:34.669860, Epoch: 1/10  |  962/10984  |  loss = 3.06621861\n",
            "2024-03-27 09:48:34.967018, Epoch: 1/10  |  963/10984  |  loss = 3.20612097\n",
            "2024-03-27 09:48:35.261629, Epoch: 1/10  |  964/10984  |  loss = 3.49671936\n",
            "2024-03-27 09:48:35.543427, Epoch: 1/10  |  965/10984  |  loss = 3.30161858\n",
            "2024-03-27 09:48:35.842318, Epoch: 1/10  |  966/10984  |  loss = 3.43888998\n",
            "2024-03-27 09:48:36.143260, Epoch: 1/10  |  967/10984  |  loss = 3.37260008\n",
            "2024-03-27 09:48:36.437658, Epoch: 1/10  |  968/10984  |  loss = 3.13509321\n",
            "2024-03-27 09:48:36.731315, Epoch: 1/10  |  969/10984  |  loss = 3.39696574\n",
            "2024-03-27 09:48:37.020700, Epoch: 1/10  |  970/10984  |  loss = 3.38684082\n",
            "2024-03-27 09:48:37.301769, Epoch: 1/10  |  971/10984  |  loss = 3.47785258\n",
            "2024-03-27 09:48:37.592232, Epoch: 1/10  |  972/10984  |  loss = 3.04054403\n",
            "2024-03-27 09:48:37.835289, Epoch: 1/10  |  973/10984  |  loss = 2.92838049\n",
            "2024-03-27 09:48:38.134372, Epoch: 1/10  |  974/10984  |  loss = 3.54481959\n",
            "2024-03-27 09:48:38.393958, Epoch: 1/10  |  975/10984  |  loss = 3.48739934\n",
            "2024-03-27 09:48:38.672495, Epoch: 1/10  |  976/10984  |  loss = 3.10632420\n",
            "2024-03-27 09:48:38.937300, Epoch: 1/10  |  977/10984  |  loss = 3.28191614\n",
            "2024-03-27 09:48:39.212925, Epoch: 1/10  |  978/10984  |  loss = 3.27887082\n",
            "2024-03-27 09:48:39.501739, Epoch: 1/10  |  979/10984  |  loss = 3.22681713\n",
            "2024-03-27 09:48:39.787475, Epoch: 1/10  |  980/10984  |  loss = 3.63688922\n",
            "2024-03-27 09:48:40.075108, Epoch: 1/10  |  981/10984  |  loss = 3.11965609\n",
            "2024-03-27 09:48:40.356178, Epoch: 1/10  |  982/10984  |  loss = 4.19098282\n",
            "2024-03-27 09:48:40.612679, Epoch: 1/10  |  983/10984  |  loss = 3.50719500\n",
            "2024-03-27 09:48:40.900134, Epoch: 1/10  |  984/10984  |  loss = 3.82009172\n",
            "2024-03-27 09:48:41.191006, Epoch: 1/10  |  985/10984  |  loss = 3.24604678\n",
            "2024-03-27 09:48:41.476956, Epoch: 1/10  |  986/10984  |  loss = 3.34951448\n",
            "2024-03-27 09:48:41.772334, Epoch: 1/10  |  987/10984  |  loss = 3.15325928\n",
            "2024-03-27 09:48:42.061164, Epoch: 1/10  |  988/10984  |  loss = 3.78088617\n",
            "2024-03-27 09:48:42.352738, Epoch: 1/10  |  989/10984  |  loss = 3.21418309\n",
            "2024-03-27 09:48:42.637582, Epoch: 1/10  |  990/10984  |  loss = 3.13923740\n",
            "2024-03-27 09:48:42.924228, Epoch: 1/10  |  991/10984  |  loss = 3.55020428\n",
            "2024-03-27 09:48:43.179657, Epoch: 1/10  |  992/10984  |  loss = 2.83455205\n",
            "2024-03-27 09:48:43.481199, Epoch: 1/10  |  993/10984  |  loss = 3.21458173\n",
            "2024-03-27 09:48:43.761769, Epoch: 1/10  |  994/10984  |  loss = 3.17188382\n",
            "2024-03-27 09:48:43.996816, Epoch: 1/10  |  995/10984  |  loss = 2.97636747\n",
            "2024-03-27 09:48:44.289051, Epoch: 1/10  |  996/10984  |  loss = 3.60511279\n",
            "2024-03-27 09:48:44.555269, Epoch: 1/10  |  997/10984  |  loss = 2.84647727\n",
            "2024-03-27 09:48:44.850646, Epoch: 1/10  |  998/10984  |  loss = 3.46082926\n",
            "2024-03-27 09:48:45.115000, Epoch: 1/10  |  999/10984  |  loss = 3.11973524\n",
            "2024-03-27 09:48:45.438592, Epoch: 1/10  |  1000/10984  |  loss = 3.72884202\n",
            "2024-03-27 09:48:45.725841, Epoch: 1/10  |  1001/10984  |  loss = 3.52471042\n",
            "2024-03-27 09:48:46.021243, Epoch: 1/10  |  1002/10984  |  loss = 2.53740525\n",
            "2024-03-27 09:48:46.279546, Epoch: 1/10  |  1003/10984  |  loss = 3.33880115\n",
            "2024-03-27 09:48:46.587008, Epoch: 1/10  |  1004/10984  |  loss = 3.23583031\n",
            "2024-03-27 09:48:46.872884, Epoch: 1/10  |  1005/10984  |  loss = 2.86623311\n",
            "2024-03-27 09:48:47.168141, Epoch: 1/10  |  1006/10984  |  loss = 3.32336617\n",
            "2024-03-27 09:48:47.461195, Epoch: 1/10  |  1007/10984  |  loss = 2.90806174\n",
            "2024-03-27 09:48:47.766650, Epoch: 1/10  |  1008/10984  |  loss = 2.79959726\n",
            "2024-03-27 09:48:48.067340, Epoch: 1/10  |  1009/10984  |  loss = 3.39415622\n",
            "2024-03-27 09:48:48.365784, Epoch: 1/10  |  1010/10984  |  loss = 3.24049807\n",
            "2024-03-27 09:48:48.645245, Epoch: 1/10  |  1011/10984  |  loss = 3.45173669\n",
            "2024-03-27 09:48:48.945647, Epoch: 1/10  |  1012/10984  |  loss = 3.13208199\n",
            "2024-03-27 09:48:49.252241, Epoch: 1/10  |  1013/10984  |  loss = 3.49270415\n",
            "2024-03-27 09:48:49.560686, Epoch: 1/10  |  1014/10984  |  loss = 3.73341346\n",
            "2024-03-27 09:48:49.823323, Epoch: 1/10  |  1015/10984  |  loss = 2.96576262\n",
            "2024-03-27 09:48:50.088079, Epoch: 1/10  |  1016/10984  |  loss = 3.88085413\n",
            "2024-03-27 09:48:50.377917, Epoch: 1/10  |  1017/10984  |  loss = 3.25514960\n",
            "2024-03-27 09:48:50.672122, Epoch: 1/10  |  1018/10984  |  loss = 2.83988643\n",
            "2024-03-27 09:48:50.965919, Epoch: 1/10  |  1019/10984  |  loss = 2.93720937\n",
            "2024-03-27 09:48:51.248357, Epoch: 1/10  |  1020/10984  |  loss = 3.43563890\n",
            "2024-03-27 09:48:51.538258, Epoch: 1/10  |  1021/10984  |  loss = 2.64863443\n",
            "2024-03-27 09:48:51.825345, Epoch: 1/10  |  1022/10984  |  loss = 2.85153031\n",
            "2024-03-27 09:48:52.111730, Epoch: 1/10  |  1023/10984  |  loss = 3.39523983\n",
            "2024-03-27 09:48:52.412053, Epoch: 1/10  |  1024/10984  |  loss = 3.11100936\n",
            "2024-03-27 09:48:52.705662, Epoch: 1/10  |  1025/10984  |  loss = 3.30140901\n",
            "2024-03-27 09:48:52.993173, Epoch: 1/10  |  1026/10984  |  loss = 3.51494336\n",
            "2024-03-27 09:48:53.283104, Epoch: 1/10  |  1027/10984  |  loss = 3.17003775\n",
            "2024-03-27 09:48:53.571829, Epoch: 1/10  |  1028/10984  |  loss = 3.37042880\n",
            "2024-03-27 09:48:53.861443, Epoch: 1/10  |  1029/10984  |  loss = 3.27074885\n",
            "2024-03-27 09:48:54.150891, Epoch: 1/10  |  1030/10984  |  loss = 2.78415513\n",
            "2024-03-27 09:48:54.444260, Epoch: 1/10  |  1031/10984  |  loss = 3.38945222\n",
            "2024-03-27 09:48:54.732803, Epoch: 1/10  |  1032/10984  |  loss = 3.22781301\n",
            "2024-03-27 09:48:55.014598, Epoch: 1/10  |  1033/10984  |  loss = 3.57287645\n",
            "2024-03-27 09:48:55.309640, Epoch: 1/10  |  1034/10984  |  loss = 3.65783811\n",
            "2024-03-27 09:48:55.595271, Epoch: 1/10  |  1035/10984  |  loss = 3.60386324\n",
            "2024-03-27 09:48:55.889917, Epoch: 1/10  |  1036/10984  |  loss = 3.23109937\n",
            "2024-03-27 09:48:56.172199, Epoch: 1/10  |  1037/10984  |  loss = 3.83762193\n",
            "2024-03-27 09:48:56.454569, Epoch: 1/10  |  1038/10984  |  loss = 3.19758844\n",
            "2024-03-27 09:48:56.751211, Epoch: 1/10  |  1039/10984  |  loss = 3.08864069\n",
            "2024-03-27 09:48:57.028940, Epoch: 1/10  |  1040/10984  |  loss = 2.94360304\n",
            "2024-03-27 09:48:57.316824, Epoch: 1/10  |  1041/10984  |  loss = 3.89418602\n",
            "2024-03-27 09:48:57.569848, Epoch: 1/10  |  1042/10984  |  loss = 3.91673255\n",
            "2024-03-27 09:48:57.850804, Epoch: 1/10  |  1043/10984  |  loss = 2.94568300\n",
            "2024-03-27 09:48:58.140310, Epoch: 1/10  |  1044/10984  |  loss = 3.26831508\n",
            "2024-03-27 09:48:58.427811, Epoch: 1/10  |  1045/10984  |  loss = 3.55606222\n",
            "2024-03-27 09:48:58.719784, Epoch: 1/10  |  1046/10984  |  loss = 2.95357966\n",
            "2024-03-27 09:48:58.961597, Epoch: 1/10  |  1047/10984  |  loss = 3.25558925\n",
            "2024-03-27 09:48:59.236887, Epoch: 1/10  |  1048/10984  |  loss = 3.46459031\n",
            "2024-03-27 09:48:59.530880, Epoch: 1/10  |  1049/10984  |  loss = 3.41185927\n",
            "2024-03-27 09:48:59.826458, Epoch: 1/10  |  1050/10984  |  loss = 3.80876589\n",
            "2024-03-27 09:49:00.134963, Epoch: 1/10  |  1051/10984  |  loss = 3.53902841\n",
            "2024-03-27 09:49:00.394321, Epoch: 1/10  |  1052/10984  |  loss = 3.26694226\n",
            "2024-03-27 09:49:00.698905, Epoch: 1/10  |  1053/10984  |  loss = 2.84297776\n",
            "2024-03-27 09:49:01.003395, Epoch: 1/10  |  1054/10984  |  loss = 2.91961002\n",
            "2024-03-27 09:49:01.296250, Epoch: 1/10  |  1055/10984  |  loss = 3.18972874\n",
            "2024-03-27 09:49:01.599692, Epoch: 1/10  |  1056/10984  |  loss = 3.71143460\n",
            "2024-03-27 09:49:01.866759, Epoch: 1/10  |  1057/10984  |  loss = 3.06149983\n",
            "2024-03-27 09:49:02.166403, Epoch: 1/10  |  1058/10984  |  loss = 3.57760215\n",
            "2024-03-27 09:49:02.462466, Epoch: 1/10  |  1059/10984  |  loss = 2.75424576\n",
            "2024-03-27 09:49:02.750125, Epoch: 1/10  |  1060/10984  |  loss = 3.73118401\n",
            "2024-03-27 09:49:03.037815, Epoch: 1/10  |  1061/10984  |  loss = 3.14848924\n",
            "2024-03-27 09:49:03.319727, Epoch: 1/10  |  1062/10984  |  loss = 3.42919493\n",
            "2024-03-27 09:49:03.588154, Epoch: 1/10  |  1063/10984  |  loss = 4.38000345\n",
            "2024-03-27 09:49:03.879710, Epoch: 1/10  |  1064/10984  |  loss = 2.96308780\n",
            "2024-03-27 09:49:04.170683, Epoch: 1/10  |  1065/10984  |  loss = 3.07887650\n",
            "2024-03-27 09:49:04.435455, Epoch: 1/10  |  1066/10984  |  loss = 2.88397646\n",
            "2024-03-27 09:49:04.718672, Epoch: 1/10  |  1067/10984  |  loss = 2.50491238\n",
            "2024-03-27 09:49:05.009319, Epoch: 1/10  |  1068/10984  |  loss = 2.93259072\n",
            "2024-03-27 09:49:05.294522, Epoch: 1/10  |  1069/10984  |  loss = 2.98593640\n",
            "2024-03-27 09:49:05.575833, Epoch: 1/10  |  1070/10984  |  loss = 3.18191075\n",
            "2024-03-27 09:49:05.858453, Epoch: 1/10  |  1071/10984  |  loss = 2.67539310\n",
            "2024-03-27 09:49:06.145600, Epoch: 1/10  |  1072/10984  |  loss = 3.00110459\n",
            "2024-03-27 09:49:06.395468, Epoch: 1/10  |  1073/10984  |  loss = 3.58639169\n",
            "2024-03-27 09:49:06.701654, Epoch: 1/10  |  1074/10984  |  loss = 3.19591856\n",
            "2024-03-27 09:49:06.993247, Epoch: 1/10  |  1075/10984  |  loss = 2.51810384\n",
            "2024-03-27 09:49:07.274755, Epoch: 1/10  |  1076/10984  |  loss = 3.54966807\n",
            "2024-03-27 09:49:07.566149, Epoch: 1/10  |  1077/10984  |  loss = 3.40229654\n",
            "2024-03-27 09:49:07.857655, Epoch: 1/10  |  1078/10984  |  loss = 3.52964664\n",
            "2024-03-27 09:49:08.144098, Epoch: 1/10  |  1079/10984  |  loss = 3.08173132\n",
            "2024-03-27 09:49:08.406937, Epoch: 1/10  |  1080/10984  |  loss = 3.50890946\n",
            "2024-03-27 09:49:08.666407, Epoch: 1/10  |  1081/10984  |  loss = 2.81310177\n",
            "2024-03-27 09:49:08.957869, Epoch: 1/10  |  1082/10984  |  loss = 3.99010158\n",
            "2024-03-27 09:49:09.243529, Epoch: 1/10  |  1083/10984  |  loss = 3.78476191\n",
            "2024-03-27 09:49:09.528783, Epoch: 1/10  |  1084/10984  |  loss = 3.93630433\n",
            "2024-03-27 09:49:09.820860, Epoch: 1/10  |  1085/10984  |  loss = 3.04345179\n",
            "2024-03-27 09:49:10.110427, Epoch: 1/10  |  1086/10984  |  loss = 2.65337133\n",
            "2024-03-27 09:49:10.371241, Epoch: 1/10  |  1087/10984  |  loss = 2.96796679\n",
            "2024-03-27 09:49:10.638231, Epoch: 1/10  |  1088/10984  |  loss = 3.33252025\n",
            "2024-03-27 09:49:10.938189, Epoch: 1/10  |  1089/10984  |  loss = 3.28107500\n",
            "2024-03-27 09:49:11.225726, Epoch: 1/10  |  1090/10984  |  loss = 3.21636701\n",
            "2024-03-27 09:49:11.489811, Epoch: 1/10  |  1091/10984  |  loss = 3.16268849\n",
            "2024-03-27 09:49:11.779527, Epoch: 1/10  |  1092/10984  |  loss = 3.19512177\n",
            "2024-03-27 09:49:12.074531, Epoch: 1/10  |  1093/10984  |  loss = 2.89634109\n",
            "2024-03-27 09:49:12.368857, Epoch: 1/10  |  1094/10984  |  loss = 2.94412661\n",
            "2024-03-27 09:49:12.673380, Epoch: 1/10  |  1095/10984  |  loss = 2.71410704\n",
            "2024-03-27 09:49:12.924468, Epoch: 1/10  |  1096/10984  |  loss = 2.55923820\n",
            "2024-03-27 09:49:13.230037, Epoch: 1/10  |  1097/10984  |  loss = 2.67593718\n",
            "2024-03-27 09:49:13.534272, Epoch: 1/10  |  1098/10984  |  loss = 3.77708268\n",
            "2024-03-27 09:49:13.831392, Epoch: 1/10  |  1099/10984  |  loss = 3.22378612\n",
            "2024-03-27 09:49:14.139417, Epoch: 1/10  |  1100/10984  |  loss = 3.32304311\n",
            "2024-03-27 09:49:14.436915, Epoch: 1/10  |  1101/10984  |  loss = 3.18509221\n",
            "2024-03-27 09:49:14.746863, Epoch: 1/10  |  1102/10984  |  loss = 3.61802173\n",
            "2024-03-27 09:49:15.033522, Epoch: 1/10  |  1103/10984  |  loss = 3.87973857\n",
            "2024-03-27 09:49:15.329785, Epoch: 1/10  |  1104/10984  |  loss = 3.51847720\n",
            "2024-03-27 09:49:15.613624, Epoch: 1/10  |  1105/10984  |  loss = 4.17970419\n",
            "2024-03-27 09:49:15.894551, Epoch: 1/10  |  1106/10984  |  loss = 3.52634811\n",
            "2024-03-27 09:49:16.184033, Epoch: 1/10  |  1107/10984  |  loss = 3.21365666\n",
            "2024-03-27 09:49:16.385360, Epoch: 1/10  |  1108/10984  |  loss = 3.62548304\n",
            "2024-03-27 09:49:16.670711, Epoch: 1/10  |  1109/10984  |  loss = 3.60081244\n",
            "2024-03-27 09:49:16.955510, Epoch: 1/10  |  1110/10984  |  loss = 3.10346603\n",
            "2024-03-27 09:49:17.245959, Epoch: 1/10  |  1111/10984  |  loss = 3.17183065\n",
            "2024-03-27 09:49:17.467305, Epoch: 1/10  |  1112/10984  |  loss = 3.39926410\n",
            "2024-03-27 09:49:17.763845, Epoch: 1/10  |  1113/10984  |  loss = 2.93811607\n",
            "2024-03-27 09:49:18.070748, Epoch: 1/10  |  1114/10984  |  loss = 2.51063132\n",
            "2024-03-27 09:49:18.359900, Epoch: 1/10  |  1115/10984  |  loss = 3.88859248\n",
            "2024-03-27 09:49:18.653988, Epoch: 1/10  |  1116/10984  |  loss = 2.73861480\n",
            "2024-03-27 09:49:18.942965, Epoch: 1/10  |  1117/10984  |  loss = 3.29623437\n",
            "2024-03-27 09:49:19.234637, Epoch: 1/10  |  1118/10984  |  loss = 3.20355892\n",
            "2024-03-27 09:49:19.518437, Epoch: 1/10  |  1119/10984  |  loss = 2.73629785\n",
            "2024-03-27 09:49:19.803281, Epoch: 1/10  |  1120/10984  |  loss = 3.41117907\n",
            "2024-03-27 09:49:20.086711, Epoch: 1/10  |  1121/10984  |  loss = 2.74924898\n",
            "2024-03-27 09:49:20.372352, Epoch: 1/10  |  1122/10984  |  loss = 2.43072462\n",
            "2024-03-27 09:49:20.659329, Epoch: 1/10  |  1123/10984  |  loss = 3.20365477\n",
            "2024-03-27 09:49:20.924880, Epoch: 1/10  |  1124/10984  |  loss = 3.11726642\n",
            "2024-03-27 09:49:21.213233, Epoch: 1/10  |  1125/10984  |  loss = 3.20287967\n",
            "2024-03-27 09:49:21.453752, Epoch: 1/10  |  1126/10984  |  loss = 3.42387366\n",
            "2024-03-27 09:49:21.733646, Epoch: 1/10  |  1127/10984  |  loss = 3.09960103\n",
            "2024-03-27 09:49:22.022226, Epoch: 1/10  |  1128/10984  |  loss = 3.76574707\n",
            "2024-03-27 09:49:22.311780, Epoch: 1/10  |  1129/10984  |  loss = 2.70790124\n",
            "2024-03-27 09:49:22.587340, Epoch: 1/10  |  1130/10984  |  loss = 2.96736193\n",
            "2024-03-27 09:49:22.881554, Epoch: 1/10  |  1131/10984  |  loss = 2.98723221\n",
            "2024-03-27 09:49:23.170296, Epoch: 1/10  |  1132/10984  |  loss = 3.22579479\n",
            "2024-03-27 09:49:23.481511, Epoch: 1/10  |  1133/10984  |  loss = 2.78271174\n",
            "2024-03-27 09:49:23.769404, Epoch: 1/10  |  1134/10984  |  loss = 3.04625082\n",
            "2024-03-27 09:49:24.049440, Epoch: 1/10  |  1135/10984  |  loss = 3.13313770\n",
            "2024-03-27 09:49:24.341482, Epoch: 1/10  |  1136/10984  |  loss = 3.44645739\n",
            "2024-03-27 09:49:24.630847, Epoch: 1/10  |  1137/10984  |  loss = 3.53407931\n",
            "2024-03-27 09:49:24.917389, Epoch: 1/10  |  1138/10984  |  loss = 3.56719136\n",
            "2024-03-27 09:49:25.208105, Epoch: 1/10  |  1139/10984  |  loss = 2.92911100\n",
            "2024-03-27 09:49:25.501616, Epoch: 1/10  |  1140/10984  |  loss = 2.83334184\n",
            "2024-03-27 09:49:25.796555, Epoch: 1/10  |  1141/10984  |  loss = 2.78365445\n",
            "2024-03-27 09:49:26.079639, Epoch: 1/10  |  1142/10984  |  loss = 3.39169240\n",
            "2024-03-27 09:49:26.325812, Epoch: 1/10  |  1143/10984  |  loss = 2.66763258\n",
            "2024-03-27 09:49:26.632326, Epoch: 1/10  |  1144/10984  |  loss = 3.06723475\n",
            "2024-03-27 09:49:26.926584, Epoch: 1/10  |  1145/10984  |  loss = 4.00551224\n",
            "2024-03-27 09:49:27.227970, Epoch: 1/10  |  1146/10984  |  loss = 2.99705577\n",
            "2024-03-27 09:49:27.513500, Epoch: 1/10  |  1147/10984  |  loss = 3.54110742\n",
            "2024-03-27 09:49:27.745976, Epoch: 1/10  |  1148/10984  |  loss = 2.87868619\n",
            "2024-03-27 09:49:28.040219, Epoch: 1/10  |  1149/10984  |  loss = 3.19742584\n",
            "2024-03-27 09:49:28.333868, Epoch: 1/10  |  1150/10984  |  loss = 3.06821394\n",
            "2024-03-27 09:49:28.626592, Epoch: 1/10  |  1151/10984  |  loss = 3.42388558\n",
            "2024-03-27 09:49:28.916902, Epoch: 1/10  |  1152/10984  |  loss = 3.16589141\n",
            "2024-03-27 09:49:29.198206, Epoch: 1/10  |  1153/10984  |  loss = 2.71220589\n",
            "2024-03-27 09:49:29.479476, Epoch: 1/10  |  1154/10984  |  loss = 3.05731940\n",
            "2024-03-27 09:49:29.761360, Epoch: 1/10  |  1155/10984  |  loss = 3.28789735\n",
            "2024-03-27 09:49:30.045323, Epoch: 1/10  |  1156/10984  |  loss = 3.15552688\n",
            "2024-03-27 09:49:30.343730, Epoch: 1/10  |  1157/10984  |  loss = 2.71588898\n",
            "2024-03-27 09:49:30.634546, Epoch: 1/10  |  1158/10984  |  loss = 3.03548455\n",
            "2024-03-27 09:49:30.931578, Epoch: 1/10  |  1159/10984  |  loss = 3.40607715\n",
            "2024-03-27 09:49:31.224313, Epoch: 1/10  |  1160/10984  |  loss = 3.64680600\n",
            "2024-03-27 09:49:31.511540, Epoch: 1/10  |  1161/10984  |  loss = 2.80380988\n",
            "2024-03-27 09:49:31.796074, Epoch: 1/10  |  1162/10984  |  loss = 3.08468199\n",
            "2024-03-27 09:49:32.050817, Epoch: 1/10  |  1163/10984  |  loss = 3.36458468\n",
            "2024-03-27 09:49:32.336215, Epoch: 1/10  |  1164/10984  |  loss = 2.96453214\n",
            "2024-03-27 09:49:32.623521, Epoch: 1/10  |  1165/10984  |  loss = 3.24243093\n",
            "2024-03-27 09:49:32.920966, Epoch: 1/10  |  1166/10984  |  loss = 2.44442511\n",
            "2024-03-27 09:49:33.217398, Epoch: 1/10  |  1167/10984  |  loss = 3.27996826\n",
            "2024-03-27 09:49:33.466628, Epoch: 1/10  |  1168/10984  |  loss = 3.59823704\n",
            "2024-03-27 09:49:33.749825, Epoch: 1/10  |  1169/10984  |  loss = 3.30027866\n",
            "2024-03-27 09:49:34.039373, Epoch: 1/10  |  1170/10984  |  loss = 2.47644186\n",
            "2024-03-27 09:49:34.328030, Epoch: 1/10  |  1171/10984  |  loss = 3.23639321\n",
            "2024-03-27 09:49:34.578841, Epoch: 1/10  |  1172/10984  |  loss = 3.14456081\n",
            "2024-03-27 09:49:34.860013, Epoch: 1/10  |  1173/10984  |  loss = 3.25639963\n",
            "2024-03-27 09:49:35.156425, Epoch: 1/10  |  1174/10984  |  loss = 3.23248410\n",
            "2024-03-27 09:49:35.452872, Epoch: 1/10  |  1175/10984  |  loss = 3.10916948\n",
            "2024-03-27 09:49:35.736444, Epoch: 1/10  |  1176/10984  |  loss = 2.81344962\n",
            "2024-03-27 09:49:36.025953, Epoch: 1/10  |  1177/10984  |  loss = 2.98640871\n",
            "2024-03-27 09:49:36.336995, Epoch: 1/10  |  1178/10984  |  loss = 2.79471159\n",
            "2024-03-27 09:49:36.627410, Epoch: 1/10  |  1179/10984  |  loss = 3.18667102\n",
            "2024-03-27 09:49:36.905823, Epoch: 1/10  |  1180/10984  |  loss = 3.11742783\n",
            "2024-03-27 09:49:37.193947, Epoch: 1/10  |  1181/10984  |  loss = 3.51471758\n",
            "2024-03-27 09:49:37.488591, Epoch: 1/10  |  1182/10984  |  loss = 3.42220211\n",
            "2024-03-27 09:49:37.788515, Epoch: 1/10  |  1183/10984  |  loss = 2.71309733\n",
            "2024-03-27 09:49:38.074387, Epoch: 1/10  |  1184/10984  |  loss = 3.84269309\n",
            "2024-03-27 09:49:38.368590, Epoch: 1/10  |  1185/10984  |  loss = 3.17870331\n",
            "2024-03-27 09:49:38.676402, Epoch: 1/10  |  1186/10984  |  loss = 3.25295830\n",
            "2024-03-27 09:49:38.971266, Epoch: 1/10  |  1187/10984  |  loss = 4.39996815\n",
            "2024-03-27 09:49:39.272159, Epoch: 1/10  |  1188/10984  |  loss = 3.14695048\n",
            "2024-03-27 09:49:39.560234, Epoch: 1/10  |  1189/10984  |  loss = 3.15931439\n",
            "2024-03-27 09:49:39.849622, Epoch: 1/10  |  1190/10984  |  loss = 2.88424635\n",
            "2024-03-27 09:49:40.127310, Epoch: 1/10  |  1191/10984  |  loss = 3.13059688\n",
            "2024-03-27 09:49:40.416652, Epoch: 1/10  |  1192/10984  |  loss = 3.45350289\n",
            "2024-03-27 09:49:40.704504, Epoch: 1/10  |  1193/10984  |  loss = 3.38144374\n",
            "2024-03-27 09:49:40.998118, Epoch: 1/10  |  1194/10984  |  loss = 2.99653339\n",
            "2024-03-27 09:49:41.266740, Epoch: 1/10  |  1195/10984  |  loss = 3.70292258\n",
            "2024-03-27 09:49:41.525466, Epoch: 1/10  |  1196/10984  |  loss = 2.73967981\n",
            "2024-03-27 09:49:41.814684, Epoch: 1/10  |  1197/10984  |  loss = 3.88982916\n",
            "2024-03-27 09:49:42.100957, Epoch: 1/10  |  1198/10984  |  loss = 2.90472651\n",
            "2024-03-27 09:49:42.388102, Epoch: 1/10  |  1199/10984  |  loss = 3.25029349\n",
            "2024-03-27 09:49:42.679741, Epoch: 1/10  |  1200/10984  |  loss = 2.98398304\n",
            "2024-03-27 09:49:42.970397, Epoch: 1/10  |  1201/10984  |  loss = 2.68621469\n",
            "2024-03-27 09:49:43.251188, Epoch: 1/10  |  1202/10984  |  loss = 3.68196964\n",
            "2024-03-27 09:49:43.539075, Epoch: 1/10  |  1203/10984  |  loss = 3.59901667\n",
            "2024-03-27 09:49:43.827483, Epoch: 1/10  |  1204/10984  |  loss = 3.27361536\n",
            "2024-03-27 09:49:44.120675, Epoch: 1/10  |  1205/10984  |  loss = 3.27128744\n",
            "2024-03-27 09:49:44.409249, Epoch: 1/10  |  1206/10984  |  loss = 3.55674338\n",
            "2024-03-27 09:49:44.699218, Epoch: 1/10  |  1207/10984  |  loss = 2.82833815\n",
            "2024-03-27 09:49:44.992065, Epoch: 1/10  |  1208/10984  |  loss = 2.76083040\n",
            "2024-03-27 09:49:45.290292, Epoch: 1/10  |  1209/10984  |  loss = 2.50576997\n",
            "2024-03-27 09:49:45.582729, Epoch: 1/10  |  1210/10984  |  loss = 3.55289888\n",
            "2024-03-27 09:49:45.883632, Epoch: 1/10  |  1211/10984  |  loss = 2.79573607\n",
            "2024-03-27 09:49:46.149687, Epoch: 1/10  |  1212/10984  |  loss = 3.42932153\n",
            "2024-03-27 09:49:46.433310, Epoch: 1/10  |  1213/10984  |  loss = 4.13140488\n",
            "2024-03-27 09:49:46.719060, Epoch: 1/10  |  1214/10984  |  loss = 3.39731884\n",
            "2024-03-27 09:49:47.013646, Epoch: 1/10  |  1215/10984  |  loss = 2.99708343\n",
            "2024-03-27 09:49:47.301094, Epoch: 1/10  |  1216/10984  |  loss = 3.34540105\n",
            "2024-03-27 09:49:47.596551, Epoch: 1/10  |  1217/10984  |  loss = 3.59409046\n",
            "2024-03-27 09:49:47.888781, Epoch: 1/10  |  1218/10984  |  loss = 3.40542150\n",
            "2024-03-27 09:49:48.107131, Epoch: 1/10  |  1219/10984  |  loss = 3.26514983\n",
            "2024-03-27 09:49:48.406645, Epoch: 1/10  |  1220/10984  |  loss = 3.26949358\n",
            "2024-03-27 09:49:48.697154, Epoch: 1/10  |  1221/10984  |  loss = 2.92974615\n",
            "2024-03-27 09:49:48.985651, Epoch: 1/10  |  1222/10984  |  loss = 2.96145272\n",
            "2024-03-27 09:49:49.245835, Epoch: 1/10  |  1223/10984  |  loss = 2.87514901\n",
            "2024-03-27 09:49:49.536983, Epoch: 1/10  |  1224/10984  |  loss = 3.62533021\n",
            "2024-03-27 09:49:49.833887, Epoch: 1/10  |  1225/10984  |  loss = 3.74499106\n",
            "2024-03-27 09:49:50.121355, Epoch: 1/10  |  1226/10984  |  loss = 2.86655021\n",
            "2024-03-27 09:49:50.397928, Epoch: 1/10  |  1227/10984  |  loss = 3.06504369\n",
            "2024-03-27 09:49:50.678737, Epoch: 1/10  |  1228/10984  |  loss = 3.24958730\n",
            "2024-03-27 09:49:50.968226, Epoch: 1/10  |  1229/10984  |  loss = 3.21694231\n",
            "2024-03-27 09:49:51.273926, Epoch: 1/10  |  1230/10984  |  loss = 2.58817530\n",
            "2024-03-27 09:49:51.567761, Epoch: 1/10  |  1231/10984  |  loss = 2.95383310\n",
            "2024-03-27 09:49:51.867376, Epoch: 1/10  |  1232/10984  |  loss = 3.40473723\n",
            "2024-03-27 09:49:52.176867, Epoch: 1/10  |  1233/10984  |  loss = 2.76104999\n",
            "2024-03-27 09:49:52.478767, Epoch: 1/10  |  1234/10984  |  loss = 3.31924033\n",
            "2024-03-27 09:49:52.758766, Epoch: 1/10  |  1235/10984  |  loss = 4.13188696\n",
            "2024-03-27 09:49:53.064493, Epoch: 1/10  |  1236/10984  |  loss = 3.27600670\n",
            "2024-03-27 09:49:53.361706, Epoch: 1/10  |  1237/10984  |  loss = 3.43166804\n",
            "2024-03-27 09:49:53.657923, Epoch: 1/10  |  1238/10984  |  loss = 3.25798512\n",
            "2024-03-27 09:49:53.936488, Epoch: 1/10  |  1239/10984  |  loss = 2.88085914\n",
            "2024-03-27 09:49:54.222829, Epoch: 1/10  |  1240/10984  |  loss = 3.19486475\n",
            "2024-03-27 09:49:54.521013, Epoch: 1/10  |  1241/10984  |  loss = 3.50203466\n",
            "2024-03-27 09:49:54.811165, Epoch: 1/10  |  1242/10984  |  loss = 3.04419804\n",
            "2024-03-27 09:49:55.102453, Epoch: 1/10  |  1243/10984  |  loss = 3.26619673\n",
            "2024-03-27 09:49:55.389044, Epoch: 1/10  |  1244/10984  |  loss = 2.89424539\n",
            "2024-03-27 09:49:55.631095, Epoch: 1/10  |  1245/10984  |  loss = 3.67171407\n",
            "2024-03-27 09:49:55.926537, Epoch: 1/10  |  1246/10984  |  loss = 3.08498693\n",
            "2024-03-27 09:49:56.222096, Epoch: 1/10  |  1247/10984  |  loss = 3.52435017\n",
            "2024-03-27 09:49:56.489959, Epoch: 1/10  |  1248/10984  |  loss = 3.14600158\n",
            "2024-03-27 09:49:56.740308, Epoch: 1/10  |  1249/10984  |  loss = 3.58651304\n",
            "2024-03-27 09:49:57.008733, Epoch: 1/10  |  1250/10984  |  loss = 3.12165284\n",
            "2024-03-27 09:49:57.248420, Epoch: 1/10  |  1251/10984  |  loss = 3.46956062\n",
            "2024-03-27 09:49:57.538162, Epoch: 1/10  |  1252/10984  |  loss = 3.41313720\n",
            "2024-03-27 09:49:57.834906, Epoch: 1/10  |  1253/10984  |  loss = 3.37845945\n",
            "2024-03-27 09:49:58.126864, Epoch: 1/10  |  1254/10984  |  loss = 2.88579226\n",
            "2024-03-27 09:49:58.415941, Epoch: 1/10  |  1255/10984  |  loss = 2.73755884\n",
            "2024-03-27 09:49:58.699383, Epoch: 1/10  |  1256/10984  |  loss = 3.02334023\n",
            "2024-03-27 09:49:58.999220, Epoch: 1/10  |  1257/10984  |  loss = 3.18788600\n",
            "2024-03-27 09:49:59.280384, Epoch: 1/10  |  1258/10984  |  loss = 3.30988145\n",
            "2024-03-27 09:49:59.552723, Epoch: 1/10  |  1259/10984  |  loss = 2.42209244\n",
            "2024-03-27 09:49:59.807978, Epoch: 1/10  |  1260/10984  |  loss = 2.84048867\n",
            "2024-03-27 09:50:00.100759, Epoch: 1/10  |  1261/10984  |  loss = 3.05337000\n",
            "2024-03-27 09:50:00.396017, Epoch: 1/10  |  1262/10984  |  loss = 3.67207479\n",
            "2024-03-27 09:50:00.648928, Epoch: 1/10  |  1263/10984  |  loss = 2.64249992\n",
            "2024-03-27 09:50:00.918308, Epoch: 1/10  |  1264/10984  |  loss = 3.42398763\n",
            "2024-03-27 09:50:01.208602, Epoch: 1/10  |  1265/10984  |  loss = 3.54834867\n",
            "2024-03-27 09:50:01.496565, Epoch: 1/10  |  1266/10984  |  loss = 2.79141164\n",
            "2024-03-27 09:50:01.786485, Epoch: 1/10  |  1267/10984  |  loss = 3.33405161\n",
            "2024-03-27 09:50:02.075462, Epoch: 1/10  |  1268/10984  |  loss = 3.71770573\n",
            "2024-03-27 09:50:02.374141, Epoch: 1/10  |  1269/10984  |  loss = 2.89625263\n",
            "2024-03-27 09:50:02.671184, Epoch: 1/10  |  1270/10984  |  loss = 3.20433712\n",
            "2024-03-27 09:50:02.923152, Epoch: 1/10  |  1271/10984  |  loss = 2.98025274\n",
            "2024-03-27 09:50:03.204442, Epoch: 1/10  |  1272/10984  |  loss = 3.68807364\n",
            "2024-03-27 09:50:03.502430, Epoch: 1/10  |  1273/10984  |  loss = 2.88063550\n",
            "2024-03-27 09:50:03.799562, Epoch: 1/10  |  1274/10984  |  loss = 3.68412900\n",
            "2024-03-27 09:50:04.086785, Epoch: 1/10  |  1275/10984  |  loss = 2.70454288\n",
            "2024-03-27 09:50:04.386272, Epoch: 1/10  |  1276/10984  |  loss = 3.18959141\n",
            "2024-03-27 09:50:04.676100, Epoch: 1/10  |  1277/10984  |  loss = 3.23914361\n",
            "2024-03-27 09:50:04.971954, Epoch: 1/10  |  1278/10984  |  loss = 3.48568583\n",
            "2024-03-27 09:50:05.265546, Epoch: 1/10  |  1279/10984  |  loss = 3.32793045\n",
            "2024-03-27 09:50:05.568466, Epoch: 1/10  |  1280/10984  |  loss = 2.89305162\n",
            "2024-03-27 09:50:05.872049, Epoch: 1/10  |  1281/10984  |  loss = 2.71403050\n",
            "2024-03-27 09:50:06.161757, Epoch: 1/10  |  1282/10984  |  loss = 2.94026423\n",
            "2024-03-27 09:50:06.464216, Epoch: 1/10  |  1283/10984  |  loss = 3.27497125\n",
            "2024-03-27 09:50:06.749339, Epoch: 1/10  |  1284/10984  |  loss = 3.40738535\n",
            "2024-03-27 09:50:07.038896, Epoch: 1/10  |  1285/10984  |  loss = 3.65202069\n",
            "2024-03-27 09:50:07.325064, Epoch: 1/10  |  1286/10984  |  loss = 2.91844106\n",
            "2024-03-27 09:50:07.558045, Epoch: 1/10  |  1287/10984  |  loss = 3.88560629\n",
            "2024-03-27 09:50:07.854464, Epoch: 1/10  |  1288/10984  |  loss = 2.92559910\n",
            "2024-03-27 09:50:08.156633, Epoch: 1/10  |  1289/10984  |  loss = 2.60379672\n",
            "2024-03-27 09:50:08.447714, Epoch: 1/10  |  1290/10984  |  loss = 3.24382401\n",
            "2024-03-27 09:50:08.727744, Epoch: 1/10  |  1291/10984  |  loss = 2.79195547\n",
            "2024-03-27 09:50:09.027881, Epoch: 1/10  |  1292/10984  |  loss = 2.76992178\n",
            "2024-03-27 09:50:09.323123, Epoch: 1/10  |  1293/10984  |  loss = 3.42677975\n",
            "2024-03-27 09:50:09.616378, Epoch: 1/10  |  1294/10984  |  loss = 3.55427289\n",
            "2024-03-27 09:50:09.909716, Epoch: 1/10  |  1295/10984  |  loss = 3.21424365\n",
            "2024-03-27 09:50:10.203974, Epoch: 1/10  |  1296/10984  |  loss = 2.70758152\n",
            "2024-03-27 09:50:10.464099, Epoch: 1/10  |  1297/10984  |  loss = 3.02070570\n",
            "2024-03-27 09:50:10.756424, Epoch: 1/10  |  1298/10984  |  loss = 3.27571487\n",
            "2024-03-27 09:50:11.042403, Epoch: 1/10  |  1299/10984  |  loss = 3.36228609\n",
            "2024-03-27 09:50:11.331463, Epoch: 1/10  |  1300/10984  |  loss = 2.77186990\n",
            "2024-03-27 09:50:11.626716, Epoch: 1/10  |  1301/10984  |  loss = 3.32936168\n",
            "2024-03-27 09:50:11.912969, Epoch: 1/10  |  1302/10984  |  loss = 3.41086936\n",
            "2024-03-27 09:50:12.200256, Epoch: 1/10  |  1303/10984  |  loss = 3.01154876\n",
            "2024-03-27 09:50:12.471178, Epoch: 1/10  |  1304/10984  |  loss = 3.35607910\n",
            "2024-03-27 09:50:12.757022, Epoch: 1/10  |  1305/10984  |  loss = 3.01608539\n",
            "2024-03-27 09:50:13.038852, Epoch: 1/10  |  1306/10984  |  loss = 3.01338339\n",
            "2024-03-27 09:50:13.332131, Epoch: 1/10  |  1307/10984  |  loss = 2.80574250\n",
            "2024-03-27 09:50:13.619037, Epoch: 1/10  |  1308/10984  |  loss = 3.28887200\n",
            "2024-03-27 09:50:13.893507, Epoch: 1/10  |  1309/10984  |  loss = 3.23440623\n",
            "2024-03-27 09:50:14.176762, Epoch: 1/10  |  1310/10984  |  loss = 4.33206606\n",
            "2024-03-27 09:50:14.472079, Epoch: 1/10  |  1311/10984  |  loss = 3.15349722\n",
            "2024-03-27 09:50:14.758884, Epoch: 1/10  |  1312/10984  |  loss = 2.77893257\n",
            "2024-03-27 09:50:15.051175, Epoch: 1/10  |  1313/10984  |  loss = 3.19918561\n",
            "2024-03-27 09:50:15.343733, Epoch: 1/10  |  1314/10984  |  loss = 2.69775653\n",
            "2024-03-27 09:50:15.622530, Epoch: 1/10  |  1315/10984  |  loss = 4.17538834\n",
            "2024-03-27 09:50:15.921661, Epoch: 1/10  |  1316/10984  |  loss = 2.54487467\n",
            "2024-03-27 09:50:16.211811, Epoch: 1/10  |  1317/10984  |  loss = 3.01905036\n",
            "2024-03-27 09:50:16.459651, Epoch: 1/10  |  1318/10984  |  loss = 3.42342567\n",
            "2024-03-27 09:50:16.729471, Epoch: 1/10  |  1319/10984  |  loss = 3.58785081\n",
            "2024-03-27 09:50:17.026569, Epoch: 1/10  |  1320/10984  |  loss = 3.35823512\n",
            "2024-03-27 09:50:17.328483, Epoch: 1/10  |  1321/10984  |  loss = 3.00028396\n",
            "2024-03-27 09:50:17.623341, Epoch: 1/10  |  1322/10984  |  loss = 3.49312663\n",
            "2024-03-27 09:50:17.911785, Epoch: 1/10  |  1323/10984  |  loss = 2.83396077\n",
            "2024-03-27 09:50:18.223491, Epoch: 1/10  |  1324/10984  |  loss = 2.82722235\n",
            "2024-03-27 09:50:18.480813, Epoch: 1/10  |  1325/10984  |  loss = 2.76001883\n",
            "2024-03-27 09:50:18.778757, Epoch: 1/10  |  1326/10984  |  loss = 2.81738639\n",
            "2024-03-27 09:50:19.090137, Epoch: 1/10  |  1327/10984  |  loss = 2.88653851\n",
            "2024-03-27 09:50:19.364803, Epoch: 1/10  |  1328/10984  |  loss = 3.19580436\n",
            "2024-03-27 09:50:19.656074, Epoch: 1/10  |  1329/10984  |  loss = 3.31887794\n",
            "2024-03-27 09:50:19.903412, Epoch: 1/10  |  1330/10984  |  loss = 2.81716156\n",
            "2024-03-27 09:50:20.200917, Epoch: 1/10  |  1331/10984  |  loss = 2.80497193\n",
            "2024-03-27 09:50:20.488593, Epoch: 1/10  |  1332/10984  |  loss = 3.09428024\n",
            "2024-03-27 09:50:20.748637, Epoch: 1/10  |  1333/10984  |  loss = 3.28138852\n",
            "2024-03-27 09:50:21.043864, Epoch: 1/10  |  1334/10984  |  loss = 2.76092482\n",
            "2024-03-27 09:50:21.334425, Epoch: 1/10  |  1335/10984  |  loss = 3.43371654\n",
            "2024-03-27 09:50:21.604533, Epoch: 1/10  |  1336/10984  |  loss = 3.23092937\n",
            "2024-03-27 09:50:21.896569, Epoch: 1/10  |  1337/10984  |  loss = 2.98731637\n",
            "2024-03-27 09:50:22.207419, Epoch: 1/10  |  1338/10984  |  loss = 2.56672287\n",
            "2024-03-27 09:50:22.446367, Epoch: 1/10  |  1339/10984  |  loss = 3.73294759\n",
            "2024-03-27 09:50:22.741800, Epoch: 1/10  |  1340/10984  |  loss = 2.98549938\n",
            "2024-03-27 09:50:23.028900, Epoch: 1/10  |  1341/10984  |  loss = 3.28678679\n",
            "2024-03-27 09:50:23.324414, Epoch: 1/10  |  1342/10984  |  loss = 3.78636932\n",
            "2024-03-27 09:50:23.602759, Epoch: 1/10  |  1343/10984  |  loss = 3.16737413\n",
            "2024-03-27 09:50:23.886230, Epoch: 1/10  |  1344/10984  |  loss = 3.23562908\n",
            "2024-03-27 09:50:24.153169, Epoch: 1/10  |  1345/10984  |  loss = 3.13229918\n",
            "2024-03-27 09:50:24.448229, Epoch: 1/10  |  1346/10984  |  loss = 3.13661528\n",
            "2024-03-27 09:50:24.746303, Epoch: 1/10  |  1347/10984  |  loss = 3.74682236\n",
            "2024-03-27 09:50:25.040923, Epoch: 1/10  |  1348/10984  |  loss = 2.69202876\n",
            "2024-03-27 09:50:25.342115, Epoch: 1/10  |  1349/10984  |  loss = 3.88051629\n",
            "2024-03-27 09:50:25.636835, Epoch: 1/10  |  1350/10984  |  loss = 3.17099452\n",
            "2024-03-27 09:50:25.936676, Epoch: 1/10  |  1351/10984  |  loss = 3.43652749\n",
            "2024-03-27 09:50:26.226804, Epoch: 1/10  |  1352/10984  |  loss = 3.00745726\n",
            "2024-03-27 09:50:26.508402, Epoch: 1/10  |  1353/10984  |  loss = 3.19972944\n",
            "2024-03-27 09:50:26.800599, Epoch: 1/10  |  1354/10984  |  loss = 2.79083323\n",
            "2024-03-27 09:50:27.083201, Epoch: 1/10  |  1355/10984  |  loss = 3.04919696\n",
            "2024-03-27 09:50:27.370412, Epoch: 1/10  |  1356/10984  |  loss = 2.64758229\n",
            "2024-03-27 09:50:27.661024, Epoch: 1/10  |  1357/10984  |  loss = 3.32399940\n",
            "2024-03-27 09:50:27.953494, Epoch: 1/10  |  1358/10984  |  loss = 3.00914335\n",
            "2024-03-27 09:50:28.209955, Epoch: 1/10  |  1359/10984  |  loss = 3.40881538\n",
            "2024-03-27 09:50:28.513120, Epoch: 1/10  |  1360/10984  |  loss = 3.50892162\n",
            "2024-03-27 09:50:28.802404, Epoch: 1/10  |  1361/10984  |  loss = 3.29958653\n",
            "2024-03-27 09:50:29.089821, Epoch: 1/10  |  1362/10984  |  loss = 3.17254305\n",
            "2024-03-27 09:50:29.362629, Epoch: 1/10  |  1363/10984  |  loss = 2.74106526\n",
            "2024-03-27 09:50:29.603002, Epoch: 1/10  |  1364/10984  |  loss = 3.07621312\n",
            "2024-03-27 09:50:29.905237, Epoch: 1/10  |  1365/10984  |  loss = 2.91605043\n",
            "2024-03-27 09:50:30.202977, Epoch: 1/10  |  1366/10984  |  loss = 3.47435474\n",
            "2024-03-27 09:50:30.525235, Epoch: 1/10  |  1367/10984  |  loss = 3.04588342\n",
            "2024-03-27 09:50:30.858115, Epoch: 1/10  |  1368/10984  |  loss = 2.90990424\n",
            "2024-03-27 09:50:31.092467, Epoch: 1/10  |  1369/10984  |  loss = 3.36708832\n",
            "2024-03-27 09:50:31.340685, Epoch: 1/10  |  1370/10984  |  loss = 3.47785068\n",
            "2024-03-27 09:50:31.653819, Epoch: 1/10  |  1371/10984  |  loss = 3.15319896\n",
            "2024-03-27 09:50:31.955586, Epoch: 1/10  |  1372/10984  |  loss = 3.45684457\n",
            "2024-03-27 09:50:32.245135, Epoch: 1/10  |  1373/10984  |  loss = 2.99645019\n",
            "2024-03-27 09:50:32.543590, Epoch: 1/10  |  1374/10984  |  loss = 2.78086853\n",
            "2024-03-27 09:50:32.825843, Epoch: 1/10  |  1375/10984  |  loss = 3.01297450\n",
            "2024-03-27 09:50:33.105198, Epoch: 1/10  |  1376/10984  |  loss = 3.31571269\n",
            "2024-03-27 09:50:33.387136, Epoch: 1/10  |  1377/10984  |  loss = 3.13573050\n",
            "2024-03-27 09:50:33.675330, Epoch: 1/10  |  1378/10984  |  loss = 3.29043388\n",
            "2024-03-27 09:50:33.970047, Epoch: 1/10  |  1379/10984  |  loss = 2.94782352\n",
            "2024-03-27 09:50:34.259070, Epoch: 1/10  |  1380/10984  |  loss = 2.86480522\n",
            "2024-03-27 09:50:34.512942, Epoch: 1/10  |  1381/10984  |  loss = 3.81833267\n",
            "2024-03-27 09:50:34.807568, Epoch: 1/10  |  1382/10984  |  loss = 3.04264688\n",
            "2024-03-27 09:50:35.078379, Epoch: 1/10  |  1383/10984  |  loss = 3.36678481\n",
            "2024-03-27 09:50:35.371804, Epoch: 1/10  |  1384/10984  |  loss = 2.68446493\n",
            "2024-03-27 09:50:35.656101, Epoch: 1/10  |  1385/10984  |  loss = 2.84512520\n",
            "2024-03-27 09:50:35.949673, Epoch: 1/10  |  1386/10984  |  loss = 3.06332946\n",
            "2024-03-27 09:50:36.235987, Epoch: 1/10  |  1387/10984  |  loss = 3.56888032\n",
            "2024-03-27 09:50:36.526382, Epoch: 1/10  |  1388/10984  |  loss = 3.21292138\n",
            "2024-03-27 09:50:36.813070, Epoch: 1/10  |  1389/10984  |  loss = 3.23708153\n",
            "2024-03-27 09:50:37.095413, Epoch: 1/10  |  1390/10984  |  loss = 3.27003288\n",
            "2024-03-27 09:50:37.378376, Epoch: 1/10  |  1391/10984  |  loss = 2.81188083\n",
            "2024-03-27 09:50:37.674964, Epoch: 1/10  |  1392/10984  |  loss = 2.90186787\n",
            "2024-03-27 09:50:37.941776, Epoch: 1/10  |  1393/10984  |  loss = 3.45073962\n",
            "2024-03-27 09:50:38.211667, Epoch: 1/10  |  1394/10984  |  loss = 3.11180830\n",
            "2024-03-27 09:50:38.492459, Epoch: 1/10  |  1395/10984  |  loss = 3.92071104\n",
            "2024-03-27 09:50:38.750131, Epoch: 1/10  |  1396/10984  |  loss = 3.19711041\n",
            "2024-03-27 09:50:39.035206, Epoch: 1/10  |  1397/10984  |  loss = 3.18251348\n",
            "2024-03-27 09:50:39.300976, Epoch: 1/10  |  1398/10984  |  loss = 3.34515524\n",
            "2024-03-27 09:50:39.595515, Epoch: 1/10  |  1399/10984  |  loss = 3.79464364\n",
            "2024-03-27 09:50:39.872259, Epoch: 1/10  |  1400/10984  |  loss = 2.93276262\n",
            "2024-03-27 09:50:40.165965, Epoch: 1/10  |  1401/10984  |  loss = 2.97705555\n",
            "2024-03-27 09:50:40.415465, Epoch: 1/10  |  1402/10984  |  loss = 3.00920701\n",
            "2024-03-27 09:50:40.712222, Epoch: 1/10  |  1403/10984  |  loss = 2.90086174\n",
            "2024-03-27 09:50:41.005798, Epoch: 1/10  |  1404/10984  |  loss = 3.25972152\n",
            "2024-03-27 09:50:41.290648, Epoch: 1/10  |  1405/10984  |  loss = 3.40577912\n",
            "2024-03-27 09:50:41.576112, Epoch: 1/10  |  1406/10984  |  loss = 2.72890401\n",
            "2024-03-27 09:50:41.873982, Epoch: 1/10  |  1407/10984  |  loss = 2.45495439\n",
            "2024-03-27 09:50:42.139159, Epoch: 1/10  |  1408/10984  |  loss = 2.89486003\n",
            "2024-03-27 09:50:42.429431, Epoch: 1/10  |  1409/10984  |  loss = 3.65205717\n",
            "2024-03-27 09:50:42.711965, Epoch: 1/10  |  1410/10984  |  loss = 3.03096366\n",
            "2024-03-27 09:50:43.016361, Epoch: 1/10  |  1411/10984  |  loss = 3.68884182\n",
            "2024-03-27 09:50:43.317450, Epoch: 1/10  |  1412/10984  |  loss = 3.03636360\n",
            "2024-03-27 09:50:43.607581, Epoch: 1/10  |  1413/10984  |  loss = 3.28801131\n",
            "2024-03-27 09:50:43.904560, Epoch: 1/10  |  1414/10984  |  loss = 3.33736134\n",
            "2024-03-27 09:50:44.208751, Epoch: 1/10  |  1415/10984  |  loss = 3.15389109\n",
            "2024-03-27 09:50:44.513029, Epoch: 1/10  |  1416/10984  |  loss = 3.65233731\n",
            "2024-03-27 09:50:44.823710, Epoch: 1/10  |  1417/10984  |  loss = 3.48068166\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Distractor_Finetune/train.py\", line 250, in <module>\n",
            "    experiment()\n",
            "  File \"/content/drive/MyDrive/Distractor_Finetune/train.py\", line 137, in experiment\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trials"
      ],
      "metadata": {
        "id": "3fi3DPM18hfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Distractor Generation\n",
        "distractor_tokenizer = AutoTokenizer.from_pretrained(distractor_model_type, model_max_length=max_length)\n",
        "distractor_tokenizer.add_special_tokens({\"sep_token\": \"<sep>\"})\n",
        "\n",
        "def prepare_distractor_input(\n",
        "    t5_tokenizer,\n",
        "    context,\n",
        "    question,\n",
        "    answer,\n",
        "    separator='<sep>',\n",
        "    max_length=512,\n",
        "    torch_device='cpu',):\n",
        "\n",
        "    \"\"\"\n",
        "    input: question <sep> answer <sep> article\n",
        "    output: distractor1 <sep> distractor2 <sep> distractor3\n",
        "    \"\"\"\n",
        "    input_text = question + ' ' + separator + ' ' + answer + ' ' + separator + ' ' + context\n",
        "    encoding = t5_tokenizer(\n",
        "        [input_text],\n",
        "        padding=\"longest\",\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",)\n",
        "\n",
        "    input_ids = encoding.input_ids\n",
        "\n",
        "    if torch_device == 'cuda':\n",
        "        input_ids = input_ids.cuda()\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "\n",
        "distractor_input_ids = prepare_distractor_input(\n",
        "        distractor_tokenizer,\n",
        "        context = context, # doc_x, sum_y\n",
        "        question = question,\n",
        "        answer = answer,\n",
        "        separator = distractor_tokenizer.sep_token,\n",
        "        torch_device = torch_device\n",
        ")\n",
        "\n",
        "outputs = distractor_model.generate(\n",
        "    distractor_input_ids,\n",
        "    max_new_tokens=128,\n",
        "    do_sample=True,\n",
        ")\n",
        "\n",
        "distractors = distractor_tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "print(distractors)\n",
        "distractors = distractors.replace(distractor_tokenizer.pad_token, \"\").replace(distractor_tokenizer.eos_token, \"\")\n",
        "print(distractors)\n",
        "distractors = [y.strip() for y in distractors.split(distractor_tokenizer.sep_token)]\n",
        "print(distractors)\n",
        "options = [answer] + distractors\n",
        "print(options)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_q49aTNnZDQ",
        "outputId": "bcba6bb3-ba94-4939-ec06-342417d91a6f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> Djokovic's wish for a \"positive decision\"<sep> An Australian Open in Dubai<sep> Indian Wells and the Miami Open</s>\n",
            " Djokovic's wish for a \"positive decision\"<sep> An Australian Open in Dubai<sep> Indian Wells and the Miami Open\n",
            "['Djokovic\\'s wish for a \"positive decision\"', 'An Australian Open in Dubai', 'Indian Wells and the Miami Open']\n",
            "[\"Djokovic's application for special permission to enter the United States\", 'Djokovic\\'s wish for a \"positive decision\"', 'An Australian Open in Dubai', 'Indian Wells and the Miami Open']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_answering_input(\n",
        "    tokenizer, # longformer_tokenizer\n",
        "    question,\n",
        "    options,\n",
        "    context,\n",
        "    max_seq_length=4096,\n",
        "    torch_device='cpu',\n",
        "):\n",
        "    \"\"\"\n",
        "    this currently only supports longformer\n",
        "    \"\"\"\n",
        "    c_plus_q = context + ' ' + tokenizer.bos_token + ' ' + question\n",
        "    c_plus_q_4 = [c_plus_q] * len(options)\n",
        "\n",
        "    tokenized_examples = tokenizer(\n",
        "        c_plus_q_4, options,\n",
        "        max_length=max_seq_length,\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = tokenized_examples['input_ids'].unsqueeze(0)\n",
        "    attention_mask = tokenized_examples['attention_mask'].unsqueeze(0)\n",
        "\n",
        "    if torch_device == 'cuda':\n",
        "        input_ids = input_ids.cuda()\n",
        "        attention_mask = attention_mask.cuda()\n",
        "\n",
        "    example_encoded = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "avaCl7Kvu-Tb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#UPCOMING\n",
        "\n",
        "# sampled_question_option_examples.append((question, options))\n",
        "# Stage3: Multiple-Choice Answering PROBABILITY\n",
        "answering_max_len = 128\n",
        "longformer_model = 'allenai/longformer-large-4096'\n",
        "answering_max_len = 4096\n",
        "from transformers import LongformerTokenizer, LongformerForMultipleChoice\n",
        "\n",
        "answering_model = LongformerForMultipleChoice.from_pretrained(longformer_model)\n",
        "if torch_device == \"cuda\":\n",
        "    answering_model.cuda()\n",
        "    state = torch.load(answering_model_path)\n",
        "else:\n",
        "    state = torch.load(answering_model_path, map_location=torch.device('cpu'))\n",
        "model_state_dict = state['model']\n",
        "answering_model.load_state_dict(model_state_dict)\n",
        "answering_model.eval()\n",
        "print('Answering Model loaded:', answering_model_path)\n",
        "\n",
        "answering_tokenizer = LongformerTokenizer.from_pretrained(longformer_model)\n",
        "answering_given_inputs = prepare_answering_input(\n",
        "    tokenizer=answering_tokenizer,\n",
        "    question=question,\n",
        "    options=options,\n",
        "    context=context,\n",
        "    max_seq_length=answering_max_len,\n",
        "    torch_device=torch_device\n",
        ")\n",
        "\n",
        "answering_outputs = answering_model(**answering_given_inputs)\n",
        "probs = torch.softmax(answering_outputs['logits'], dim=-1)[0].cpu().tolist()\n",
        "probs = [\"{:.6f}\".format(p) for p in probs]\n",
        "\n",
        "print(\"---------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "_jMTBGj0u62D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339,
          "referenced_widgets": [
            "ae441ec35804478c90e77e66b0ab9215",
            "b686f3ea17cf4b2bb26b7ba3635836ab",
            "86855bf84c674115971847cd34eaf27e",
            "ffb5547bf2fe4dccb3c529dd12bb8883",
            "15cf433e56f74b008c22729d9b4c06c6",
            "58268898eb9c4619a87a3eba8009d2fd",
            "747b486c41314c089a6e024685966cd7",
            "0ff17e7ac2144c9198fad41f858be73f",
            "140b78eb0722405da21e574de214ee3e",
            "008459f3a15c450b9e9fedade10e23ff",
            "a81db9130e5b4a05976520dcff524766",
            "d0bfec24ae2743a589208384f20fd32b",
            "9f5b13fb21784c379fc97baa47dcb9c4",
            "188c2b933364496d9b1b7404e5c41ddc",
            "afef4158982a4fe4a6470df53e0f9212",
            "5c3ff09ffa38458c8e326ea5f1b9e22f",
            "1f11be0bb3ac4649a174987e05b2ecaf",
            "de05b3c9d1ce48f8a130bf39137f8252",
            "41cf30a13b634e0cb9f3f05641238763",
            "691a1624688746f6a545f4945b7a3f27",
            "16dda797a02e4063a52a8eec697f54db",
            "abdd2b0ee6d24b5597c7d51ab03c1bc7"
          ]
        },
        "outputId": "71dcefa4-ca80-485e-f8d2-5bffa259becb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/803 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae441ec35804478c90e77e66b0ab9215"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0bfec24ae2743a589208384f20fd32b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForMultipleChoice were not initialized from the model checkpoint at allenai/longformer-large-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'answering_model_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-dd7740ce3e53>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch_device\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0manswering_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswering_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswering_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'answering_model_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USE Distractive pretrained Model"
      ],
      "metadata": {
        "id": "uTJ4Wdr-mpt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "MToKoS4yjbmi",
        "outputId": "2b53f122-f84e-4d68-e1e3-22e083646582"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-2f79ebd4dd12>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KmXcQU99ivRp"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"potsawee/t5-large-generation-race-Distractor\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-race-Distractor\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = r\"\"\"\n",
        "World number one Novak Djokovic says he is hoping for a \"positive decision\" to allow him\n",
        "to play at Indian Wells and the Miami Open next month. The United States has extended\n",
        "its requirement for international visitors to be vaccinated against Covid-19. Proof of vaccination\n",
        "will be required to enter the country until at least 10 April, but the Serbian has previously\n",
        "said he is unvaccinated. The 35-year-old has applied for special permission to enter the country.\n",
        "Indian Wells and the Miami Open - two of the most prestigious tournaments on the tennis calendar\n",
        "outside the Grand Slams - start on 6 and 20 March respectively. Djokovic says he will return to\n",
        "the ATP tour in Dubai next week after claiming a record-extending 10th Australian Open title\n",
        "and a record-equalling 22nd Grand Slam men's title last month.\"\"\".replace(\"\\n\", \"\")\n",
        "question = \"What is the best title for the passage?\"\n",
        "answer = \"Djokovic's application for special permission to enter the United States\"\n"
      ],
      "metadata": {
        "id": "ly6zM1oce447"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "Kb6YhCHJhfmh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \" \".join([question, tokenizer.sep_token, answer, tokenizer.sep_token, context])\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=128)\n",
        "distractors = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "distractors = distractors.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n",
        "distractors = [y.strip() for y in distractors.split(tokenizer.sep_token)]\n",
        "options = [answer] + distractors\n",
        "\n",
        "if \"\" or '' in options:\n",
        "  try:\n",
        "    options.remove(\"\")\n",
        "  except:\n",
        "    options.remove('')\n",
        "\n",
        "random.shuffle(options)"
      ],
      "metadata": {
        "id": "bAtS62YHjS3U"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N06sIzashsXp",
        "outputId": "eaec661b-f50d-4e9d-8413-8ef684b5614d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Djokovic's preparation for the Miami Open\",\n",
              " \"Djokovic's application for special permission to enter the United States\",\n",
              " \"Djokovic's preparation for the Miami Open\",\n",
              " \"Djokovic's preparation for the Miami Open\"]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drafts"
      ],
      "metadata": {
        "id": "1ZG4XyPQVWcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "4AKqQgxvnvBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/NTI_datasets/RACE.tar.gz\" -C \"/content/drive/MyDrive/NTI_datasets/\"     #[run this cell to extract tar.gz files]"
      ],
      "metadata": {
        "id": "TghYK-BBm9Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine_tune_fromHugging 2"
      ],
      "metadata": {
        "id": "OYDLdCr38x4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model = 't5-small'\n",
        "save_dir = \"model_weights/\"\n",
        "model_name = f\"{t5_model}-Race-Distractor-Generation-version0\"\n",
        "\n",
        "lr0          = 5e-5\n",
        "batch_size   = 8\n",
        "num_workers  = 0\n",
        "num_epochs   = 10\n",
        "max_length   = 512\n",
        "valid_step   = 5000"
      ],
      "metadata": {
        "id": "0FLWyg0Y_TrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"race\", \"all\")\n",
        "dataset[\"train\"][10]"
      ],
      "metadata": {
        "id": "EOJDzOMG9_Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = RaceDistractorGeneration(\n",
        "        tokenizer = t5_tokenizer,\n",
        "        data_split = \"train\",\n",
        "        shuffle_distractors = True,\n",
        "        separator = t5_tokenizer.sep_token,\n",
        "    )"
      ],
      "metadata": {
        "id": "CUnR4stW-aSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "uyX6yg7w8wtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjust code TO retrain if it interrupts"
      ],
      "metadata": {
        "id": "0zXAyXlAVgn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as nd\n",
        "# Load the weights\n",
        "if force_restart or not weights_path.exists():\n",
        "    print(\"\\nStarting the training of T5-model from scratch\\n\")\n",
        "    model.save(weights_path)\n",
        "    train_loss = []\n",
        "    validate_loss = []\n",
        "\n",
        "else:\n",
        "    print(\"\\nLoading weights at %s\" % weights_path)\n",
        "    model.load(weights_path, optimizer)\n",
        "\n",
        "    train_load_losses_np = np.load(train_loss_path)\n",
        "    train_loss = train_load_losses_np.tolist()\n",
        "\n",
        "    validate_load_losses_np = np.load(validate_loss_path)\n",
        "    validate_loss = validate_load_losses_np.tolist()\n",
        "    #assert (len(train_loss) == (model.step/157)) , \"validate loss != train loss \"\n",
        "\n",
        "    print(\"T5-model weights loaded from step %d\" % model.step)\n",
        "    print(f\"\\ntrain loss loaded from: {train_loss_path}, length = {len(train_loss)}\")\n",
        "    print(f\"\\nvalidate loss loaded from: {validate_loss_path}, length = {len(validate_loss)}\")\n",
        "    assert (len(validate_loss) == len(train_loss)) , \"validate loss != train loss \"\n",
        "\n"
      ],
      "metadata": {
        "id": "BlbPtqfSJ87v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YCwRcuHISQWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "class RaceQuestionAnswerGeneration(Dataset):\n",
        "    def __init__(self, tokenizer, data_split, separator='<sep>'):\n",
        "        \"\"\"\n",
        "        task:\n",
        "            - input: article (i.e. context)\n",
        "            - output: question <sep> answer\n",
        "        args:\n",
        "            tokenizer: tokenizer\n",
        "            data_split: train, validation, test\n",
        "        \"\"\"\n",
        "        data = load_dataset(\"race\", \"all\", split=data_split)\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.separator = separator\n",
        "        self.label_mapping = {label: i for i, label in enumerate([\"A\", \"B\", \"C\", \"D\"])}\n",
        "        print(\"RaceQuestionAnswerGeneration Initialized\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        # example_id = example[\"example_id\"]\n",
        "        question = example[\"question\"]\n",
        "        context = example[\"article\"]\n",
        "        options = example[\"options\"]\n",
        "        label_example = example[\"answer\"]\n",
        "        answer = options[self.label_mapping[label_example]]\n",
        "\n",
        "        # input & output\n",
        "        input = context\n",
        "        output = question + ' ' + self.separator + ' ' + answer\n",
        "        return {'input': input, 'output': output}\n",
        "\n",
        "class RaceDistractorGeneration(Dataset):\n",
        "    def __init__(self, tokenizer, data_split, shuffle_distractors=False, separator='<sep>'):\n",
        "        \"\"\"\n",
        "        task:\n",
        "            - input: question <sep> answer <sep> article\n",
        "            - output: distractor1 <sep> distractor2 <sep> distractor3\n",
        "        args:\n",
        "            tokenizer: tokenizer\n",
        "            data_split: train, validation, test\n",
        "        \"\"\"\n",
        "        data = load_dataset(\"race\", \"all\", split=data_split)\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.separator = separator\n",
        "        self.label_mapping = {label: i for i, label in enumerate([\"A\", \"B\", \"C\", \"D\"])}\n",
        "        self.all_labels = [0, 1, 2, 3]\n",
        "        self.shuffle_distractors = shuffle_distractors\n",
        "        print(\"RaceQuestionAnswerGeneration Initialized\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        # example_id = example[\"example_id\"]\n",
        "        question = example[\"question\"]\n",
        "        context = example[\"article\"]\n",
        "        options = example[\"options\"]\n",
        "        label_example = example[\"answer\"]\n",
        "        answer_i = self.label_mapping[label_example]\n",
        "        answer = options[answer_i]\n",
        "        distractor_ids = [i for i in self.all_labels if i != answer_i]\n",
        "        if self.shuffle_distractors:\n",
        "            random.shuffle(distractor_ids)\n",
        "        distractors = [options[i] for i in distractor_ids]\n",
        "\n",
        "        # input & output\n",
        "        input = question + ' ' + self.separator + ' ' + answer + ' ' + self.separator + ' ' + context\n",
        "        output = distractors[0] + ' ' + self.separator + ' ' + distractors[1] + ' ' + self.separator + ' ' + distractors[2]\n",
        "        return {'input': input, 'output': output}\n",
        "\n",
        "class RaceAnsweringModel(Dataset):\n",
        "    def __init__(self,\n",
        "            data_split,\n",
        "        ):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        data = load_dataset(\"race\", \"all\", split=data_split)\n",
        "        self.data = data\n",
        "        self.label_mapping = {label: i for i, label in enumerate([\"A\", \"B\", \"C\", \"D\"])}\n",
        "        self.all_labels = [0, 1, 2, 3]\n",
        "        print(\"RaceAnsweringModel Initialized\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        question = example[\"question\"]\n",
        "        context = example[\"article\"]\n",
        "        options = example[\"options\"]\n",
        "        label_example = example[\"answer\"]\n",
        "        answer_i = self.label_mapping[label_example]\n",
        "\n",
        "        return {'context': context, 'question': question, 'options': options, 'answer_i': answer_i}"
      ],
      "metadata": {
        "id": "YLV9_oJCTsw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = AutoTokenizer.from_pretrained('t5-small', model_max_length=512)\n",
        "t5_tokenizer.add_special_tokens({\"sep_token\": \"<sep>\"})\n",
        "\n",
        "# ---------------------------- Data ---------------------------- #\n",
        "train_data = RaceDistractorGeneration(\n",
        "    tokenizer = t5_tokenizer,\n",
        "    data_split = \"train\",\n",
        "    shuffle_distractors = True,\n",
        "    separator = t5_tokenizer.sep_token,\n",
        ")\n",
        "print(\"len_train_data:\", len(train_data))\n",
        "\n",
        "valid_data = RaceDistractorGeneration(\n",
        "    tokenizer = t5_tokenizer,\n",
        "    data_split = \"validation\",\n",
        "    separator = t5_tokenizer.sep_token,\n",
        ")\n",
        "print(\"len_valid_data:\", len(valid_data))\n"
      ],
      "metadata": {
        "id": "GvrZiB5_TrMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "batch_size = 8\n",
        "total_iters = len(train_data)\n",
        "steps_per_epoch = np.ceil(total_iters / batch_size).astype(np.int32)\n",
        "\n",
        "print(len(valid_data))"
      ],
      "metadata": {
        "id": "s8tglsc8UNhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from data_loader import RaceDistractorGeneration\n",
        "\n",
        "force_restart = True\n",
        "\n",
        "t5_model = 't5-small'\n",
        "model_name = f\"{t5_model}-Race-Distractor-Generation-version0\"\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/Distractor_Finetune/save_dir\"\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/Distractor_Finetune/save_dir/t5_model.pt\"\n",
        "load_weights_path = \"/content/drive/MyDrive/Distractor_Finetune/save_dir/t5-small-Race-Distractor-Generation-version0-step5000.pt\"\n",
        "train_loss_path = \"/content/drive/MyDrive/Distractor_Finetune/save_dir/train_loss.npy\"\n",
        "validate_loss_path = \"/content/drive/MyDrive/Distractor_Finetune/save_dir/validate_loss.npy\"\n",
        "\n",
        "lr0          = 5e-5\n",
        "batch_size   = 32\n",
        "num_workers  = 0\n",
        "num_epochs   = 10\n",
        "max_length   = 512\n",
        "valid_step   = 5000\n",
        "\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(t5_model, model_max_length=max_length)\n",
        "t5_tokenizer.add_special_tokens({\"sep_token\": \"<sep>\"})\n",
        "\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"torch_device:\", torch_device)\n",
        "print(\"model_name:\", model_name)\n",
        "print(\"t5_model:\", t5_model)\n",
        "print(\"lr0:\", lr0)\n",
        "print(\"batch_size:\", batch_size)\n",
        "print(\"num_workers:\", num_workers)\n",
        "print(\"num_epochs:\", num_epochs)\n",
        "print(\"valid_step:\", valid_step)\n",
        "print(\"max_length:\", max_length)\n",
        "\n",
        "\n",
        "def experiment():\n",
        "    # ---------------------------- Data ---------------------------- #\n",
        "    train_data = RaceDistractorGeneration(\n",
        "        tokenizer = t5_tokenizer,\n",
        "        data_split = \"train\",\n",
        "        shuffle_distractors = True,\n",
        "        separator = t5_tokenizer.sep_token,\n",
        "    )\n",
        "    print(\"len_train_data:\", len(train_data))\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "                    train_data,\n",
        "                    batch_size=batch_size,\n",
        "                    num_workers=num_workers,\n",
        "                    shuffle=True,\n",
        "                    collate_fn=collate_fn)\n",
        "\n",
        "    valid_data = RaceDistractorGeneration(\n",
        "        tokenizer = t5_tokenizer,\n",
        "        data_split = \"validation\",\n",
        "        separator = t5_tokenizer.sep_token,\n",
        "    )\n",
        "    print(\"len_valid_data:\", len(valid_data))\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "                    valid_data,\n",
        "                    batch_size=batch_size,\n",
        "                    num_workers=num_workers,\n",
        "                    shuffle=False,\n",
        "                    collate_fn=collate_fn)\n",
        "    # ---------------------------- Model ---------------------------- #\n",
        "\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(t5_model)\n",
        "\n",
        "    if force_restart or not weights_path.exists():\n",
        "      print(\"\\nStarting the training of T5-model from scratch\\n\")\n",
        "      train_loss = []\n",
        "      validate_loss = []\n",
        "\n",
        "      train_loss_as_numpy = np.asarray(train_loss)\n",
        "      np.save(train_loss_path , train_loss_as_numpy)\n",
        "      validate_loss_as_numpy = np.asarray(validate_loss)\n",
        "      np.save(validate_loss_path , validate_loss_as_numpy)\n",
        "\n",
        "      if torch_device == \"cuda\":\n",
        "          model.cuda()\n",
        "      print(\"#parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "      # by default, it's not training!!!\n",
        "      model.train()\n",
        "    else:\n",
        "      print(\"\\nLoading weights at %s\" % load_weights_path)\n",
        "      model.load(weights_path, optimizer)\n",
        "\n",
        "      train_load_losses_np = np.load(train_loss_path)\n",
        "      train_loss = train_load_losses_np.tolist()\n",
        "\n",
        "      validate_load_losses_np = np.load(validate_loss_path)\n",
        "      validate_loss = validate_load_losses_np.tolist()\n",
        "\n",
        "      print(\"T5-model weights loaded from step %d\" % model.step)\n",
        "      print(f\"\\ntrain loss loaded from: {train_loss_path}, length = {len(train_loss)}\")\n",
        "      print(f\"\\nvalidate loss loaded from: {validate_loss_path}, length = {len(validate_loss)}\")\n",
        "      assert (len(validate_loss) == len(train_loss)) , \"validate loss != train loss \"\n",
        "\n",
        "    # ----------------- Optimizer and Loss Function ----------------- #\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr0,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
        "    optimizer.zero_grad()\n",
        "    training_step = 0\n",
        "    stop_counter = 0\n",
        "    best_val_loss = 99999999\n",
        "    total_iters = len(train_data)\n",
        "    steps_per_epoch = np.ceil(total_iters / batch_size).astype(np.int32)\n",
        "\n",
        "    for epoch_i in range(num_epochs):\n",
        "        batches_loss = 0\n",
        "        train_counter = 0\n",
        "        for iter_, sample in enumerate(train_loader):\n",
        "            if sample is None:\n",
        "                continue\n",
        "\n",
        "            input_ids, attention_mask = sample['input_ids'], sample['attention_mask']\n",
        "            labels = sample['labels']\n",
        "\n",
        "            if torch_device == 'cuda':\n",
        "                input_ids = input_ids.cuda()\n",
        "                attention_mask = attention_mask.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
        "            loss.backward()\n",
        "            curr_batch_size = len(labels)\n",
        "            batches_loss += loss.item()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if training_step % 1 == 0:\n",
        "                print(\"{}, Epoch: {}/{}  |  {}/{}  |  loss = {:.8f}\".format(str(datetime.now()), epoch_i, num_epochs, training_step, steps_per_epoch, loss))\n",
        "                sys.stdout.flush()\n",
        "\n",
        "            if training_step % valid_step == 0:\n",
        "                state = {\n",
        "                    'training_step': training_step,\n",
        "                    'model': model.state_dict(),\n",
        "                }\n",
        "                savepath = \"{}/{}-step{}.pt\".format(save_dir, model_name, training_step)\n",
        "                torch.save(state, savepath)\n",
        "                print(\"Saved at {}\".format(savepath))\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    valid_loss = validation(model, valid_loader)\n",
        "                print(\"Valid Loss = {:.6f}\".format(valid_loss))\n",
        "\n",
        "                train_loss.append((batches_loss)/len(train_counter))\n",
        "                validate_loss.append((valid_loss))\n",
        "\n",
        "\n",
        "                model.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                if valid_loss < best_val_loss:\n",
        "                    stop_counter = 0\n",
        "                    best_val_loss = valid_loss\n",
        "                    print(\"Model improved\".format(stop_counter))\n",
        "                else:\n",
        "                    stop_counter += 1\n",
        "                    print(\"Model not improved #{}\".format(stop_counter))\n",
        "                    if stop_counter == 3:\n",
        "                        print(\"Stop training!\")\n",
        "                        return\n",
        "\n",
        "            training_step += 1\n",
        "\n",
        "        print(\"finish epoch: {}\".format(epoch_i+1))\n",
        "\n",
        "    print(\"Finish Training\")\n",
        "\n",
        "def validation(model, valid_loader):\n",
        "    valid_loss = 0\n",
        "    counter = 0\n",
        "    for sample in valid_loader:\n",
        "        input_ids, attention_mask = sample['input_ids'], sample['attention_mask']\n",
        "        labels = sample['labels']\n",
        "\n",
        "        if torch_device == 'cuda':\n",
        "            input_ids = input_ids.cuda()\n",
        "            attention_mask = attention_mask.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
        "        valid_loss += loss.item()\n",
        "        counter += 1\n",
        "        if counter % 50 == 0:\n",
        "            print(\"#\", end=\"\")\n",
        "            sys.stdout.flush()\n",
        "    print()\n",
        "    return valid_loss / counter\n",
        "\n",
        "def collate_fn(list_of_items):\n",
        "    \"\"\"\n",
        "    each item is a dictionary:\n",
        "    \"\"\"\n",
        "    list_of_items = [x for x in list_of_items if x is not None]\n",
        "    batch_size = len(list_of_items)\n",
        "    if batch_size == 0: return None\n",
        "\n",
        "    input_sequences, output_sequences = [], []\n",
        "    for item in list_of_items:\n",
        "        input_sequences.append(item['input'])\n",
        "        output_sequences.append(item['output'])\n",
        "\n",
        "    encoding = t5_tokenizer(\n",
        "        input_sequences,\n",
        "        padding=\"longest\",\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
        "\n",
        "    target_encoding = t5_tokenizer(\n",
        "        output_sequences,\n",
        "        padding=\"longest\",\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # the forward function automatically creates the correct decoder_input_ids\n",
        "    labels = target_encoding.input_ids\n",
        "    # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
        "    labels = torch.tensor(labels)\n",
        "    labels[labels == t5_tokenizer.pad_token_id] = -100\n",
        "\n",
        "    return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels,\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    experiment()"
      ],
      "metadata": {
        "id": "xJ79Jil4ea-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}